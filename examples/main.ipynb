{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.dirname(\"../\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import deepof.data\n",
    "import deepof.models\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda t: [item for sublist in t for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load first batch\n",
    "dset11 = pd.ExcelFile(\n",
    "    \"../../Desktop/deepof-data/tagged_videos/Individual_datasets/DLC_batch_1/DLC_single_CDR1_1/1.Openfield_data-part1/JB05.1-OF-SI-part1.xlsx\"\n",
    ")\n",
    "dset12 = pd.ExcelFile(\n",
    "    \"../../Desktop/deepof-data/tagged_videos/Individual_datasets/DLC_batch_1/DLC_single_CDR1_1/2.Openfielddata-part2/AnimalID's-JB05.1-part2.xlsx\"\n",
    ")\n",
    "dset11 = pd.read_excel(dset11, \"Tabelle2\")\n",
    "dset12 = pd.read_excel(dset12, \"Tabelle2\")\n",
    "\n",
    "dset11.Test = dset11.Test.apply(lambda x: \"Test {}_s11\".format(x))\n",
    "dset12.Test = dset12.Test.apply(lambda x: \"Test {}_s12\".format(x))\n",
    "\n",
    "dset1 = {\"CSDS\":list(dset11.loc[dset11.Treatment.isin([\"CTR+CSDS\",\"NatCre+CSDS\"]), \"Test\"]) + \n",
    "                list(dset12.loc[dset12.Treatment.isin([\"CTR+CSDS\",\"NatCre+CSDS\"]), \"Test\"]),\n",
    "         \"NS\":  list(dset11.loc[dset11.Treatment.isin([\"CTR+nonstressed\",\"NatCre+nonstressed\"]), \"Test\"]) + \n",
    "                list(dset12.loc[dset12.Treatment.isin([\"CTR+nonstressed\",\"NatCre+nonstressed\"]), \"Test\"]),}\n",
    "\n",
    "dset1inv = {}\n",
    "for i in flatten(list(dset1.values())):\n",
    "    if i in dset1[\"CSDS\"]:\n",
    "        dset1inv[i] = \"CSDS\"\n",
    "    else:\n",
    "        dset1inv[i] = \"NS\"\n",
    "        \n",
    "assert len(dset1inv) == dset11.shape[0] + dset12.shape[0], \"You missed some labels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load second batch\n",
    "dset21 = pd.read_excel(\n",
    "    \"../../Desktop/deepof-data/tagged_videos/Individual_datasets/DLC_batch_2/Part1/2_Single/stressproject22.04.2020genotypes-openfieldday1.xlsx\"\n",
    ")\n",
    "dset22 = pd.read_excel(\n",
    "    \"../../Desktop/deepof-data/tagged_videos/Individual_datasets/DLC_batch_2/Part2/2_Single/OpenFieldvideos-part2.xlsx\"\n",
    ")\n",
    "dset21.Test = dset21.Test.apply(lambda x: \"Test {}_s21\".format(x))\n",
    "dset22.Test = dset22.Test.apply(lambda x: \"Test {}_s22\".format(x))\n",
    "\n",
    "dset2 = {\"CSDS\":list(dset21.loc[dset21.Treatment == \"Stress\", \"Test\"]) + \n",
    "                list(dset22.loc[dset22.Treatment == \"Stressed\", \"Test\"]),\n",
    "         \"NS\":  list(dset21.loc[dset21.Treatment == \"Nonstressed\", \"Test\"]) +\n",
    "                list(dset22.loc[dset22.Treatment == \"Nonstressed\", \"Test\"])}\n",
    "\n",
    "dset2inv = {}\n",
    "for i in flatten(list(dset2.values())):\n",
    "    if i in dset2[\"CSDS\"]:\n",
    "        dset2inv[i] = \"CSDS\"\n",
    "    else:\n",
    "        dset2inv[i] = \"NS\"\n",
    "        \n",
    "assert len(dset2inv) == dset21.shape[0] + dset22.shape[0], \"You missed some labels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load third batch\n",
    "\n",
    "dset31 = pd.read_excel(\n",
    "    \"../../Desktop/deepof-data/tagged_videos/Individual_datasets/DLC_batch_3/1.Day2OF-SIpart1/JB05 2Female-ELS-OF-SIpart1.xlsx\",\n",
    "    sheet_name=1\n",
    ")\n",
    "dset32 = pd.read_excel(\n",
    "    \"../../Desktop/deepof-data/tagged_videos/Individual_datasets/DLC_batch_3/2.Day3OF-SIpart2/JB05 2FEMALE-ELS-OF-SIpart2.xlsx\",\n",
    "    sheet_name=1\n",
    ")\n",
    "dset31.Test = dset31.Test.apply(lambda x: \"Test {}_s31\".format(x))\n",
    "dset32.Test = dset32.Test.apply(lambda x: \"Test {}_s32\".format(x))\n",
    "\n",
    "dset3 = {\"CSDS\":[],\n",
    "         \"NS\":  list(dset31.loc[:, \"Test\"]) +\n",
    "                list(dset32.loc[:, \"Test\"])}\n",
    "\n",
    "dset3inv = {}\n",
    "for i in flatten(list(dset3.values())):\n",
    "    if i in dset3[\"CSDS\"]:\n",
    "        dset3inv[i] = \"CSDS\"\n",
    "    else:\n",
    "        dset3inv[i] = \"NS\"\n",
    "        \n",
    "assert len(dset3inv) == dset31.shape[0] + dset32.shape[0], \"You missed some labels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fourth batch\n",
    "dset41 = os.listdir(\"../../Desktop/deepof-data/tagged_videos/Individual_datasets/DLC_batch_4/JB05.4-OpenFieldvideos/\")\n",
    "\n",
    "# Remove empty video!\n",
    "dset41 = [vid for vid in dset41 if \"52\" not in vid]\n",
    "\n",
    "dset4 = {\"CSDS\":[],\n",
    "         \"NS\":  [i[:-4]+\"_s41\" for i in dset41]}\n",
    "\n",
    "dset4inv = {}\n",
    "for i in flatten(list(dset4.values())):\n",
    "    if i in dset4[\"CSDS\"]:\n",
    "        dset4inv[i] = \"CSDS\"\n",
    "    else:\n",
    "        dset4inv[i] = \"NS\"\n",
    "        \n",
    "assert len(dset4inv) == len(dset41), \"You missed some labels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge phenotype dicts and serialise!\n",
    "aggregated_dset = {**dset1inv, **dset2inv, **dset3inv, **dset4inv}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'NS': 115, 'CSDS': 52})\n",
      "167\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(aggregated_dset.values()))\n",
    "print(115+52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save aggregated dataset to disk\n",
    "import pickle\n",
    "with open(\"../../Desktop/deepof-data/deepof_single_topview/deepof_exp_conditions.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(aggregated_dset, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and run project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14 s, sys: 1.17 s, total: 15.1 s\n",
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "deepof_main = deepof.data.project(path=os.path.join(\"..\",\"..\",\"Desktop\",\"deepof-data\",\"deepof_single_topview\"),\n",
    "                                  smooth_alpha=0.99,                                     \n",
    "                                  arena_dims=[380],\n",
    "                                  exclude_bodyparts=[\"Tail_1\", \"Tail_2\", \"Tail_tip\", \"Tail_base\"],\n",
    "                                  exp_conditions=aggregated_dset\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trajectories...\n",
      "Smoothing trajectories...\n",
      "Computing distances...\n",
      "Computing angles...\n",
      "Done!\n",
      "Coordinates of 167 videos across 2 conditions\n",
      "CPU times: user 30 s, sys: 2.93 s, total: 32.9 s\n",
      "Wall time: 34.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "deepof_main = deepof_main.run(verbose=True)\n",
    "print(deepof_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_quality = pd.concat([tab for tab in deepof_main.get_quality().values()]).droplevel(\"scorer\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_quality.boxplot(rot=45)\n",
    "plt.ylim(0.99985, 1.00001)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d7b020c9624ee48d31a53a87549e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='quality_top', max=1.0, step=0.01), Output()), _dom_c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(quality_top=(0., 1., 0.01))\n",
    "def low_quality_tags(quality_top):\n",
    "    pd.DataFrame(pd.melt(all_quality).groupby(\"bodyparts\").value.apply(\n",
    "        lambda y: sum(y<quality_top) / len(y) * 100)\n",
    "                ).sort_values(by=\"value\", ascending=False).plot.bar(rot=45)\n",
    "    \n",
    "    plt.xlabel(\"body part\")\n",
    "    plt.ylabel(\"Tags with quality under {} (%)\".format(quality_top))\n",
    "    plt.tight_layout()\n",
    "    plt.legend([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.9 s, sys: 321 ms, total: 51.2 s\n",
      "Wall time: 51.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "deepof_coords = deepof_main.get_coords(center=\"Center\", polar=False, speed=0, align=\"Spine_1\", align_inplace=True, propagate_labels=False)\n",
    "#deepof_dists  = deepof_main.get_distances(propagate_labels=False)\n",
    "#deepof_angles = deepof_main.get_angles(propagate_labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier detection / remediation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prototype 1:\n",
    "##### 1) Obtain distribution of distances between each bpart at a given time with the time before / after / a combination of both\n",
    "##### 2) Visualize the distribution / see if there is any obvious good fit\n",
    "##### 3) Compute and mark outliers (e.g. 3 sds away from the median)\n",
    "##### 4) Replace outliers by mean between previous and following (not outlier) points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.2 ms, sys: 790 µs, total: 1.99 ms\n",
      "Wall time: 1.45 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# step 1) obtain distribution for example bpart\n",
    "test_bpart = deepof_coords[\"Test 10_s11\"][\"Nose\"]\n",
    "distance_distribution = np.linalg.norm(np.array(test_bpart)[1:,:] - np.array(test_bpart)[:-1,:], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected outliers: 280\n",
      "CPU times: user 374 ms, sys: 44.4 ms, total: 418 ms\n",
      "Wall time: 208 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# step 2) visualize distribution and find a good fit\n",
    "median = np.median(distance_distribution)\n",
    "stddev = np.sqrt(np.std(distance_distribution))\n",
    "approx_gaussian = np.random.normal(median, stddev, 1000)\n",
    "\n",
    "decision_point = median + 3*stddev\n",
    "\n",
    "sns.kdeplot(distance_distribution, label=\"Distance distribution\")\n",
    "sns.kdeplot(approx_gaussian, shade=True, label=\"Gaussian approximation\")\n",
    "plt.axvline(decision_point, c=\"r\", label=\"Decision point\")\n",
    "plt.xlabel(\"Distance across two consecutive timepoints\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.xlim(-10,40)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Detected outliers:\", sum(distance_distribution > decision_point))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280\n",
      "CPU times: user 482 µs, sys: 332 µs, total: 814 µs\n",
      "Wall time: 587 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# step 3) Compute and mark outliers\n",
    "\n",
    "mask = distance_distribution > decision_point\n",
    "mask = np.insert(mask, 0, False, axis=0)\n",
    "print(np.sum(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# step 4) Replace outliers by interpolation\n",
    "\n",
    "def replace_outliers():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "print(\"Preprocessing training set...\")\n",
    "deepof_train = deepof_coords.preprocess(\n",
    "    window_size=24,\n",
    "    window_step=24,\n",
    "    conv_filter=None,\n",
    "    scale=\"standard\",\n",
    "    shuffle=True,\n",
    "    test_videos=0,\n",
    ")[0]\n",
    "\n",
    "print(\"Loading pre-trained model...\")\n",
    "encoder, decoder, grouper, gmvaep, = deepof.models.SEQ_2_SEQ_GMVAE(\n",
    "    loss=\"ELBO\",\n",
    "    number_of_components=20,\n",
    "    compile_model=True,\n",
    "    kl_warmup_epochs=20,\n",
    "    montecarlo_kl=10,\n",
    "    encoding=6,\n",
    "    mmd_warmup_epochs=20,\n",
    "    predictor=0,\n",
    "    phenotype_prediction=0,\n",
    ").build(deepof_train.shape)[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = \"../../Desktop/deepof-data/trained_weights/dimension_and_loss_experiments_24frames/GMVAE_loss=ELBO_encoding=6_k=20_run_0_final_weights.h5\"\n",
    "#weights = [tpath+i for i in os.listdir(tpath) if \"run_0\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_network = weights\n",
    "print(trained_network)\n",
    "l = int(re.findall(\"encoding=(\\d+)_\", trained_network)[0])\n",
    "k = int(re.findall(\"k=(\\d+)_\", trained_network)[0])\n",
    "pheno = 0# float(re.findall(\"pheno=(.+?)_\", trained_network)[0])\n",
    "\n",
    "encoder, decoder, grouper, gmvaep, = deepof.models.SEQ_2_SEQ_GMVAE(\n",
    "    loss=\"ELBO\",\n",
    "    number_of_components=k,\n",
    "    compile_model=True,\n",
    "    kl_warmup_epochs=20,\n",
    "    montecarlo_kl=10,\n",
    "    encoding=l,\n",
    "    mmd_warmup_epochs=20,\n",
    "    predictor=0,\n",
    "    phenotype_prediction=pheno,\n",
    ").build(deepof_train.shape)[:4]\n",
    "\n",
    "gmvaep.load_weights(trained_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data to pass through the models\n",
    "trained_distribution = encoder(deepof_train[:10000])\n",
    "categories = tf.keras.models.Model(encoder.input, encoder.layers[13].output)(deepof_train[:10000]).numpy()\n",
    "\n",
    "# Fit a scaler to unscale the reconstructions later on\n",
    "video_key = np.random.choice(list(deepof_coords.keys()), 1)[0]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(np.array(pd.concat(list(deepof_coords.values()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve latent distribution parameters and sample from posterior\n",
    "def get_median_params(component, categories, cluster, param):\n",
    "    # means = [np.median(component.mean().numpy(), axis=0) for component in mix_components]\n",
    "    # stddevs = [np.median(component.stddev().numpy(), axis=0) for component in mix_components]\n",
    "    if param == \"mean\":\n",
    "        component = component.mean().numpy()\n",
    "    elif param == \"stddev\":\n",
    "        component = component.stddev().numpy()\n",
    "    \n",
    "    cluster_select = np.argmax(categories, axis=1)==cluster\n",
    "    if np.sum(cluster_select) == 0:\n",
    "        return None\n",
    "    component = component[cluster_select]\n",
    "    return np.median(component, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_latent_parameters(distribution, reduce=False, plot=False, categories=None, filt=0, save=True):\n",
    "    mix_components = distribution.components\n",
    "    \n",
    "    # The main problem is here! We need to select only those training instances in which a given cluster was selected. \n",
    "    # Then compute the median for those only\n",
    "    \n",
    "    means = [get_median_params(component, categories, i, \"mean\") for i,component in enumerate(mix_components)]\n",
    "    stddevs = [get_median_params(component, categories, i, \"stddev\") for i,component in enumerate(mix_components)]\n",
    "    means = [i for i in means if i is not None]\n",
    "    stddevs = [i for i in stddevs if i is not None]\n",
    "    \n",
    "    if filter:\n",
    "        filts = np.max(categories, axis=0) > filt\n",
    "        means = [i for i,j in zip(means, filts) if j]\n",
    "        stddevs = [i for i,j in zip(stddevs, filts) if j]\n",
    "    \n",
    "    if reduce:\n",
    "        data = [np.random.normal(size=[1000, len(means[0])],\n",
    "                                 loc=meanvec, \n",
    "                                 scale=stddevvec)[:,np.newaxis] for meanvec, stddevvec in zip(means, stddevs)]\n",
    "        data = np.concatenate(data, axis=1).reshape([1000*len(means), len(means[0])])        \n",
    "        reducer = PCA(n_components=3)\n",
    "        data = reducer.fit_transform(data)\n",
    "        data = data.reshape([1000, len(means), 3])\n",
    "        \n",
    "    if plot == 2:\n",
    "        for i in range(len(means)):\n",
    "            plt.scatter(data[:,i,0], data[:,i,1], label=i)\n",
    "        plt.title(\"Mean representation of latent space - K={}/{} - L={} - filt={}\".format(len(means), \n",
    "                                                                                          len(mix_components), \n",
    "                                                                                          len(means[0]), filt))        \n",
    "        plt.xlabel(\"PCA 1\")\n",
    "        plt.ylabel(\"PCA 2\")\n",
    "        #plt.legend()\n",
    "        if save:\n",
    "            plt.savefig(\"Mean representation of latent space - K={}.{} - L={} - filt={}.png\".format(len(means), \n",
    "                                                                                          len(mix_components), \n",
    "                                                                                          len(means[0]), filt).replace(\" \", \"_\"))\n",
    "        plt.show()\n",
    "        \n",
    "    elif plot == 3:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        for i in range(len(means)):\n",
    "            ax.scatter(data[:,i,0], data[:,i,1], data[:,i,2], label=i)\n",
    "        plt.title(\"Mean representation of latent space - K={}/{} - L={} - filt={}\".format(len(means), \n",
    "                                                                                          len(mix_components), \n",
    "                                                                                          len(means[0]), filt))\n",
    "        ax.set_xlabel(\"PCA 1\")\n",
    "        ax.set_ylabel(\"PCA 2\")\n",
    "        ax.set_zlabel(\"PCA 3\")\n",
    "        #plt.legend()\n",
    "        if save:\n",
    "            plt.savefig(\"Mean representation of latent space - K={}.{} - L={} - filt={}.png\".format(len(means), \n",
    "                                                                                          len(mix_components), \n",
    "                                                                                          len(means[0]), filt).replace(\" \", \"_\"))\n",
    "        plt.show()\n",
    "    \n",
    "    elif plot > 3:\n",
    "        raise ValueError(\"Can't plot in more than 3 dimensions!\")\n",
    "    \n",
    "    return means, stddevs\n",
    "\n",
    "def sample_from_posterior(decoder, parameters, component, enable_variance=False, video_output=False, samples=1):\n",
    "    means, stddevs = parameters\n",
    "    sample = np.random.normal(size=[samples, len(means[component])], loc=means[component], scale=(stddevs[component] if enable_variance else 0))\n",
    "    reconstruction = decoder(sample).mean()\n",
    "    \n",
    "    if video_output:\n",
    "        scaled_video_rec = scaler.inverse_transform(reconstruction)\n",
    "        scaled_video_rec = scaled_video_rec.reshape(\n",
    "            [samples*scaled_video_rec.shape[1], scaled_video_rec.shape[2]]\n",
    "        )\n",
    "        columns = deepof_coords[list(deepof_coords.keys())[0]].columns\n",
    "        scaled_video_rec = pd.DataFrame(scaled_video_rec, columns=columns)\n",
    "\n",
    "        ### VIDEO OUTPUT ###\n",
    "        w = 400\n",
    "        h = 400\n",
    "        factor = 2.5\n",
    "\n",
    "        # Instantiate video\n",
    "        writer = cv2.VideoWriter()\n",
    "        writer.open(\n",
    "            \"Reconstruction_test_L={}_k={}_pheno={}_component={}_video.avi\".format(l,k,pheno,component),\n",
    "            cv2.VideoWriter_fourcc(*\"MJPG\"),\n",
    "            24,\n",
    "            (int(w * factor), int(h * factor)),\n",
    "            True,\n",
    "        )\n",
    "\n",
    "        for frame in tqdm.tqdm(range(scaled_video_rec.shape[0])):\n",
    "\n",
    "            image = np.zeros((h, w, 3), np.uint8) + 30\n",
    "            for bpart in scaled_video_rec.columns.levels[0]:\n",
    "\n",
    "                try:\n",
    "                    pos = (\n",
    "                        (-int(scaled_video_rec[bpart].loc[frame, \"x\"]) + w // 2),\n",
    "                        (-int(scaled_video_rec[bpart].loc[frame, \"y\"]) + h // 2),\n",
    "                    )\n",
    "\n",
    "                    cv2.circle(image, pos, 2, (0, 0, 255), -1)\n",
    "\n",
    "                except KeyError:\n",
    "                    continue\n",
    "\n",
    "            # draw skeleton\n",
    "            def draw_line(start, end, df, col):\n",
    "                for bpart in end:\n",
    "                    cv2.line(\n",
    "                        image,\n",
    "                        tuple(-df[start].loc[frame, :].astype(int) + w // 2),\n",
    "                        tuple(-df[bpart].loc[frame, :].astype(int) + h // 2),\n",
    "                        col,\n",
    "                        1,\n",
    "                    )\n",
    "\n",
    "            col = (0,0,255)\n",
    "            draw_line(\"Nose\", [\"Left_ear\", \"Right_ear\"], scaled_video_rec, col)\n",
    "            draw_line(\"Spine_1\", [\"Left_ear\", \"Right_ear\", \"Left_fhip\", \"Right_fhip\"], scaled_video_rec, col)\n",
    "            draw_line(\"Spine_2\", [\"Spine_1\", \"Left_bhip\", \"Right_bhip\"], scaled_video_rec, col)\n",
    "            #draw_line(\"Tail_1\", [\"Tail_base\", \"Tail_2\"], scaled_video_rec, col)\n",
    "            #draw_line(\"Tail_tip\", [\"Tail_2\"], scaled_video_rec, col)\n",
    "\n",
    "            image = cv2.resize(image, (0, 0), fx=factor, fy=factor)\n",
    "            writer.write(image)\n",
    "\n",
    "        writer.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    return reconstruction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means, stddevs = retrieve_latent_parameters(trained_distribution, categories=categories, reduce=True, plot=3, filt=0.9, save=True)\n",
    "for i in range(0, 20):\n",
    "    reconst = sample_from_posterior(decoder, (means, stddevs), i, enable_variance=True, video_output=True, samples=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_key = np.random.choice(list(deepof_coords.keys()), 1)[0]\n",
    "# video_input = deepof.data.table_dict({video_key:deepof_coords[video_key]}, typ=\"coords\").preprocess(\n",
    "#                                                                                                 window_size=11,\n",
    "#                                                                                                 window_step=1,\n",
    "#                                                                                                 conv_filter=None,\n",
    "#                                                                                                 scale=\"standard\",\n",
    "#                                                                                                 shuffle=False,\n",
    "#                                                                                                 test_videos=0,\n",
    "#                                                                                             )[0]\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(np.array(pd.concat(list(deepof_coords.values()))))\n",
    "\n",
    "# for trained_network in tqdm.tqdm(weights):\n",
    "    \n",
    "#     l = int(re.findall(\"encoding=(\\d+)_\", trained_network)[0])\n",
    "#     k = int(re.findall(\"k=(\\d+)_\", trained_network)[0])\n",
    "#     pheno = float(re.findall(\"pheno=(.+?)_\", trained_network)[0])\n",
    "    \n",
    "#     encoder, decoder, grouper, gmvaep, = deepof.models.SEQ_2_SEQ_GMVAE(\n",
    "#         loss=\"ELBO\",\n",
    "#         number_of_components=k,\n",
    "#         compile_model=True,\n",
    "#         kl_warmup_epochs=20,\n",
    "#         montecarlo_kl=10,\n",
    "#         encoding=l,\n",
    "#         mmd_warmup_epochs=20,\n",
    "#         predictor=0,\n",
    "#         phenotype_prediction=pheno,\n",
    "#     ).build(video_input.shape)[:4]\n",
    "    \n",
    "#     gmvaep.load_weights(trained_network)\n",
    "    \n",
    "\n",
    "#     # Get reconstruction\n",
    "#     video_pred = gmvaep.predict(video_input)[0][:, 6, :]\n",
    "\n",
    "#     # Get encodings\n",
    "#     # video_clusters = grouper.predict(video_input)\n",
    "#     # video_encodings = encoder.predict(video_input)\n",
    "\n",
    "#     scaled_video_pred = scaler.inverse_transform(video_pred)\n",
    "#     scaled_video_input = scaler.inverse_transform(video_input[:, 6, :])\n",
    "\n",
    "#     scaled_video_input = pd.DataFrame(scaled_video_input, columns=deepof_coords[video_key].columns)\n",
    "#     scaled_video_pred = pd.DataFrame(scaled_video_pred, columns=deepof_coords[video_key].columns)\n",
    "    \n",
    "#     ### VIDEO OUTPUT ###\n",
    "#     w = 400\n",
    "#     h = 400\n",
    "#     factor = 2.5\n",
    "\n",
    "#     # Instantiate video\n",
    "#     writer = cv2.VideoWriter()\n",
    "#     writer.open(\n",
    "#         \"L={}_k={}_pheno={}_run0_video.avi\".format(l,k,pheno),\n",
    "#         cv2.VideoWriter_fourcc(*\"MJPG\"),\n",
    "#         24,\n",
    "#         (int(w * factor), int(h * factor)),\n",
    "#         True,\n",
    "#     )\n",
    "\n",
    "#     for frame in tqdm.tqdm(range(250)):\n",
    "\n",
    "#         image = np.zeros((h, w, 3), np.uint8) + 30\n",
    "#         for bpart in scaled_video_input.columns.levels[0]:\n",
    "\n",
    "#             try:\n",
    "#                 pos = (\n",
    "#                     (-int(scaled_video_input[bpart].loc[frame, \"x\"]) + w // 2),\n",
    "#                     (-int(scaled_video_input[bpart].loc[frame, \"y\"]) + h // 2),\n",
    "#                 )\n",
    "\n",
    "#                 pos_pred = (\n",
    "#                     (-int(scaled_video_pred[bpart].loc[frame, \"x\"]) + w // 2),\n",
    "#                     (-int(scaled_video_pred[bpart].loc[frame, \"y\"]) + h // 2),\n",
    "#                 )\n",
    "\n",
    "#                 cv2.circle(image, pos, 2, (0, 0, 255), -1)\n",
    "#                 cv2.circle(image, pos_pred, 2, (0, 255, 0), -1)\n",
    "\n",
    "#             except KeyError:\n",
    "#                 continue\n",
    "\n",
    "#         # draw skeleton\n",
    "#         def draw_line(start, end, df, col):\n",
    "#             for bpart in end:\n",
    "#                 cv2.line(\n",
    "#                     image,\n",
    "#                     tuple(-df[start].loc[frame, :].astype(int) + w // 2),\n",
    "#                     tuple(-df[bpart].loc[frame, :].astype(int) + h // 2),\n",
    "#                     col,\n",
    "#                     1,\n",
    "#                 )\n",
    "\n",
    "#         for df, col in zip([scaled_video_input, scaled_video_pred], [(0,0,255),(0,255,0)]):\n",
    "#             draw_line(\"Nose\", [\"Left_ear\", \"Right_ear\"], df, col)\n",
    "#             draw_line(\"Spine_1\", [\"Left_ear\", \"Right_ear\", \"Left_fhip\", \"Right_fhip\"], df, col)\n",
    "#             draw_line(\"Spine_2\", [\"Spine_1\", \"Tail_base\", \"Left_bhip\", \"Right_bhip\"], df, col)\n",
    "#             draw_line(\"Tail_1\", [\"Tail_base\", \"Tail_2\"], df, col)\n",
    "#             draw_line(\"Tail_tip\", [\"Tail_2\"], df, col)\n",
    "\n",
    "#         image = cv2.resize(image, (0, 0), fx=factor, fy=factor)\n",
    "#         writer.write(image)\n",
    "\n",
    "#     writer.release()\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_corrs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "### Plot latent space!\n",
    "X_train = deepof_coords.preprocess(\n",
    "                            window_size=11,\n",
    "                            window_step=1,\n",
    "                            conv_filter=None,\n",
    "                            scale=\"standard\",\n",
    "                            shuffle=True,\n",
    "                            test_videos=0,\n",
    "                        )[0]\n",
    "\n",
    "samples = 10000\n",
    "X_train = X_train[:samples]\n",
    "\n",
    "for trained_network in tqdm.tqdm(weights):\n",
    "    print(trained_network)\n",
    "    \n",
    "    l = int(re.findall(\"encoding=(\\d+)_\", trained_network)[0])\n",
    "    k = int(re.findall(\"k=(\\d+)_\", trained_network)[0])\n",
    "    pheno = float(re.findall(\"pheno=(.+?)_\", trained_network)[0])\n",
    "\n",
    "    \n",
    "    encoder, decoder, grouper, gmvaep, = deepof.models.SEQ_2_SEQ_GMVAE(\n",
    "        loss=\"ELBO\",\n",
    "        number_of_components=k,\n",
    "        compile_model=True,\n",
    "        kl_warmup_epochs=20,\n",
    "        montecarlo_kl=10,\n",
    "        encoding=l,\n",
    "        mmd_warmup_epochs=20,\n",
    "        predictor=0,\n",
    "        phenotype_prediction=pheno,\n",
    "    ).build(X_train.shape)[:4]\n",
    "    \n",
    "    gmvaep.load_weights(trained_network)\n",
    "\n",
    "    # Get encodings\n",
    "    pheno_pred = gmvaep.predict(X_train)[1]\n",
    "    clusters = grouper.predict(X_train)\n",
    "    encodings = encoder.predict(X_train)\n",
    "    \n",
    "#     # For each cluster, compute correlation between pheno prediction and cluster weight\n",
    "#     pheno_corr = []\n",
    "#     for i in range(k):\n",
    "#         pheno_corr.append(np.corrcoef(clusters[:,i], np.squeeze(pheno_pred))[0,1])\n",
    "#     pheno_corrs[\"L={}_k={}_pheno={}_run0\".format(l,k, pheno)] = pheno_corr\n",
    "    \n",
    "    reducer = umap.UMAP(n_components=2)\n",
    "    encodings = reducer.fit_transform(encodings)\n",
    "    \n",
    "    sns.scatterplot(encodings[:,0], encodings[:,1], \n",
    "                hue=np.squeeze(pheno_pred),#np.argmax(clusters, axis=1).astype(int).astype(str),\n",
    "                #palette=(\"jet\" if k>1 else None), legend=\"none\")\n",
    "                   )\n",
    "    plt.title(\"GMVAE Latent space representation: L={}; k={}\".format(l,k))\n",
    "    plt.xlabel(\"UMAP 1\")\n",
    "    plt.ylabel(\"UMAP 2\")\n",
    "    plt.legend([],[], frameon=False)\n",
    "    plt.savefig(\"L={}_k={}_pheno={}_run0_latent_space_phenohue.pdf\".format(l,k, pheno))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pheno_pred.shape)\n",
    "print(clusters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation density plots\n",
    "pweights = [0.01, 0.1, 0.5, 0.25, 1, 2, 4, 10, 100]\n",
    "for i in pweights:\n",
    "    corrs = {k:v for k,v in pheno_corrs.items() if str(i) in k}\n",
    "    sns.kdeplot(np.concatenate([i for i in corrs.values()]), label=str(i))\n",
    "    plt.xlabel(\"pearson correlation coefficient\")\n",
    "    plt.ylabel(\"density\")\n",
    "    \n",
    "plt.savefig(\"deepof_pheno_fullcorrhistogram.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation density plots\n",
    "pweights = [0.01, 0.1, 0.5, 0.25, 1, 2, 4, 10, 100]\n",
    "for i in pweights:\n",
    "    corrs = {k:v for k,v in pheno_corrs.items() if str(i) in k}\n",
    "    sns.kdeplot(np.concatenate([i for i in corrs.values()]), label=str(i))\n",
    "    plt.xlabel(\"pearson correlation coefficient\")\n",
    "    plt.ylabel(\"density\")\n",
    "    \n",
    "plt.savefig(\"deepof_pheno_parccorrhistogram.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(gmvaep, show_shapes=True, show_layer_names=True,\n",
    "    rankdir='TB', expand_nested=True, dpi=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly_express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_encodings(data, samples, n, clusters, threshold, highlight=None):\n",
    "    \n",
    "    reducer  = LinearDiscriminantAnalysis(n_components=n)\n",
    "    clusters = clusters[:samples, :]\n",
    "    \n",
    "    # filter   = np.max(np.mean(clusters, axis=0), axis=1) > threshold\n",
    "    \n",
    "    clusters = np.argmax(clusters, axis=1)#[filter]\n",
    "    rep = reducer.fit_transform(data[:samples], clusters)\n",
    "\n",
    "    if n == 2:\n",
    "        df = pd.DataFrame({\"encoding-1\":rep[:,0],\"encoding-2\":rep[:,1],\"clusters\":[\"A\"+str(i) for i in clusters]})\n",
    "\n",
    "        enc = px.scatter(data_frame=df, x=\"encoding-1\", y=\"encoding-2\",\n",
    "                           color=\"clusters\", width=600, height=600,\n",
    "                           color_discrete_sequence=px.colors.qualitative.T10)\n",
    "                \n",
    "        #if highlight:\n",
    "        #    ig.add_trace(go.Scatter(x=, y=)\n",
    "\n",
    "    elif n == 3:\n",
    "        df3d = pd.DataFrame({\"encoding-1\":rep[:,0],\"encoding-2\":rep[:,1],\"encoding-3\":rep[:,2],\n",
    "                         \"clusters\":[\"A\"+str(i) for i in clusters]})\n",
    "\n",
    "        enc = px.scatter_3d(data_frame=df3d, x=\"encoding-1\", y=\"encoding-2\", z=\"encoding-3\",\n",
    "                           color=\"clusters\", width=600, height=600,\n",
    "                           color_discrete_sequence=px.colors.qualitative.T10)\n",
    "\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_encodings(encoder.predict(deepof_train[:10000]), 1000, 2, categories, 1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train, y_train, X_test, y_test = deepof_coords.preprocess(window_size=11, window_step=11, conv_filter=None, sigma=55,\n",
    "                                                            shift=0, scale='standard', align='all', shuffle=True, test_videos=5)\n",
    "print(\"Train dataset shape: \", X_train.shape)\n",
    "print(\"Train dataset shape: \", y_train.shape)\n",
    "print(\"Test dataset shape: \", X_test.shape)\n",
    "print(\"Test dataset shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build models and get learning rate (1-cycle policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq 2 seq Variational Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import tensorflow.keras as k\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = 'Baseline_AE'\n",
    "log_dir = os.path.abspath(\n",
    "    \"logs/fit/{}_{}\".format(NAME, datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    ")\n",
    "tensorboard_callback = k.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepof.models import SEQ_2_SEQ_AE, SEQ_2_SEQ_GMVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, decoder, ae = SEQ_2_SEQ_AE().build(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "encoder, generator, grouper, gmvaep, kl_warmup_callback, mmd_warmup_callback = SEQ_2_SEQ_GMVAE(loss='ELBO',\n",
    "                                                                               compile_model=True,\n",
    "                                                                               number_of_components=10,\n",
    "                                                                               kl_warmup_epochs=20,\n",
    "                                                                               mmd_warmup_epochs=0,\n",
    "                                                                               predictor=0,\n",
    "                                                                               phenotype_prediction=0,\n",
    "                                                                               architecture_hparams={\"encoding\":2}\n",
    "                                                                                ).build(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "rates, losses = deepof.model_utils.find_learning_rate(gmvaep, deepof_train[:512*10], deepof_test[:512*10], epochs=1, batch_size=batch_size)\n",
    "deepof.model_utils.plot_lr_vs_loss(rates, losses)\n",
    "plt.title(\"Learning rate tuning\")\n",
    "plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 1.4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = gmvaep.fit(\n",
    "                    x=X_train,\n",
    "                    y=X_train,\n",
    "                    epochs=1,\n",
    "                    batch_size=128,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, [X_test, y_test]),\n",
    "                    callbacks=[kl_warmup_callback],\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pttest\n",
    "samples = 15000\n",
    "montecarlo = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = \"GMVAE_components=30_loss=ELBO_kl_warmup=30_mmd_warmup=30_20200804-225526_final_weights.h5\"\n",
    "\n",
    "gmvaep.load_weights(weights)\n",
    "\n",
    "if montecarlo:\n",
    "    clusts = np.stack([grouper(data[:samples]) for sample in (tqdm(range(montecarlo)))])\n",
    "    clusters = clusts.mean(axis=0)\n",
    "    clusters = np.argmax(clusters, axis=1)\n",
    "    \n",
    "else:\n",
    "    clusters = grouper(data[:samples], training=False)\n",
    "\n",
    "    \n",
    "    clusters = np.argmax(clusters, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_encodings(data, samples, n, clusters, threshold):\n",
    "    \n",
    "    reducer  = PCA(n_components=n)\n",
    "    clusters = clusters[:, :samples]\n",
    "    filter   = np.max(np.mean(clusters, axis=0), axis=1) > threshold\n",
    "    encoder.predict(data[:samples][filter])\n",
    "    print(\"{}/{} samples used ({}%); confidence threshold={}\".format(sum(filter),\n",
    "                                                                     samples,\n",
    "                                                                     sum(filter)/samples*100,\n",
    "                                                                     threshold))\n",
    "    \n",
    "    clusters = np.argmax(np.mean(clusters, axis=0), axis=1)[filter]\n",
    "    rep = reducer.fit_transform(encoder.predict(data[:samples][filter]))\n",
    "\n",
    "    if n == 2:\n",
    "        df = pd.DataFrame({\"encoding-1\":rep[:,0],\"encoding-2\":rep[:,1],\"clusters\":[\"A\"+str(i) for i in clusters]})\n",
    "\n",
    "        enc = px.scatter(data_frame=df, x=\"encoding-1\", y=\"encoding-2\",\n",
    "                           color=\"clusters\", width=600, height=600,\n",
    "                           color_discrete_sequence=px.colors.qualitative.T10)\n",
    "\n",
    "\n",
    "    elif n == 3:\n",
    "        df3d = pd.DataFrame({\"encoding-1\":rep[:,0],\"encoding-2\":rep[:,1],\"encoding-3\":rep[:,2],\n",
    "                         \"clusters\":[\"A\"+str(i) for i in clusters]})\n",
    "\n",
    "        enc = px.scatter_3d(data_frame=df3d, x=\"encoding-1\", y=\"encoding-2\", z=\"encoding-3\",\n",
    "                           color=\"clusters\", width=600, height=600,\n",
    "                           color_discrete_sequence=px.colors.qualitative.T10)\n",
    "\n",
    "    return enc\n",
    "\n",
    "plot_encodings(data, 5000, 2, clusts, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence distribution per cluster\n",
    "for cl in range(5):\n",
    "    cl_select = np.argmax(np.mean(clusts, axis=0), axis=1) == cl\n",
    "    dt = np.mean(clusts[:,cl_select,cl], axis=0)\n",
    "    sns.kdeplot(dt, shade=True, label=cl)\n",
    "    \n",
    "plt.xlabel('MC Dropout confidence')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animated_cluster_heatmap(data, clust, clusters, threshold=0.75, samples=False):\n",
    "    \n",
    "    if not samples:\n",
    "        samples = data.shape[0]\n",
    "    tpoints = data.shape[1]\n",
    "    bdparts = data.shape[2] // 2\n",
    "    \n",
    "    cls = clusters[:,:samples,:]\n",
    "    filt = np.max(np.mean(cls, axis=0), axis=1) > threshold\n",
    "    \n",
    "    cls = np.argmax(np.mean(cls, axis=0), axis=1)[filt]\n",
    "    clust_series = data[:samples][filt][cls==clust]\n",
    "        \n",
    "    rshape = clust_series.reshape(clust_series.shape[0]*clust_series.shape[1],\n",
    "                                  clust_series.shape[2])\n",
    "    \n",
    "    cluster_df = pd.DataFrame()\n",
    "    cluster_df['x'] = rshape[:,[0,2,4,6,8,10]].flatten(order='F')\n",
    "    cluster_df['y'] = rshape[:,[1,3,5,7,9,11]].flatten(order='F')\n",
    "    cluster_df['bpart'] = np.tile(np.repeat(np.arange(bdparts),\n",
    "                                            clust_series.shape[0]), tpoints)\n",
    "    cluster_df['frame'] = np.tile(np.repeat(np.arange(tpoints),\n",
    "                                            clust_series.shape[0]), bdparts)\n",
    "        \n",
    "    fig = px.density_contour(data_frame=cluster_df, x='x', y='y', animation_frame='frame',\n",
    "                     width=600, height=600, \n",
    "                     color='bpart',color_discrete_sequence=px.colors.qualitative.T10)\n",
    "\n",
    "    fig.update_traces(contours_coloring=\"fill\", \n",
    "                      contours_showlabels = True)\n",
    "    \n",
    "    fig.update_xaxes(range=[-3, 3])\n",
    "    fig.update_yaxes(range=[-3, 3])\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# animated_cluster_heatmap(pttest, 4, clusts, samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stability across runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [i for i in os.listdir() if \"GMVAE\" in i and \".h5\" in i]\n",
    "mult_clusters = np.zeros([len(weights), samples])\n",
    "mean_conf = []\n",
    "\n",
    "for k,i in tqdm(enumerate(sorted(weights))):\n",
    "    print(i)\n",
    "    gmvaep.load_weights(i)\n",
    "\n",
    "    if montecarlo:\n",
    "        clusters = np.stack([grouper(data[:samples]) for sample in (tqdm(range(montecarlo)))])\n",
    "        clusters = clusters.mean(axis=0)\n",
    "        mean_conf.append(clusters.max(axis=1))\n",
    "        clusters = np.argmax(clusters, axis=1)\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        clusters = grouper(data[:samples], training=False)\n",
    "        mean_conf.append(clusters.max(axis=1))\n",
    "        clusters = np.argmax(clusters, axis=1)\n",
    "        \n",
    "    mult_clusters[k] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = 0.95\n",
    "ari_dist = []\n",
    "\n",
    "for i,k in enumerate(combinations(range(len(weights)),2)):\n",
    "    filt = ((mean_conf[k[0]] > thr) & (mean_conf[k[1]]>thr))\n",
    "    \n",
    "    ari = adjusted_rand_score(mult_clusters[k[0]][filt],\n",
    "                              mult_clusters[k[1]][filt])\n",
    "    \n",
    "    ari_dist.append(ari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ari_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_ari = []\n",
    "for i in tqdm(range(6)):\n",
    "    random_ari.append(adjusted_rand_score(np.random.uniform(0,6,50).astype(int),\n",
    "                                          np.random.uniform(0,6,50).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(ari_dist, label=\"ARI gmvaep\", shade=True)\n",
    "sns.kdeplot(random_ari, label=\"ARI random\", shade=True)\n",
    "\n",
    "plt.xlabel(\"Normalised Adjusted Rand Index\")\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster differences across conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "DLCS1_coords = DLC_social_1_coords.get_coords(center=\"B_Center\",polar=False, length='00:10:00', align='B_Nose')\n",
    "\n",
    "Treatment_coords = {}\n",
    "\n",
    "for cond in Treatment_dict.keys():\n",
    "    Treatment_coords[cond] = DLCS1_coords.filter(Treatment_dict[cond]).preprocess(window_size=13, \n",
    "                                                 window_step=10, filter=None, scale='standard', align='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "montecarlo = 10\n",
    "\n",
    "Predictions_per_cond = {}\n",
    "Confidences_per_cond = {}\n",
    "\n",
    "for cond in Treatment_dict.keys():\n",
    "    \n",
    "    Predictions_per_cond[cond] = np.stack([grouper(Treatment_coords[cond]\n",
    "                         ) for sample in (tqdm(range(montecarlo)))])\n",
    "\n",
    "    Confidences_per_cond[cond] = np.mean(Predictions_per_cond[cond], axis=0)\n",
    "    Predictions_per_cond[cond] = np.argmax(Confidences_per_cond[cond], axis=1) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Predictions_per_condition = {k:{cl:[] for cl in range(1,31)} for k in Treatment_dict.keys()}\n",
    "\n",
    "for k in Predictions_per_cond.values():\n",
    "    print(Counter(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cond in Treatment_dict.keys():\n",
    "    start = 0\n",
    "    for i,j in enumerate(DLCS1_coords.filter(Treatment_dict[cond]).values()):\n",
    "        \n",
    "        update  = start + j.shape[0]//10\n",
    "        counter = Counter(Predictions_per_cond[cond][start:update])\n",
    "        start  += j.shape[0]//10\n",
    "        \n",
    "        for num in counter.keys():\n",
    "            Predictions_per_condition[cond][num+1].append(counter[num+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = []\n",
    "clusters = []\n",
    "conditions = []\n",
    "for cond,v in Predictions_per_condition.items():\n",
    "    for cluster,i in v.items():\n",
    "        counts+=i\n",
    "        clusters+=list(np.repeat(cluster, len(i)))\n",
    "        conditions+=list(np.repeat(cond, len(i)))\n",
    "        \n",
    "Prediction_per_cond_df = pd.DataFrame({'condition':conditions,\n",
    "                                       'cluster':clusters,\n",
    "                                       'count':counts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame=Prediction_per_cond_df, x='cluster', y='count', color='condition')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(Counter(labels[str(i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score(labels[0], labels[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(ari_dist)\n",
    "plt.xlabel(\"Adjusted Rand Index\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy(np.array([0.5,0,0.5,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd.Categorical(np.array([0.5,0.5,0.5,0.5])).entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk = np.array([0.5,0,0.5,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.clip(np.log(pk), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-np.sum(pk*np.array([-0.69314718,        0, -0.69314718,        0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "entropy = K.sum(tf.multiply(pk, tf.where(~tf.math.is_inf(K.log(pk)), K.log(pk), 0)), axis=0)\n",
    "entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.max(clusts, axis=1))\n",
    "sns.distplot(clusts.reshape(clusts.shape[0] * clusts.shape[1]))\n",
    "plt.axvline(1/10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_means = gmvaep.get_layer(name=\"dense_4\").get_weights()[0][:32]\n",
    "gauss_variances = tf.keras.activations.softplus(gmvaep.get_layer(name=\"dense_4\").get_weights()[0][32:]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_means.shape == gauss_variances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "n=100\n",
    "samples = []\n",
    "for i in range(k):\n",
    "    samples.append(np.random.normal(gauss_means[:,i], gauss_variances[:,i], size=(100,32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "test_matrix = np.zeros([k,k])\n",
    "for i in range(k):\n",
    "    for j in range(k):\n",
    "        test_matrix[i][j] = np.mean(ttest_ind(samples[i], samples[j], equal_var=False)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.55\n",
    "np.sum(test_matrix > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transition matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Treatment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomaly detection - the model was trained in the WT - NS mice alone\n",
    "gmvaep.load_weights(\"GMVAE_components=10_loss=ELBO_kl_warmup=20_mmd_warmup=5_20200721-043310_final_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_NS = table_dict({k:v for k,v in mtest2.items() if k in Treatment_dict['WT+NS']}, typ=\"coords\")\n",
    "WT_WS = table_dict({k:v for k,v in mtest2.items() if k in Treatment_dict['WT+CSDS']}, typ=\"coords\")\n",
    "MU_NS = table_dict({k:v for k,v in mtest2.items() if k in Treatment_dict['NatCre+NS']}, typ=\"coords\")\n",
    "MU_WS = table_dict({k:v for k,v in mtest2.items() if k in Treatment_dict['NatCre+CSDS']}, typ=\"coords\")\n",
    "\n",
    "preps = [WT_NS.preprocess(window_size=11, window_step=10, filter=\"gaussian\", sigma=55,shift=0, scale=\"standard\", align=True),\n",
    "         WT_WS.preprocess(window_size=11, window_step=10, filter=\"gaussian\", sigma=55,shift=0, scale=\"standard\", align=True),\n",
    "         MU_NS.preprocess(window_size=11, window_step=10, filter=\"gaussian\", sigma=55,shift=0, scale=\"standard\", align=True),\n",
    "         MU_WS.preprocess(window_size=11, window_step=10, filter=\"gaussian\", sigma=55,shift=0, scale=\"standard\", align=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [gmvaep.predict(i) for i in preps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "reconst_error = {k:mean_absolute_error(preps[i].reshape(preps[i].shape[0]*preps[i].shape[1],12).T, \n",
    "                                       preds[i].reshape(preds[i].shape[0]*preds[i].shape[1],12).T,\n",
    "                                       multioutput='raw_values') for i,k in enumerate(Treatment_dict.keys())}\n",
    "\n",
    "reconst_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconst_df = pd.concat([pd.DataFrame(np.concatenate([np.repeat(k, len(v)).reshape(len(v),1), v.reshape(len(v),1)],axis=1)) for k,v in reconst_error.items()])\n",
    "reconst_df = reconst_df.astype({0:str,1:float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=reconst_df, x=0, y=1, orient='vertical')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.ylim(0,0.35)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check frame rates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
