# @author lucasmiranda42
# encoding: utf-8
# module deepof

"""

deep autoencoder model for unsupervised pose detection.
Based on VQ-VAE: a variational autoencoder with a vector quantization latent-space (https://arxiv.org/abs/1711.00937).

"""

import tensorflow as tf
import tensorflow_probability as tfp
from tensorflow.keras import Input, Model
from tensorflow.keras.initializers import he_uniform
from tensorflow.keras.layers import Dense, GRU, RepeatVector, TimeDistributed
from tensorflow.keras.layers import LayerNormalization, Bidirectional

from deepof import unsupervised_utils

tfb = tfp.bijectors
tfd = tfp.distributions
tfpl = tfp.layers

# noinspection PyCallingNonCallable
def get_deepof_encoder(
    input_shape,
    latent_dim,
    conv_filters=64,
    dense_activation="relu",
    gru_units_1=32,
    gru_unroll=False,
    bidirectional_merge="concat",
):
    """

    Returns a deep neural network capable of encoding the motion tracking instances into a vector ready to be fed to
    one of the provided structured latent spaces.

    Args:
        input_shape (tuple): shape of the input data
        latent_dim (int): dimension of the latent space
        conv_filters (int): number of filters in the first convolutional layer
        dense_activation (str): activation function for the dense layers. Defaults to "relu".
        gru_units_1 (int): number of units in the first GRU layer. Defaults to 128.
        gru_unroll (bool): whether to unroll the GRU layers. Defaults to False.
        bidirectional_merge (str): how to merge the forward and backward GRU layers. Defaults to "concat".

    Returns:
        keras.Model: a keras model that can be trained to encode motion tracking instances into a vector.

    """

    # Define and instantiate encoder
    x = Input(shape=input_shape)
    encoder = tf.keras.layers.Conv1D(
        filters=conv_filters,
        kernel_size=5,
        strides=1,  # Increased strides yield shorter sequences
        padding="same",
        activation=dense_activation,
        kernel_initializer=he_uniform(),
        use_bias=False,
    )(x)
    encoder = tf.keras.layers.Masking(mask_value=0.0)(encoder)
    encoder = Bidirectional(
        GRU(
            gru_units_1,
            activation="tanh",
            recurrent_activation="sigmoid",
            return_sequences=True,
            unroll=gru_unroll,
            use_bias=True,
        ),
        merge_mode=bidirectional_merge,
    )(encoder)
    encoder = LayerNormalization()(encoder)
    encoder = Bidirectional(
        GRU(
            gru_units_1 // 2,
            activation="tanh",
            recurrent_activation="sigmoid",
            return_sequences=False,
            unroll=gru_unroll,
            use_bias=True,
        ),
        merge_mode=bidirectional_merge,
    )(encoder)
    encoder = LayerNormalization()(encoder)
    encoder_output = tf.keras.layers.Dense(
        latent_dim, kernel_initializer="he_uniform",
    )(encoder)

    return Model(x, encoder_output, name="deepof_encoder")


# noinspection PyCallingNonCallable
def get_deepof_decoder(
    input_shape,
    latent_dim,
    conv_filters=64,
    dense_activation="relu",
    gru_units_1=32,
    gru_unroll=False,
    bidirectional_merge="concat",
):

    """

    Returns a deep neural network capable of decoding the structured latent space generated by one of the compatible
    classes into a sequence of motion tracking instances, either reconstructing the original
    input, or generating new data from given clusters.

    Args:
        input_shape (tuple): shape of the input data
        latent_dim (int): dimensionality of the latent space
        conv_filters (int): number of filters in the first convolutional layer
        dense_activation (str): activation function for the dense layers. Defaults to "relu".
        gru_units_1 (int): number of units in the first GRU layer. Defaults to 128.
        gru_unroll (bool): whether to unroll the GRU layers. Defaults to False.
        bidirectional_merge (str): how to merge the forward and backward GRU layers. Defaults to "concat".

    Returns:
        keras.Model: a keras model that can be trained to decode the latent space into a series of motion tracking
        sequences.

    """

    # Define and instantiate generator
    g = Input(shape=latent_dim)  # Decoder input, shaped as the latent space
    x = Input(shape=input_shape)  # Encoder input, used to generate an output mask
    validity_mask = tf.math.logical_not(tf.reduce_all(x == 0.0, axis=2))

    generator = RepeatVector(input_shape[0])(g)
    generator = Bidirectional(
        GRU(
            gru_units_1 // 2,
            activation="tanh",
            recurrent_activation="sigmoid",
            return_sequences=True,
            unroll=gru_unroll,
            use_bias=True,
        ),
        merge_mode=bidirectional_merge,
    )(generator, mask=validity_mask)
    generator = LayerNormalization()(generator)
    generator = Bidirectional(
        GRU(
            gru_units_1,
            activation="tanh",
            recurrent_activation="sigmoid",
            return_sequences=True,
            unroll=gru_unroll,
            use_bias=True,
        ),
        merge_mode=bidirectional_merge,
    )(generator)
    generator = LayerNormalization()(generator)
    generator = tf.keras.layers.Conv1D(
        filters=conv_filters,
        kernel_size=5,
        strides=1,
        padding="same",
        activation=dense_activation,
        kernel_initializer=he_uniform(),
        use_bias=False,
    )(generator)
    generator = LayerNormalization()(generator)
    x_decoded_mean = TimeDistributed(
        Dense(tfpl.IndependentNormal.params_size(input_shape[1:]) // 2)
    )(generator)

    # Add a skip connection, adding information directly from the latent space to propagate through the decoder
    # early in training.
    x_decoded_mean = tf.keras.layers.Add()(
        [x_decoded_mean, Dense(input_shape[-1], activation=dense_activation)(g)]
    )

    x_decoded = tfpl.DistributionLambda(
        make_distribution_fn=lambda decoded: tfd.Masked(
            tfd.Independent(
                tfd.Normal(
                    loc=decoded[0],
                    scale=tf.ones_like(decoded[0]),
                    validate_args=False,
                    allow_nan_stats=False,
                ),
                reinterpreted_batch_ndims=1,
            ),
            validity_mask=decoded[1],
        ),
        convert_to_tensor_fn="mean",
    )([x_decoded_mean, validity_mask])

    # Zero out values that are not in the initial mask
    x_decoded = tfpl.DistributionLambda(
        make_distribution_fn=lambda decoded: tfd.Masked(
            tfd.TransformedDistribution(
                decoded[0],
                tfb.Scale(tf.cast(tf.expand_dims(decoded[1], axis=2), tf.float32)),
                name="vae_reconstruction",
            ),
            validity_mask=decoded[1],
        ),
        convert_to_tensor_fn="mean",
    )([x_decoded, validity_mask])

    return Model([g, x], x_decoded, name="deepof_decoder")


class VectorQuantizer(tf.keras.models.Model):
    """

    Vector quantizer layer, which quantizes the input vectors into a fixed number of clusters using L2 norm. Based on
    https://arxiv.org/pdf/1509.03700.pdf. Implementation based on https://keras.io/examples/generative/vq_vae/.

    """

    def __init__(
        self, n_components, embedding_dim, beta, reg_gram: float = 0.0, **kwargs
    ):
        """

        Initializes the VQ layer.

        Args:
            n_components (int): number of embeddings to use
            embedding_dim (int): dimensionality of the embeddings
            beta (float): beta value for the loss function
            reg_gram (float): regularization parameter for the Gram matrix
            **kwargs: additional arguments for the parent class

        """

        super(VectorQuantizer, self).__init__(**kwargs)
        self.embedding_dim = embedding_dim
        self.n_components = n_components
        self.beta = beta
        self.reg_gram = reg_gram

        # Initialize the VQ codebook
        w_init = unsupervised_utils.far_uniform_initializer(
            shape=(self.embedding_dim, self.n_components), samples=10000
        )
        self.codebook = tf.Variable(
            initial_value=w_init, trainable=True, name="vqvae_codebook",
        )

    def call(self, x):  # pragma: no cover
        """

        Computes the VQ layer.

        Args:
            x (tf.Tensor): input tensor

        Returns:
                x (tf.Tensor): output tensor

        """

        # Compute input shape and flatten, keeping the embedding dimension intact
        input_shape = tf.shape(x)

        # Add a disentangling penalty to the embeddings
        if self.reg_gram:
            gram_loss = unsupervised_utils.compute_gram_loss(
                x, weight=self.reg_gram, batch_size=input_shape[0]
            )
            self.add_loss(gram_loss)
            self.add_metric(gram_loss, name="gram_loss")

        flattened = tf.reshape(x, [-1, self.embedding_dim])

        # Quantize input using the codebook
        encoding_indices = tf.cast(
            self.get_code_indices(flattened, return_soft_counts=False), tf.int32
        )
        soft_counts = self.get_code_indices(flattened, return_soft_counts=True)

        encodings = tf.one_hot(encoding_indices, self.n_components)

        quantized = tf.matmul(encodings, self.codebook, transpose_b=True)
        quantized = tf.reshape(quantized, input_shape)

        # Compute vector quantization loss, and add it to the layer
        commitment_loss = self.beta * tf.reduce_sum(
            (tf.stop_gradient(quantized) - x) ** 2
        )
        codebook_loss = tf.reduce_sum((quantized - tf.stop_gradient(x)) ** 2)
        self.add_loss(commitment_loss + codebook_loss)

        # Straight-through estimator (copy gradients through the undiferentiable layer)
        quantized = x + tf.stop_gradient(quantized - x)

        return quantized, soft_counts

    def get_code_indices(
        self, flattened_inputs, return_soft_counts=False
    ):  # pragma: no cover
        """

        Getter for the code indices at any given time.

        Args:
            input_shape (tf.Tensor): input shape
            flattened_inputs (tf.Tensor): flattened input tensor (encoder output)
            return_soft_counts (bool): whether to return soft counts based on the distance to the codes, instead of
            the code indices

        Returns:
            encoding_indices (tf.Tensor): code indices tensor with cluster assignments.

        """
        # Compute L2-norm distance between inputs and codes at a given time
        similarity = tf.matmul(flattened_inputs, self.codebook)
        distances = (
            tf.reduce_sum(flattened_inputs ** 2, axis=1, keepdims=True)
            + tf.reduce_sum(self.codebook ** 2, axis=0)
            - 2 * similarity
        )

        if return_soft_counts:
            # Compute soft counts based on the distance to the codes
            similarity = (1 / distances) ** 2
            soft_counts = similarity / tf.expand_dims(
                tf.reduce_sum(similarity, axis=1), axis=1
            )
            return soft_counts

        # Return index of the closest code
        encoding_indices = tf.argmin(distances, axis=1)
        return encoding_indices


# noinspection PyCallingNonCallable
def get_vqvae(
    input_shape: tuple,
    latent_dim: int,
    n_components: int,
    beta: float = 1.0,
    reg_gram: float = 0.0,
    phenotype_prediction_loss: float = 0.0,
    phenotype_num_labels: int = None,
    conv_filters=64,
    dense_activation="relu",
    gru_units_1=32,
    gru_unroll=False,
    bidirectional_merge="concat",
):
    """

    Builds a Vector-Quantization variational autoencoder (VQ-VAE) model, adapted to the DeepOF setting.

    Args:
        input_shape (tuple): shape of the input to the encoder.
        latent_dim (int): dimension of the latent space.
        n_components (int): number of embeddings in the embedding layer.
        beta (float): beta parameter of the VQ loss.
        reg_gram (float): regularization parameter for the Gram matrix.
        phenotype_prediction_loss (float): weight of the phenotype prediction loss. Defaults to 0.0.
        phenotype_num_labels (int): number of labels for the phenotype prediction loss. Defaults to None.
        conv_filters (int): number of filters in the first convolutional layers ib both encoder and decoder.
        dense_activation (str): activation function for the dense layers in both encoder and decoder. Defaults to "relu".
        gru_units_1 (int): number of units in the first GRU layer in both encoder and decoder. Defaults to 128.
        gru_unroll (bool): whether to unroll the GRU layers. Defaults to False.
        bidirectional_merge (str): how to merge the forward and backward GRU layers. Defaults to "concat".

    Returns:
        encoder (tf.keras.Model): connected encoder of the VQ-VAE model.
        Outputs a vector of shape (latent_dim,).
        decoder (tf.keras.Model): connected decoder of the VQ-VAE model.
        quantizer (tf.keras.Model): connected embedder layer of the VQ-VAE model.
        Outputs cluster indices of shape (batch_size,).
        vqvae (tf.keras.Model): complete VQ VAE model.

    """
    vq_layer = VectorQuantizer(
        n_components, latent_dim, beta=beta, reg_gram=reg_gram, name="vector_quantizer",
    )
    encoder = get_deepof_encoder(
        input_shape=input_shape,
        latent_dim=latent_dim,
        conv_filters=conv_filters,
        dense_activation=dense_activation,
        gru_units_1=gru_units_1,
        gru_unroll=gru_unroll,
        bidirectional_merge=bidirectional_merge,
    )
    decoder = get_deepof_decoder(
        input_shape=input_shape,
        latent_dim=latent_dim,
        conv_filters=conv_filters,
        dense_activation=dense_activation,
        gru_units_1=gru_units_1,
        gru_unroll=gru_unroll,
        bidirectional_merge=bidirectional_merge,
    )

    # Connect encoder and quantizer
    inputs = tf.keras.layers.Input(input_shape, name="encoder_input")
    encoder_outputs = encoder(inputs)
    quantized_latents, soft_counts = vq_layer(encoder_outputs)

    # Connect full models
    encoder = tf.keras.Model(inputs, encoder_outputs, name="encoder")
    quantizer = tf.keras.Model(inputs, quantized_latents, name="quantizer")
    soft_quantizer = tf.keras.Model(inputs, soft_counts, name="soft_quantizer")
    vqvae = tf.keras.Model(
        quantizer.inputs, decoder([quantizer.outputs, inputs]), name="VQ-VAE"
    )

    models = [encoder, decoder, quantizer, soft_quantizer, vqvae]

    # If phenotype prediction loss is not zero, add a phenotype prediction classifier
    if phenotype_prediction_loss > 0.0:
        phenotype_predictor = tf.keras.layers.Dense(
            units=tfpl.IndependentBernoulli.params_size(phenotype_num_labels),
            activation=dense_activation,
            kernel_regularizer=tf.keras.regularizers.l2(0.01),
            name="phenotype_predictor_dense_1",
        )(quantized_latents)
        phenotype_predictor = tfpl.IndependentBernoulli(1, name="phenotype_predictor")(
            phenotype_predictor
        )
        phenotype_predictor = tf.keras.Model(
            quantizer.inputs, phenotype_predictor, name="phenotype_predictor"
        )
        models.append(phenotype_predictor)

    return models


class VQVAE(tf.keras.models.Model):
    """

    VQ-VAE model adapted to the DeepOF setting.

    """

    def __init__(
        self,
        input_shape: tuple,
        latent_dim: int = 4,
        n_components: int = 15,
        beta: float = 1.0,
        reg_gram: float = 0.0,
        phenotype_prediction_loss: float = 0.0,
        phenotype_num_labels: int = None,
        architecture_hparams: dict = None,
        **kwargs,
    ):
        """

        Initializes a VQ-VAE model.

        Args:
            input_shape (tuple): Shape of the input to the full model.
            latent_dim (int): Dimensionality of the latent space.
            n_components (int): Number of embeddings (clusters) in the embedding layer.
            beta (float): Beta parameter of the VQ loss, as described in the original VQVAE paper.
            reg_gram (float): Regularization parameter for the Gram matrix.
            phenotype_prediction_loss (float): Weight of the phenotype prediction loss.
            phenotype_num_labels (int): Number of labels for the phenotype prediction task.
            architecture_hparams (dict): Dictionary of architecture hyperparameters. Defaults to None.
            **kwargs: Additional keyword arguments.

        """

        super(VQVAE, self).__init__(**kwargs)
        self.seq_shape = input_shape[1:]
        self.latent_dim = latent_dim
        self.n_components = n_components
        self.beta = beta
        self.reg_gram = reg_gram
        self.phenotype_prediction_loss = phenotype_prediction_loss
        self.phenotype_num_labels = phenotype_num_labels
        self.architecture_hparams = architecture_hparams

        # Define VQ_VAE model
        models = get_vqvae(
            self.seq_shape,
            self.latent_dim,
            self.n_components,
            self.beta,
            self.reg_gram,
            self.phenotype_prediction_loss,
            self.phenotype_num_labels,
            conv_filters=self.hparams["conv_filters"],
            dense_activation=self.hparams["dense_activation"],
            gru_units_1=self.hparams["gru_units_1"],
            gru_unroll=self.hparams["gru_unroll"],
            bidirectional_merge=self.hparams["bidirectional_merge"],
        )
        if phenotype_prediction_loss > 0.0:
            self.phenotype_predictor = models[-1]
            models = models[:-1]

        (
            self.encoder,
            self.decoder,
            self.quantizer,
            self.soft_quantizer,
            self.vqvae,
        ) = models

        # Define metrics to track
        self.total_loss_tracker = tf.keras.metrics.Mean(name="total_loss")
        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(
            name="reconstruction_loss"
        )
        self.vq_loss_tracker = tf.keras.metrics.Mean(name="vq_loss")
        self.cluster_population = tf.keras.metrics.Mean(
            name="number_of_populated_clusters"
        )
        self.val_total_loss_tracker = tf.keras.metrics.Mean(name="total_loss")
        self.val_reconstruction_loss_tracker = tf.keras.metrics.Mean(
            name="reconstruction_loss"
        )
        self.val_vq_loss_tracker = tf.keras.metrics.Mean(name="vq_loss")
        self.val_cluster_population = tf.keras.metrics.Mean(
            name="number_of_populated_clusters"
        )
        if self.phenotype_prediction_loss > 0.0:
            self.phenotype_prediction_loss_tracker = tf.keras.metrics.Mean(
                name="phenotype_prediction_loss"
            )
            self.val_phenotype_prediction_loss_tracker = tf.keras.metrics.Mean(
                name="phenotype_prediction_loss"
            )

    @tf.function
    def call(self, inputs, **kwargs):
        return self.vqvae(inputs, **kwargs)

    @property
    def metrics(self):  # pragma: no cover
        metrics = [
            self.total_loss_tracker,
            self.reconstruction_loss_tracker,
            self.vq_loss_tracker,
            self.cluster_population,
            self.val_total_loss_tracker,
            self.val_reconstruction_loss_tracker,
            self.val_vq_loss_tracker,
            self.val_cluster_population,
        ]
        if self.phenotype_prediction_loss > 0.0:
            metrics.append(self.phenotype_prediction_loss_tracker)

        return metrics

    @property
    def hparams(self):
        hparams = {
            "conv_filters": 64,
            "dense_activation": "relu",
            "gru_units_1": 32,
            "gru_unroll": False,
            "bidirectional_merge": "concat",
        }
        if self.architecture_hparams is not None:
            hparams.update(self.architecture_hparams)

        return hparams

    @tf.function
    def train_step(self, data):  # pragma: no cover
        """

        Performs a training step.

        """

        # Unpack data, repacking labels into a generator
        x, y = data
        if not isinstance(y, tuple):
            y = [y]
        y = (labels for labels in y)

        with tf.GradientTape() as tape:
            # Get outputs from the full model
            reconstructions = self.vqvae(x, training=True)

            # Compute losses
            reconstruction_loss = -tf.reduce_sum(reconstructions.log_prob(next(y)))
            total_loss = reconstruction_loss + sum(self.vqvae.losses)

            # Add phenotype prediction loss if it is defined
            if self.phenotype_prediction_loss > 0.0:
                phenotype_prediction_loss = self.phenotype_predictor(
                    x, training=True
                ).log_prob(next(y))
                total_loss += phenotype_prediction_loss

        # Backpropagation
        grads = tape.gradient(total_loss, self.vqvae.trainable_variables)
        self.optimizer.apply_gradients(zip(grads, self.vqvae.trainable_variables))

        # Compute populated clusters
        unique_indices = tf.unique(
            tf.reshape(tf.argmax(self.soft_quantizer(x), axis=1), [-1])
        ).y
        populated_clusters = tf.shape(unique_indices)[0]

        # Track losses
        self.total_loss_tracker.update_state(total_loss)
        self.reconstruction_loss_tracker.update_state(reconstruction_loss)
        self.vq_loss_tracker.update_state(sum(self.vqvae.losses))
        self.cluster_population.update_state(populated_clusters)

        # Log results (coupled with TensorBoard)
        log_dict = {
            "total_loss": self.total_loss_tracker.result(),
            "reconstruction_loss": self.reconstruction_loss_tracker.result(),
            "vq_loss": self.vq_loss_tracker.result(),
            "number_of_populated_clusters": self.cluster_population.result(),
        }

        if self.phenotype_prediction_loss > 0.0:
            # noinspection PyUnboundLocalVariable
            self.phenotype_prediction_loss_tracker.update_state(
                phenotype_prediction_loss
            )
            log_dict[
                "phenotype_prediction_loss"
            ] = self.phenotype_prediction_loss_tracker.result()

        return {**log_dict, **{met.name: met.result() for met in self.vqvae.metrics}}

    @tf.function
    def test_step(self, data):  # pragma: no cover
        """

        Performs a test step.

        """

        # Unpack data, repacking labels into a generator
        x, y = data
        if not isinstance(y, tuple):
            y = [y]
        y = (labels for labels in y)

        # Get outputs from the full model
        reconstructions = self.vqvae(x, training=False)

        # Compute losses
        reconstruction_loss = -tf.reduce_sum(reconstructions.log_prob(next(y)))
        total_loss = reconstruction_loss + sum(self.vqvae.losses)

        # Add phenotype prediction loss if it is defined
        if self.phenotype_prediction_loss > 0.0:
            phenotype_prediction_loss = self.phenotype_predictor(
                x, training=False
            ).log_prob(next(y))
            total_loss += phenotype_prediction_loss

        # Compute populated clusters
        unique_indices = tf.unique(
            tf.reshape(tf.argmax(self.soft_quantizer(x), axis=1), [-1])
        ).y
        populated_clusters = tf.shape(unique_indices)[0]

        # Track losses
        self.val_total_loss_tracker.update_state(total_loss)
        self.val_reconstruction_loss_tracker.update_state(reconstruction_loss)
        self.val_vq_loss_tracker.update_state(sum(self.vqvae.losses))
        self.val_cluster_population.update_state(populated_clusters)

        # Log results (coupled with TensorBoard)
        log_dict = {
            "total_loss": self.val_total_loss_tracker.result(),
            "reconstruction_loss": self.val_reconstruction_loss_tracker.result(),
            "vq_loss": self.val_vq_loss_tracker.result(),
            "number_of_populated_clusters": self.val_cluster_population.result(),
        }

        if self.phenotype_prediction_loss > 0.0:
            # noinspection PyUnboundLocalVariable
            self.val_phenotype_prediction_loss_tracker.update_state(
                phenotype_prediction_loss
            )
            log_dict[
                "phenotype_prediction_loss"
            ] = self.val_phenotype_prediction_loss_tracker.result()

        return {**log_dict, **{met.name: met.result() for met in self.vqvae.metrics}}


# noinspection PyCallingNonCallable
# def get_vae(
#     input_shape: tuple,
#     latent_dim: int,
#     batch_size: int,
#     loss: str = "ELBO",
#     kl_warmup: int = 15,
#     kl_annealing_mode: str = "sigmoid",
#     mc_kl: int = 100,
#     reg_gram: float = 1.0,
#     phenotype_prediction_loss: float = 0.0,
#     phenotype_num_labels: int = None,
#     conv_filters=64,
#     dense_activation="relu",
#     gru_units_1=32,
#     gru_unroll=False,
#     bidirectional_merge="concat",
# ):
#     """
#
#     Builds a Gaussian mixture variational autoencoder (GMVAE) model, adapted to the DeepOF setting.
#
#     Args:
#             input_shape (tuple): shape of the input data
#             latent_dim (int): dimensionality of the latent space.
#             batch_size (int): batch size for training.
#             loss (str): loss function to use for training. Must be one of "SELBO", "MMD", or "SELBO+MMD".
#             kl_warmup (int): number of epochs to warm up the KL divergence.
#             kl_annealing_mode (str): mode to use for annealing the KL divergence. Must be one of "linear" and "sigmoid".
#             mc_kl (int): number of Monte Carlo samples to use for computing the KL divergence.
#             reg_gram (float): weight of the Gram matrix loss as described in deepof.unsupervised_utils.compute_gram_matrix.
#             model by enabling forecasting of the next sequence.
#             phenotype_prediction_loss (bool): weight of the phenotype prediction loss. Defaults to 0.0.
#             phenotype_num_labels (int): number of features in the supervised prediction label matrix.
#             Ignored if supervised prediction is null.
#             conv_filters (int): number of filters in the first convolutional layers ib both encoder and decoder.
#             dense_activation (str): activation function for the dense layers in both encoder and decoder. Defaults to "relu".
#             gru_units_1 (int): number of units in the first GRU layer in both encoder and decoder. Defaults to 128.
#             gru_unroll (bool): whether to unroll the GRU layers. Defaults to False.
#             bidirectional_merge (str): how to merge the forward and backward GRU layers. Defaults to "concat".
#
#     Returns:
#         encoder (tf.keras.Model): connected encoder of the VQ-VAE model.
#         Outputs a vector of shape (latent_dim,).
#         decoder (tf.keras.Model): connected decoder of the VQ-VAE model.
#         vae (tf.keras.Model): complete VAE model
#
#     """
#
#     encoder = get_deepof_encoder(
#         input_shape=input_shape[1:],
#         conv_filters=conv_filters,
#         dense_activation=dense_activation,
#         gru_units_1=gru_units_1,
#         gru_unroll=gru_unroll,
#         bidirectional_merge=bidirectional_merge,
#     )
#     latent_space = deepof.unsupervised_utils.GaussianMixtureLatent(
#         input_shape=input_shape[0],
#         n_components=n_components,
#         latent_dim=latent_dim,
#         batch_size=batch_size,
#         latent_loss=loss,
#         kl_warmup=kl_warmup,
#         kl_annealing_mode=kl_annealing_mode,
#         mc_kl=mc_kl,
#         mmd_warmup=mmd_warmup,
#         mmd_annealing_mode=mmd_annealing_mode,
#         n_cluster_loss=n_cluster_loss,
#         reg_gram=reg_gram,
#         reg_cat_clusters=reg_cat_clusters,
#         reg_cluster_variance=reg_cluster_variance,
#         name="gaussian_mixture_latent",
#     )
#     decoder = get_deepof_decoder(
#         input_shape=input_shape[1:],
#         latent_dim=latent_dim,
#         conv_filters=conv_filters,
#         dense_activation=dense_activation,
#         gru_units_1=gru_units_1,
#         gru_unroll=gru_unroll,
#         bidirectional_merge=bidirectional_merge,
#     )
#
#     # Connect encoder and latent space
#     inputs = Input(input_shape[1:])
#     encoder_outputs = encoder(inputs)
#     latent, categorical = latent_space(encoder_outputs)
#     embedding = tf.keras.Model(inputs, latent, name="encoder")
#     grouper = tf.keras.Model(inputs, categorical, name="grouper")
#
#     # Connect decoder
#     gmvae_outputs = [decoder([embedding.outputs, inputs])]
#
#     # Add additional (optional) branches departing from the latent space
#     if next_sequence_prediction:
#         predictor = get_deepof_decoder(
#             input_shape[1:],
#             latent_dim,
#             conv_filters=conv_filters,
#             dense_activation=dense_activation,
#             gru_units_1=gru_units_1,
#             gru_unroll=gru_unroll,
#             bidirectional_merge=bidirectional_merge,
#         )
#         predictor._name = "deepof_predictor"
#         gmvae_outputs.append(predictor([embedding.outputs, inputs]))
#
#     if (
#         phenotype_prediction_loss
#     ):  # Predict from cluster assignments instead of embedding itself!
#         pheno_pred = Dense(
#             latent_dim, activation="relu", kernel_initializer=he_uniform()
#         )(categorical)
#         pheno_pred = Dense(tfpl.IndependentBernoulli.params_size(1))(pheno_pred)
#         pheno_pred = tfpl.IndependentBernoulli(
#             event_shape=1,
#             convert_to_tensor_fn=tfp.distributions.Distribution.mean,
#             name="phenotype_prediction",
#         )(pheno_pred)
#
#         gmvae_outputs.append(pheno_pred)
#
#     if supervised_prediction:
#         supervised_trait_pred = Dense(
#             n_components,
#             activation="relu",
#             kernel_initializer=he_uniform(),
#         )(latent)
#         supervised_trait_pred = Dense(
#             tfpl.IndependentBernoulli.params_size(phenotype_num_labels)
#         )(supervised_trait_pred)
#         supervised_trait_pred = tfpl.IndependentBernoulli(
#             event_shape=phenotype_num_labels,
#             convert_to_tensor_fn=tfp.distributions.Distribution.mean,
#             name="supervised_prediction",
#         )(supervised_trait_pred)
#         gmvae_outputs.append(supervised_trait_pred)
#
#     # Instantiate fully connected model
#     gmvae = tf.keras.Model(embedding.inputs, gmvae_outputs, name="GMVAE")
#
#     return (
#         embedding,
#         decoder,
#         grouper,
#         gmvae,
#     )
#
#
# # noinspection PyDefaultArgument,PyCallingNonCallable
# class VAE(tf.keras.models.Model):
#     """
#
#     Recurrent variational Autoencoder for pose motif elucidation.
#
#     """
#
#     def __init__(
#         self,
#         input_shape: tuple,
#         batch_size: int = 64,
#         latent_dim: int = 4,
#         kl_annealing_mode: str = "sigmoid",
#         kl_warmup_epochs: int = 15,
#         montecarlo_kl: int = 1000,
#         reg_gram: float = 1.0,
#         phenotype_prediction_loss: float = 0.0,
#         phenotype_num_labels: int = 6,
#         architecture_hparams: dict = None,
#         **kwargs,
#     ):
#         """
#
#         Initalizes a GMVAE model.
#
#         Args:
#             input_shape (tuple): Shape of the input to the full model.
#             batch_size (int): Batch size for training.
#             latent_dim (int): Dimensionality of the latent space.
#             kl_annealing_mode (str): Annealing mode for KL annealing. Can be one of 'linear' and 'sigmoid'.
#             kl_warmup_epochs (int): Number of epochs to warmup KL annealing.
#             montecarlo_kl (int): Number of Monte Carlo samples for KL divergence.
#             reg_gram (float): weight of the gram matrix regularization loss.
#             next_sequence_prediction (bool): whether to add a next sequence prediction loss, which regularizes the
#             model by enabling forecasting of the next sequence.
#             phenotype_prediction_loss (bool): weight of the phenotype prediction loss. Defaults to 0.0.
#             phenotype_num_labels (int): number of features in the supervised prediction label matrix.
#             Ignored if supervised prediction is null.
#             architecture_hparams (dict): dictionary of hyperparameters for the architecture. Defaults to None.
#             **kwargs:
#
#         """
#         super(VAE, self).__init__(**kwargs)
#         self.seq_shape = input_shape
#         self.batch_size = batch_size
#         self.latent_dim = latent_dim
#         self.kl_annealing_mode = kl_annealing_mode
#         self.kl_warmup = kl_warmup_epochs
#         self.mc_kl = montecarlo_kl
#         self.optimizer = Nadam(learning_rate=1e-4, clipvalue=0.75)
#         self.reg_gram = reg_gram
#         self.phenotype_prediction = phenotype_prediction_loss
#         self.supervised_features = phenotype_num_labels
#         self.architecture_hparams = architecture_hparams
#
#         assert (
#             "SIWAE" in self.latent_loss
#             or "SELBO" in self.latent_loss
#             or "MMD" in self.latent_loss
#         ), "loss must be one of SIWAE, SELBO (default), MMD, SIWAE+MMD, or SELBO+MMD"
#
#         # Define GMVAE model
#         self.encoder, self.decoder, self.vae = get_vae(
#             input_shape=self.seq_shape,
#             latent_dim=self.latent_dim,
#             batch_size=self.batch_size,
#             loss=self.latent_loss,
#             kl_warmup=self.kl_warmup,
#             kl_annealing_mode=self.kl_annealing_mode,
#             mc_kl=self.mc_kl,
#             reg_gram=self.reg_gram,
#             phenotype_prediction_loss=self.phenotype_prediction,
#             phenotype_num_labels=self.supervised_features,
#             conv_filters=self.hparams["conv_filters"],
#             dense_activation=self.hparams["dense_activation"],
#             gru_units_1=self.hparams["gru_units_1"],
#             gru_unroll=self.hparams["gru_unroll"],
#             bidirectional_merge=self.hparams["bidirectional_merge"],
#         )
#         # Propagate the optimizer to all relevant sub-models, to enable metric annealing
#         self.vae.optimizer = self.optimizer
#         self.vae.get_layer("gaussian_mixture_latent").optimizer = self.optimizer
#
#         # Define metrics to track
#
#         # Track all loss function components
#         self.total_loss_tracker = tf.keras.metrics.Mean(name="total_loss")
#         self.val_total_loss_tracker = tf.keras.metrics.Mean(name="total_loss")
#
#         if "SIWAE" not in self.latent_loss:
#             self.reconstruction_loss_tracker = tf.keras.metrics.Mean(
#                 name="reconstruction_loss"
#             )
#             self.val_reconstruction_loss_tracker = tf.keras.metrics.Mean(
#                 name="reconstruction_loss"
#             )
#         if "SIWAE" in self.latent_loss:
#             self.siwae_loss_tracker = tf.keras.metrics.Mean(name="siwae_loss")
#             self.val_siwae_loss_tracker = tf.keras.metrics.Mean(name="siwae_loss")
#         if "SELBO" in self.latent_loss:
#             self.kl_loss_weight_tracker = tf.keras.metrics.Mean(name="kl_weight")
#             self.val_kl_loss_weight_tracker = tf.keras.metrics.Mean(name="kl_weight")
#         if "MMD" in self.latent_loss:
#             self.mmd_loss_weight_tracker = tf.keras.metrics.Mean(name="mmd_weight")
#             self.val_mmd_loss_weight_tracker = tf.keras.metrics.Mean(name="mmd_weight")
#         if self.next_sequence_prediction:
#             self.next_sequence_loss_tracker = tf.keras.metrics.Mean(
#                 name="next_sequence_loss"
#             )
#             self.val_next_sequence_loss_tracker = tf.keras.metrics.Mean(
#                 name="next_sequence_loss"
#             )
#         if self.phenotype_prediction:
#             self.phenotype_loss_tracker = tf.keras.metrics.Mean(name="phenotype_loss")
#             self.val_phenotype_loss_tracker = tf.keras.metrics.Mean(
#                 name="phenotype_loss"
#             )
#         if self.supervised_prediction:
#             self.supervised_loss_tracker = tf.keras.metrics.Mean(name="supervised_loss")
#             self.val_supervised_loss_tracker = tf.keras.metrics.Mean(
#                 name="supervised_loss"
#             )
#
#     @property
#     def metrics(self):  # pragma: no cover
#         metrics = [
#             self.total_loss_tracker,
#             self.val_total_loss_tracker,
#         ]
#         if "SIWAE" not in self.latent_loss:
#             metrics += [self.reconstruction_loss_tracker]
#             metrics += [self.val_reconstruction_loss_tracker]
#         if "SIWAE" in self.latent_loss:
#             metrics += [self.siwae_loss_tracker]
#             metrics += [self.val_siwae_loss_tracker]
#         if "SELBO" in self.latent_loss:
#             metrics += [self.kl_loss_weight_tracker]
#             metrics += [self.val_kl_loss_weight_tracker]
#         if "MMD" in self.latent_loss:
#             metrics += [self.mmd_loss_weight_tracker]
#             metrics += [self.val_mmd_loss_weight_tracker]
#         if self.next_sequence_prediction:
#             metrics += [
#                 self.next_sequence_loss_tracker,
#                 self.val_next_sequence_loss_tracker,
#             ]
#         if self.phenotype_prediction:
#             metrics += [self.phenotype_loss_tracker, self.val_phenotype_loss_tracker]
#         if self.supervised_prediction:
#             metrics += [self.supervised_loss_tracker, self.val_supervised_loss_tracker]
#
#         metrics += self.gmvae.metrics
#
#         return metrics
#
#     @property
#     def hparams(self):
#         hparams = {
#             "conv_filters": 64,
#             "dense_activation": "relu",
#             "gru_units_1": 32,
#             "gru_unroll": True,
#             "bidirectional_merge": "concat",
#         }
#         if self.architecture_hparams is not None:
#             hparams.update(self.architecture_hparams)
#
#         return hparams
#
#     @property
#     def prior(self):
#         """
#
#         Property to retrieve the current's model prior
#
#         """
#
#         return self.gmvae.get_layer("gaussian_mixture_latent").prior
#
#     @tf.function
#     def call(self, inputs, **kwargs):
#         return self.gmvae(inputs, **kwargs)
#
#     @tf.function
#     def train_step(self, data):  # pragma: no cover
#         """
#
#         Performs a training step.
#
#         """
#
#         # Unpack data, repacking labels into a generator
#         x, y = data
#         if not isinstance(y, tuple):
#             y = [y]
#         y = (labels for labels in y)
#
#         with tf.GradientTape() as tape:
#             # Get outputs from the full model
#             outputs = self.gmvae(x, training=True)
#             if isinstance(outputs, list):
#                 reconstructions = outputs[0]
#             else:
#                 reconstructions = outputs
#
#             # Compute losses
#             seq_inputs = next(y)
#             total_loss = sum(self.gmvae.losses)
#
#             if "SIWAE" not in self.latent_loss:
#                 reconstruction_loss = -tf.reduce_sum(
#                     reconstructions.log_prob(seq_inputs)
#                 )
#                 total_loss += reconstruction_loss
#
#             if "SIWAE" in self.latent_loss:
#                 siwae_loss = deepof.unsupervised_utils.compute_siwae(
#                     self.prior,
#                     self.gmvae,
#                     self.encoder,
#                     seq_inputs,
#                     self.n_components,
#                 )
#                 total_loss += siwae_loss
#
#             if self.next_sequence_prediction:
#                 next_seq_predictions = [
#                     out for out in outputs if "predictor" in out.name
#                 ][0]
#                 next_seq_loss = -tf.reduce_sum(next_seq_predictions.log_prob(next(y)))
#                 total_loss += self.next_sequence_prediction * next_seq_loss
#             if self.phenotype_prediction:
#                 pheno_predictions = [out for out in outputs if "phenotype" in out.name][
#                     0
#                 ]
#                 phenotype_loss = -tf.reduce_sum(pheno_predictions.log_prob(next(y)))
#                 total_loss += self.phenotype_prediction * phenotype_loss
#             if self.supervised_prediction:
#                 sup_predictions = [out for out in outputs if "supervised" in out.name][
#                     0
#                 ]
#                 supervised_loss = -tf.reduce_sum(sup_predictions.log_prob(next(y)))
#                 total_loss += self.supervised_prediction * supervised_loss
#
#         # Backpropagation
#         grads = tape.gradient(total_loss, self.gmvae.trainable_variables)
#         self.optimizer.apply_gradients(zip(grads, self.gmvae.trainable_variables))
#
#         # Track losses
#         self.total_loss_tracker.update_state(total_loss)
#         if "SIWAE" not in self.latent_loss:
#             self.reconstruction_loss_tracker.update_state(reconstruction_loss)
#         if "SIWAE" in self.latent_loss:
#             self.siwae_loss_tracker.update_state(siwae_loss)
#         if "SELBO" in self.latent_loss:
#             # noinspection PyProtectedMember
#             self.kl_loss_weight_tracker.update_state(
#                 self.gmvae.get_layer("gaussian_mixture_latent").kl_layer._kl_weight
#             )
#         if "MMD" in self.latent_loss:
#             # noinspection PyProtectedMember
#             self.mmd_loss_weight_tracker.update_state(
#                 self.gmvae.get_layer("gaussian_mixture_latent").mmd_layer._mmd_weight
#             )
#         if self.next_sequence_prediction:
#             self.next_sequence_loss_tracker.update_state(next_seq_loss)
#         if self.phenotype_prediction:
#             self.phenotype_loss_tracker.update_state(phenotype_loss)
#         if self.supervised_prediction:
#             self.supervised_loss_tracker.update_state(supervised_loss)
#
#         # Log results (coupled with TensorBoard)
#         log_dict = {
#             "total_loss": self.total_loss_tracker.result(),
#         }
#
#         # Add optional metrics to final log dict
#         if "SIWAE" not in self.latent_loss:
#             log_dict["reconstruction_loss"] = self.reconstruction_loss_tracker.result()
#         if "SIWAE" in self.latent_loss:
#             log_dict["siwae_loss"] = self.siwae_loss_tracker.result()
#         if "SELBO" in self.latent_loss:
#             log_dict["kl_weight"] = self.kl_loss_weight_tracker.result()
#         if "MMD" in self.latent_loss:
#             log_dict["mmd_weight"] = self.mmd_loss_weight_tracker.result()
#         if self.next_sequence_prediction:
#             log_dict["next_sequence_loss"] = self.next_sequence_loss_tracker.result()
#         if self.phenotype_prediction:
#             log_dict["phenotype_loss"] = self.phenotype_loss_tracker.result()
#         if self.supervised_prediction:
#             log_dict["supervised_loss"] = self.supervised_loss_tracker.result()
#
#         # Log to TensorBoard, both explitly and implicitly (within model) tracked metrics
#         return {**log_dict, **{met.name: met.result() for met in self.gmvae.metrics}}
#
#     # noinspection PyUnboundLocalVariable
#     @tf.function
#     def test_step(self, data):  # pragma: no cover
#         """
#
#         Performs a test step.
#
#         """
#
#         # Unpack data, repacking labels into a generator
#         x, y = data
#         if not isinstance(y, tuple):
#             y = [y]
#         y = (labels for labels in y)
#
#         # Get outputs from the full model
#         outputs = self.gmvae(x, training=False)
#         if isinstance(outputs, list):
#             reconstructions = outputs[0]
#         else:
#             reconstructions = outputs
#
#         # Compute losses
#         seq_inputs = next(y)
#         total_loss = sum(self.gmvae.losses)
#
#         if "SIWAE" not in self.latent_loss:
#             reconstruction_loss = -tf.reduce_sum(reconstructions.log_prob(seq_inputs))
#             total_loss += reconstruction_loss
#
#         if "SIWAE" in self.latent_loss:
#             siwae_loss = deepof.unsupervised_utils.compute_siwae(
#                 self.prior,
#                 self.gmvae,
#                 self.encoder,
#                 seq_inputs,
#                 self.n_components,
#             )
#             total_loss += siwae_loss
#
#         if self.next_sequence_prediction:
#             next_seq_predictions = [out for out in outputs if "predictor" in out.name][
#                 0
#             ]
#             next_seq_loss = -tf.reduce_sum(next_seq_predictions.log_prob(next(y)))
#             total_loss += self.next_sequence_prediction * next_seq_loss
#         if self.phenotype_prediction:
#             pheno_predictions = [out for out in outputs if "phenotype" in out.name][0]
#             phenotype_loss = -tf.reduce_sum(pheno_predictions.log_prob(next(y)))
#             total_loss += self.phenotype_prediction * phenotype_loss
#         if self.supervised_prediction:
#             sup_predictions = [out for out in outputs if "supervised" in out.name][0]
#             supervised_loss = -tf.reduce_sum(sup_predictions.log_prob(next(y)))
#             total_loss += self.supervised_prediction * supervised_loss
#
#         # Track losses
#         self.val_total_loss_tracker.update_state(total_loss)
#         if "SIWAE" not in self.latent_loss:
#             self.val_reconstruction_loss_tracker.update_state(reconstruction_loss)
#         if "SIWAE" in self.latent_loss:
#             self.val_siwae_loss_tracker.update_state(siwae_loss)
#         if "SELBO" in self.latent_loss:
#             self.val_kl_loss_weight_tracker.update_state(
#                 self.gmvae.get_layer("gaussian_mixture_latent").kl_layer._kl_weight
#             )
#         if "MMD" in self.latent_loss:
#             self.val_mmd_loss_weight_tracker.update_state(
#                 # noinspection PyProtectedMember
#                 self.mmd_loss_weight_tracker.update_state(
#                     self.gmvae.get_layer(
#                         "gaussian_mixture_latent"
#                     ).mmd_layer._mmd_weight
#                 )
#             )
#         if self.next_sequence_prediction:
#             self.val_next_sequence_loss_tracker.update_state(next_seq_loss)
#         if self.phenotype_prediction:
#             self.val_phenotype_loss_tracker.update_state(phenotype_loss)
#         if self.supervised_prediction:
#             self.val_supervised_loss_tracker.update_state(supervised_loss)
#
#         # Log results (coupled with TensorBoard)
#         log_dict = {
#             "total_loss": self.val_total_loss_tracker.result(),
#         }
#
#         # Add optional metrics to final log dict
#         if "SIWAE" not in self.latent_loss:
#             log_dict[
#                 "reconstruction_loss"
#             ] = self.val_reconstruction_loss_tracker.result()
#         if self.next_sequence_prediction:
#             log_dict[
#                 "next_sequence_loss"
#             ] = self.val_next_sequence_loss_tracker.result()
#         if self.phenotype_prediction:
#             log_dict["phenotype_loss"] = self.val_phenotype_loss_tracker.result()
#         if self.supervised_prediction:
#             log_dict["supervised_loss"] = self.val_supervised_loss_tracker.result()
#
#         return {**log_dict, **{met.name: met.result() for met in self.gmvae.metrics}}
