{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2b46f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../../..\")\n",
    "import deepof.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e85be887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ed73656",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d41506e",
   "metadata": {},
   "source": [
    "# DeepOF unsupervised pipeline: exploring the behavioral space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e24f1d",
   "metadata": {},
   "source": [
    "##### Tutorial index:\n",
    "    \n",
    "* Brief introduction to unsupervised analysis.\n",
    "* Load your previous project.\n",
    "* Running an unsupervised analysis with default parameters.\n",
    "* Understanding the different available models.\n",
    "* Temporal and global embeddings.\n",
    "* Global separation dynamics.\n",
    "* Exploring cluster enrichment across conditions.\n",
    "* Exploring cluster dynamics across conditions.\n",
    "* Interpreting clusters using SHAP.\n",
    "* Exporting cluster video snippets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366bcf28",
   "metadata": {},
   "source": [
    "### Brief introduction to unsupervised analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58a7f23",
   "metadata": {},
   "source": [
    "### Load your previous project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ce3f645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# SI data\n",
    "my_deepof_project = deepof.data.load_project(\"../../Desktop/deepOF_CSDS_tutorial_dataset/deepof_tutorial\")\n",
    "with open(\"deepof_SI_exp_conds.pkl\", \"rb\") as handle:\n",
    "    exp_conds = pickle.load(handle)\n",
    "my_deepof_project._exp_conditions = {\n",
    "    key: val for key, val in exp_conds.items() if key in my_deepof_project.get_quality().keys()\n",
    "}\n",
    "\n",
    "# Update project path to a local path\n",
    "my_deepof_project._project_path = \"../../Desktop/deepOF_CSDS_tutorial_dataset\"\n",
    "my_deepof_project._project_name = \"deepof_tutorial\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52430042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS SHOULD BE THE LAST SECTION OF THE FIRST TUTORIAL!\n",
    "\n",
    "# Check scales across animals. Can we detect to which animal a given time series belongs to?\n",
    "# Once happy with a solution, check that all animals show comparable cluster interpretations.\n",
    "\n",
    "# Add preprocessing options to include multiple animals, concatenated and together in a graph\n",
    "\n",
    "coords = my_deepof_project.get_coords(selected_id=\"B\", center=\"Center\", align=\"Spine_1\")\n",
    "preprocessed_coords, global_scaler = coords.preprocess(\n",
    "    window_size=25,\n",
    "    window_step=1,\n",
    "    test_videos=1,\n",
    "    scale=\"standard\",\n",
    "    handle_ids=\"concat\", # \"concat\" uses bps from != animals as features, \"split\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85d25a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAME HERE: Last section of the last tutorial should explore tensor and graph preprocessing\n",
    "from deepof.utils import connect_mouse_topview\n",
    "import networkx as nx\n",
    "\n",
    "graph_preprocessed_coords, G, to_preprocess, global_scaler = my_deepof_project.get_graph_dataset(\n",
    "    animal_id=\"B\",\n",
    "    center=\"Center\",\n",
    "    align=\"Spine_1\",\n",
    "    window_size=25,\n",
    "    window_step=1,\n",
    "    preprocess=True,\n",
    "    scale=\"standard\"\n",
    ")\n",
    "\n",
    "adjacency_matrix = nx.adjacency_matrix(G).todense()\n",
    "\n",
    "# with open(\"graph_processed_dataset.pkl\", \"wb\") as handle:\n",
    "#     pickle.dump([pp, G, to_preprocess, global_scaler], handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515bc6d3",
   "metadata": {},
   "source": [
    "### Running an unsupervised analysis with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64d50a7e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 16:12:49.147827: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2023-03-09 16:12:49.147843: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "2023-03-09 16:12:49.147926: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2023-03-09 16:13:07.553498: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-03-09 16:14:23.075577: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-03-09 16:15:25.050855: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-03-09 16:16:29.126599: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-03-09 16:17:42.641887: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-03-09 16:18:59.449624: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-03-09 16:20:07.189983: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-03-09 16:21:22.096617: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-03-09 16:22:39.455532: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-03-09 16:23:46.522248: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-03-09 16:25:12.363044: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-03-09 16:25:24.738250: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2023-03-09 16:25:24.738291: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "2023-03-09 16:25:26.533137: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
      "2023-03-09 16:25:26.592699: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2023-03-09 16:25:26.615717: I tensorflow/core/profiler/rpc/client/save_profile.cc:164] Collecting XSpace to repository: /Users/lucas_miranda/Desktop/deepOF_CSDS_tutorial_dataset/Trained_models/fit/deepof_unsupervised_VaDE_recurrent_encodings_input_type=coords_kmeans_loss=0.0_encoding=8_k=10_20230309-161249/plugins/profile/2023_03_09_16_25_26/MC-C9791E.local.xplane.pb\n",
      "2023-03-09 16:26:36.434925: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-03-09 16:27:48.307613: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-03-09 16:28:52.424925: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-03-09 16:29:47.508264: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-03-09 16:30:40.162652: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-03-09 16:31:36.863247: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-03-09 16:32:37.344567: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-03-09 16:33:48.415658: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-03-09 16:34:41.070395: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-03-09 16:35:25.305897: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 30min 14s, sys: 31min 3s, total: 2h 1min 18s\n",
      "Wall time: 22min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trained_model = my_deepof_project.deep_unsupervised_embedding(\n",
    "    graph_preprocessed_coords, # Change to preprocessed_coords to use non-graph embeddings\n",
    "    adjacency_matrix=adjacency_matrix,\n",
    "    embedding_model=\"VaDE\", # Can also be set to VQVAE and Contrastive\n",
    "    epochs=10,\n",
    "    encoder_type=\"recurrent\", # Can also be set to TCN and transformer\n",
    "    n_components=10,\n",
    "    latent_dim=8,\n",
    "    kl_warmup=10,\n",
    "    kl_annealing_mode=\"linear\",\n",
    "    batch_size=1024,\n",
    "    kmeans_loss=0.0,\n",
    "    reg_cat_clusters=0.0,\n",
    "    verbose=False, # Set to True to follow the training loop\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a8fde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                     | 0/6 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Get embeddings, soft_counts, and breaks per video\n",
    "embeddings, soft_counts, breaks = deepof.model_utils.embedding_per_video(\n",
    "    my_deepof_project,\n",
    "    to_preprocess, \n",
    "    trained_model,\n",
    "    animal_id=\"B\",\n",
    "    global_scaler=global_scaler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f581f691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load results\n",
    "# import pickle\n",
    "# with open(\n",
    "#     \"NatComm_trained_sadeepOF_SI/deepof_unsupervised_VaDE_encoder_recurrent_encodings_input=graph_k=10_latdim=8_changepoints_False_kmeans_loss=0.0_run=0.pkl\", \"rb\"\n",
    "# ) as handle:\n",
    "#     embeddings, soft_counts, breaks = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027e584b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = {key: val.numpy() for key, val in embeddings.items()}\n",
    "# soft_counts = {key: val.numpy() for key, val in soft_counts.items()}\n",
    "# breaks = {key: np.ones(soft_counts[key].shape[0]).astype(int) for key in soft_counts.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa43e0b",
   "metadata": {},
   "source": [
    "### Understanding the different available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff9e992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cons.vade.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3175278c",
   "metadata": {},
   "source": [
    "### Visualizing temporal and global embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2ad890",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# INCORPORATE AS A METHOD FOR EACH MODEL\n",
    "# embeddings, soft_counts, breaks = deepof.model_utils.embedding_per_video(my_deepof_project, to_preprocess, cons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa50ace5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "deepof.visuals.plot_embeddings(\n",
    "    my_deepof_project, \n",
    "    embeddings, \n",
    "    soft_counts,\n",
    "    breaks,\n",
    "    aggregate_experiments=False,\n",
    "    samples=500,\n",
    "    ax=ax1,\n",
    "    save=False, # Set to True, or give a custom name, to save the plot\n",
    ")\n",
    "\n",
    "deepof.visuals.plot_embeddings(\n",
    "    my_deepof_project,\n",
    "    embeddings, \n",
    "    soft_counts,\n",
    "    breaks,\n",
    "    aggregate_experiments=\"time on cluster\",\n",
    "    exp_condition=\"CSDS\",\n",
    "    show_aggregated_density=False,\n",
    "#     bin_index=4,\n",
    "#     bin_size=25*120,\n",
    "    ax=ax2,\n",
    "    save=False, # Set to True, or give a custom name, to save the plot,\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ae0e11",
   "metadata": {},
   "source": [
    "### Global separation dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6dc3ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "    \n",
    "deepof.visuals.plot_distance_between_conditions(\n",
    "    my_deepof_project,\n",
    "    embeddings,\n",
    "    soft_counts,\n",
    "    breaks,\n",
    "    \"CSDS\",\n",
    "    distance_metric=\"wasserstein\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2e4d1b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 16))\n",
    "\n",
    "\n",
    "for i, ax in zip(range(4), [ax1, ax2, ax3, ax4]):\n",
    "\n",
    "    deepof.visuals.plot_embeddings(\n",
    "        my_deepof_project,\n",
    "        embeddings, \n",
    "        soft_counts,\n",
    "        breaks,\n",
    "        aggregate_experiments=\"time on cluster\",\n",
    "        exp_condition=\"CSDS\",\n",
    "        show_aggregated_density=True,\n",
    "        bin_index=i,\n",
    "        bin_size=126,\n",
    "        ax=ax,\n",
    "        save=False, # Set to True, or give a custom name, to save the plot,\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec60eee",
   "metadata": {},
   "source": [
    "### Exploring cluster enrichment across conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2258e23",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "\n",
    "deepof.visuals.plot_cluster_enrichment(\n",
    "    my_deepof_project,\n",
    "    embeddings,\n",
    "    soft_counts,\n",
    "    breaks,\n",
    "    normalize=True,\n",
    "    bin_size=126,\n",
    "    bin_index=0,\n",
    "    add_stats=\"Mann-Whitney\",\n",
    "    exp_condition=\"CSDS\",\n",
    "    verbose=False,\n",
    "    ax=ax,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e61418",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "video = deepof.visuals.animate_skeleton(\n",
    "    my_deepof_project,\n",
    "    embedding=embeddings,\n",
    "    cluster_assignments=soft_counts,\n",
    "    experiment_id=\"20191204_Day2_SI_JB08_Test_54\",\n",
    "    frame_limit=150,\n",
    "    min_confidence=0.75,\n",
    "    selected_cluster=2,\n",
    "    dpi=60,\n",
    "    center=\"arena\",    \n",
    ")\n",
    "\n",
    "html = display.HTML(video)\n",
    "display.display(html)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ac4dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "video = deepof.visuals.animate_skeleton(\n",
    "    my_deepof_project,\n",
    "    embedding=embeddings,\n",
    "    cluster_assignments=soft_counts,\n",
    "    experiment_id=\"20191204_Day2_SI_JB08_Test_54\",\n",
    "    frame_limit=150,\n",
    "    min_confidence=0.75,\n",
    "    selected_cluster=8,\n",
    "    dpi=60,\n",
    "    center=\"arena\",\n",
    ")\n",
    "\n",
    "html = display.HTML(video)\n",
    "display.display(html)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0950730c",
   "metadata": {},
   "source": [
    "### Exploring cluster dynamics across conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbffdf3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Transition matrices and heatmaps\n",
    "deepof.visuals.plot_transitions(\n",
    "    my_deepof_project,\n",
    "    embeddings,\n",
    "    soft_counts,\n",
    "   # cluster=False,\n",
    "    visualization=\"heatmaps\",\n",
    "    exp_condition=\"CSDS\",\n",
    ")\n",
    "\n",
    "deepof.visuals.plot_transitions(\n",
    "    my_deepof_project,\n",
    "    embeddings,\n",
    "    soft_counts,\n",
    "    visualization=\"networks\",\n",
    "    silence_diagonal=True,\n",
    "    exp_condition=\"CSDS\",\n",
    ")\n",
    "\n",
    "# TODO:\n",
    "\n",
    "# Add option to use umap location on network plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576c91cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Entropy plots\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 2))\n",
    "\n",
    "deepof.visuals.plot_stationary_entropy(\n",
    "    my_deepof_project,\n",
    "    embeddings,\n",
    "    soft_counts,\n",
    "    breaks,\n",
    "    exp_condition=\"CSDS\",\n",
    "    ax=ax,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9787776a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "deepof.visuals.plot_gantt( # TODO: Add X axis in seconds, and parameter to overlay events as vertical black bars!\n",
    "    my_deepof_project, # TODO: restrict time span! it looks noisy\n",
    "    soft_counts=soft_counts,\n",
    "    experiment_id=\"20191204_Day2_SI_JB08_Test_54\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ab15e4",
   "metadata": {},
   "source": [
    "### Combining supervised and unsupervised information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f966bdcb",
   "metadata": {},
   "source": [
    "#### Visualize global embeddings using the retrieved traits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1239bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a90225e6",
   "metadata": {},
   "source": [
    "#### Visualize animated unsupervised embeddings, coloured by specific traits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caf4f84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66ffb1d3",
   "metadata": {},
   "source": [
    "### Interpreting clusters using SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c72b75",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "csds_chunk_stats, hard_counts, sampled_breaks = deepof.post_hoc.annotate_time_chunks(\n",
    "    deepof_project=my_deepof_project,\n",
    "    soft_counts=soft_counts,\n",
    "    breaks=breaks,\n",
    "    #supervised_annotations=csds_OF_supervised_annotations,\n",
    "    kin_derivative=1,\n",
    "    window_size=13,\n",
    "    include_distances=True,\n",
    "    min_confidence=0.9,\n",
    "    include_angles=True,\n",
    "    include_areas=True,\n",
    "    aggregate=\"mean\",\n",
    "    samples=1500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302b1c70",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "full_cluster_clf, cluster_gbm_performance, groups = deepof.post_hoc.train_supervised_cluster_detectors(\n",
    "    csds_chunk_stats, hard_counts, sampled_breaks, n_folds=5, verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bc7eab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.set_context(\"notebook\")\n",
    "\n",
    "deepof.visuals.plot_cluster_detection_performance(\n",
    "    my_deepof_project,\n",
    "    csds_chunk_stats,\n",
    "    cluster_gbm_performance,\n",
    "    hard_counts,\n",
    "    groups,\n",
    "    visualization=\"confusion_matrix\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e747618",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "deepof.visuals.plot_cluster_detection_performance(\n",
    "    my_deepof_project,\n",
    "    csds_chunk_stats,\n",
    "    cluster_gbm_performance,\n",
    "    hard_counts,\n",
    "    groups,\n",
    "    visualization=\"balanced_accuracy\",\n",
    "    save=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e425d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values, explainer, data_to_explain = deepof.post_hoc.explain_clusters(\n",
    "    csds_chunk_stats, hard_counts, full_cluster_clf, samples=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87279c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import colors as plt_colors\n",
    "from ipywidgets import interact\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "# Plot swarm plots per cluster\n",
    "@interact()\n",
    "def plot_shap_swarm_per_cluster(\n",
    "    cluster=[\"all\"] + list(range(10)), save=False,\n",
    "):\n",
    "    \n",
    "    deepof.visuals.plot_shap_swarm_per_cluster(\n",
    "        my_deepof_project, \n",
    "        data_to_explain, \n",
    "        shap_values, cluster, \n",
    "        save=save,\n",
    "        show=False,\n",
    "    )\n",
    "    \n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c18109",
   "metadata": {},
   "source": [
    "### Exporting cluster video snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f8a30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepof.visuals.export_annotated_video( # TODO: add exp condition filters to output names\n",
    "    my_deepof_project,\n",
    "    soft_counts,\n",
    "    breaks,\n",
    "    frame_limit_per_video=100,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepof",
   "language": "python",
   "name": "deepof"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
