{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2b46f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../../..\")\n",
    "import deepof.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ed73656",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d41506e",
   "metadata": {},
   "source": [
    "# DeepOF unsupervised pipeline: exploring the behavioral space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e24f1d",
   "metadata": {},
   "source": [
    "##### Tutorial index:\n",
    "    \n",
    "* Brief introduction to unsupervised analysis.\n",
    "* Load your previous project.\n",
    "* Running an unsupervised analysis with default parameters.\n",
    "* Understanding the different available models.\n",
    "* Cluster number selection.\n",
    "* Temporal and global embeddings.\n",
    "* Global separation dynamics.\n",
    "* Exploring cluster enrichment across conditions.\n",
    "* Exploring cluster dynamics across conditions.\n",
    "* Interpreting clusters using SHAP.\n",
    "* Exporting cluster video snippets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366bcf28",
   "metadata": {},
   "source": [
    "### Brief introduction to unsupervised analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58a7f23",
   "metadata": {},
   "source": [
    "### Load your previous project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ce3f645",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_deepof_project = deepof.data.load_project(\"../../Desktop/deepOF_CSDS_tutorial_dataset/deepof_tutorial/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52430042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS SHOULD BE THE LAST SECTION OF THE FIRST TUTORIAL!\n",
    "\n",
    "# Check scales across animals. Can we detect to which animal a given time series belongs to?\n",
    "# Once happy with a solution, check that all animals show comparable cluster interpretations.\n",
    "\n",
    "# Add preprocessing options to include multiple animals, concatenated and together in a graph\n",
    "\n",
    "tt = my_deepof_project.get_coords(center=\"Center\", align=\"Spine_1\")\n",
    "# ss = my_deepof_project.get_coords(speed=1)\n",
    "\n",
    "# tt = cc.merge(ss)\n",
    "\n",
    "tt, _ = tt.preprocess(\n",
    "    window_size=25,\n",
    "    window_step=1,\n",
    "    test_videos=1,\n",
    "    scale=\"standard\",\n",
    "    handle_ids=\"split\", # \"concat\" uses bps from != animals as features, \"split\"\n",
    ")\n",
    "\n",
    "tt = (tt[0][:25000], tt[1][:25000], tt[2][:25000], tt[3][:25000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85d25a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wf/msmt6cvx5xl9t0p2qjd1tn65jtl6l8/T/ipykernel_3064/1053585518.py:14: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  adj = nx.adjacency_matrix(G).todense()\n"
     ]
    }
   ],
   "source": [
    "# SAME HERE: Last section of the last tutorial should explore tensor and graph preprocessing\n",
    "\n",
    "from deepof.utils import connect_mouse_topview\n",
    "import networkx as nx\n",
    "\n",
    "pp, G, to_preprocess, global_scaler = my_deepof_project.get_graph_dataset(\n",
    "    animal_id=\"B\",\n",
    "    center=\"Center\",\n",
    "    align=\"Spine_1\",\n",
    "    preprocess=True,\n",
    "    scale=\"standard\"\n",
    ")\n",
    "\n",
    "adj = nx.adjacency_matrix(G).todense()\n",
    "pp = (pp[0][:25000], pp[1][:25000], pp[2][:25000], pp[3][:25000], pp[4][:25000], pp[5][:25000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98060f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What happens if we use a two-stage normalization approach?\n",
    "# 1) Normalize within animals to get rid of body size effects\n",
    "# 2) Normalize across animals to have similar stats across animals, and get the same clusters regardless of the animal\n",
    "# ID."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515bc6d3",
   "metadata": {},
   "source": [
    "### Running an unsupervised analysis with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64d50a7e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 14:13:36.881343: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2023-01-16 14:13:36.881513: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2023-01-16 14:13:36.882122: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 14:13:53.760795: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-01-16 14:13:53.763439: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 28s 48ms/step - total_loss: 48.1816 - reconstruction_loss: 46.4099 - clustering_loss: 0.0000e+00 - prior_loss: 0.0000e+00 - kl_weight: 0.0497 - kl_divergence: -3.0038 - kmeans_loss: 1.7388 - number_of_populated_clusters: 14.4821 - confidence_in_selected_cluster: 0.3445\n",
      "Epoch 2/10\n",
      "195/195 [==============================] - 9s 46ms/step - total_loss: 44.7448 - reconstruction_loss: 43.4752 - clustering_loss: 0.0000e+00 - prior_loss: 0.0000e+00 - kl_weight: 0.1497 - kl_divergence: -2.2489 - kmeans_loss: 1.5918 - number_of_populated_clusters: 13.9282 - confidence_in_selected_cluster: 0.3444\n",
      "Epoch 3/10\n",
      "  3/195 [..............................] - ETA: 10s - total_loss: 42.4129 - reconstruction_loss: 41.2559 - clustering_loss: 0.0000e+00 - prior_loss: 0.0000e+00 - kl_weight: 0.2005 - kl_divergence: -2.0846 - kmeans_loss: 1.5732 - number_of_populated_clusters: 13.3333 - confidence_in_selected_cluster: 0.3341"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 14:14:30.693913: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 9s 45ms/step - total_loss: 44.1211 - reconstruction_loss: 43.0898 - clustering_loss: 0.0000e+00 - prior_loss: 0.0000e+00 - kl_weight: 0.2497 - kl_divergence: -2.0676 - kmeans_loss: 1.5459 - number_of_populated_clusters: 13.8410 - confidence_in_selected_cluster: 0.3327\n",
      "Epoch 4/10\n",
      "195/195 [==============================] - 9s 47ms/step - total_loss: 43.5148 - reconstruction_loss: 42.6273 - clustering_loss: 0.0000e+00 - prior_loss: 0.0000e+00 - kl_weight: 0.3497 - kl_divergence: -2.0437 - kmeans_loss: 1.6010 - number_of_populated_clusters: 13.6974 - confidence_in_selected_cluster: 0.3511\n",
      "Epoch 5/10\n",
      "195/195 [==============================] - 9s 47ms/step - total_loss: 43.0144 - reconstruction_loss: 42.3534 - clustering_loss: 0.0000e+00 - prior_loss: 0.0000e+00 - kl_weight: 0.4497 - kl_divergence: -2.0444 - kmeans_loss: 1.5790 - number_of_populated_clusters: 13.9282 - confidence_in_selected_cluster: 0.3500\n",
      "Epoch 6/10\n",
      "195/195 [==============================] - 9s 45ms/step - total_loss: 42.5586 - reconstruction_loss: 42.1131 - clustering_loss: 0.0000e+00 - prior_loss: 0.0000e+00 - kl_weight: 0.5497 - kl_divergence: -2.0478 - kmeans_loss: 1.5693 - number_of_populated_clusters: 13.9487 - confidence_in_selected_cluster: 0.3508\n",
      "Epoch 7/10\n",
      "  3/195 [..............................] - ETA: 9s - total_loss: 40.4319 - reconstruction_loss: 40.0696 - clustering_loss: 0.0000e+00 - prior_loss: 0.0000e+00 - kl_weight: 0.6005 - kl_divergence: -2.0354 - kmeans_loss: 1.5836 - number_of_populated_clusters: 14.6667 - confidence_in_selected_cluster: 0.3440 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 14:15:07.250706: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 9s 46ms/step - total_loss: 42.1283 - reconstruction_loss: 41.8869 - clustering_loss: 0.0000e+00 - prior_loss: 0.0000e+00 - kl_weight: 0.6497 - kl_divergence: -2.0571 - kmeans_loss: 1.5753 - number_of_populated_clusters: 13.9795 - confidence_in_selected_cluster: 0.3499\n",
      "Epoch 8/10\n",
      "195/195 [==============================] - 9s 46ms/step - total_loss: 41.7496 - reconstruction_loss: 41.7003 - clustering_loss: 0.0000e+00 - prior_loss: 0.0000e+00 - kl_weight: 0.7497 - kl_divergence: -2.0965 - kmeans_loss: 1.6145 - number_of_populated_clusters: 14.0923 - confidence_in_selected_cluster: 0.3570\n",
      "Epoch 9/10\n",
      "195/195 [==============================] - 9s 46ms/step - total_loss: 41.3000 - reconstruction_loss: 41.5575 - clustering_loss: 0.0000e+00 - prior_loss: 0.0000e+00 - kl_weight: 0.8497 - kl_divergence: -2.4105 - kmeans_loss: 1.7541 - number_of_populated_clusters: 14.0718 - confidence_in_selected_cluster: 0.3813\n",
      "Epoch 10/10\n",
      "195/195 [==============================] - 9s 48ms/step - total_loss: 40.7869 - reconstruction_loss: 41.4320 - clustering_loss: 0.0000e+00 - prior_loss: 0.0000e+00 - kl_weight: 0.9497 - kl_divergence: -2.9596 - kmeans_loss: 2.0267 - number_of_populated_clusters: 13.9231 - confidence_in_selected_cluster: 0.4353\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 14:15:47.269240: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/195 [..............................] - ETA: 28s - total_loss: 43.0761 - reconstruction_loss: 38.9124 - clustering_loss: -0.8800 - prior_loss: 2.7080 - kl_weight: 2.5641e-04 - kl_divergence: -3.4751 - kmeans_loss: 2.1225 - number_of_populated_clusters: 12.0000 - confidence_in_selected_cluster: 0.9159  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 14:15:54.276206: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2023-01-16 14:15:54.276219: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2023-01-16 14:15:54.349174: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2023-01-16 14:15:54.355483: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2023-01-16 14:15:54.396580: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: /Users/lucas_miranda/PycharmProjects/deepof/unsupervised_trained_models/fit/deepof_unsupervised_VaDE_recurrent_encodings_input_type=coords_kmeans_loss=0.0_encoding=4_k=15_20230116-141336/plugins/profile/2023_01_16_14_15_54\n",
      "\n",
      "2023-01-16 14:15:54.397747: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to /Users/lucas_miranda/PycharmProjects/deepof/unsupervised_trained_models/fit/deepof_unsupervised_VaDE_recurrent_encodings_input_type=coords_kmeans_loss=0.0_encoding=4_k=15_20230116-141336/plugins/profile/2023_01_16_14_15_54/MC-C9791E.local.trace.json.gz\n",
      "2023-01-16 14:15:54.400833: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: /Users/lucas_miranda/PycharmProjects/deepof/unsupervised_trained_models/fit/deepof_unsupervised_VaDE_recurrent_encodings_input_type=coords_kmeans_loss=0.0_encoding=4_k=15_20230116-141336/plugins/profile/2023_01_16_14_15_54\n",
      "\n",
      "2023-01-16 14:15:54.418372: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to /Users/lucas_miranda/PycharmProjects/deepof/unsupervised_trained_models/fit/deepof_unsupervised_VaDE_recurrent_encodings_input_type=coords_kmeans_loss=0.0_encoding=4_k=15_20230116-141336/plugins/profile/2023_01_16_14_15_54/MC-C9791E.local.memory_profile.json.gz\n",
      "2023-01-16 14:15:54.420039: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /Users/lucas_miranda/PycharmProjects/deepof/unsupervised_trained_models/fit/deepof_unsupervised_VaDE_recurrent_encodings_input_type=coords_kmeans_loss=0.0_encoding=4_k=15_20230116-141336/plugins/profile/2023_01_16_14_15_54\n",
      "Dumped tool data for xplane.pb to /Users/lucas_miranda/PycharmProjects/deepof/unsupervised_trained_models/fit/deepof_unsupervised_VaDE_recurrent_encodings_input_type=coords_kmeans_loss=0.0_encoding=4_k=15_20230116-141336/plugins/profile/2023_01_16_14_15_54/MC-C9791E.local.xplane.pb\n",
      "Dumped tool data for overview_page.pb to /Users/lucas_miranda/PycharmProjects/deepof/unsupervised_trained_models/fit/deepof_unsupervised_VaDE_recurrent_encodings_input_type=coords_kmeans_loss=0.0_encoding=4_k=15_20230116-141336/plugins/profile/2023_01_16_14_15_54/MC-C9791E.local.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to /Users/lucas_miranda/PycharmProjects/deepof/unsupervised_trained_models/fit/deepof_unsupervised_VaDE_recurrent_encodings_input_type=coords_kmeans_loss=0.0_encoding=4_k=15_20230116-141336/plugins/profile/2023_01_16_14_15_54/MC-C9791E.local.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to /Users/lucas_miranda/PycharmProjects/deepof/unsupervised_trained_models/fit/deepof_unsupervised_VaDE_recurrent_encodings_input_type=coords_kmeans_loss=0.0_encoding=4_k=15_20230116-141336/plugins/profile/2023_01_16_14_15_54/MC-C9791E.local.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to /Users/lucas_miranda/PycharmProjects/deepof/unsupervised_trained_models/fit/deepof_unsupervised_VaDE_recurrent_encodings_input_type=coords_kmeans_loss=0.0_encoding=4_k=15_20230116-141336/plugins/profile/2023_01_16_14_15_54/MC-C9791E.local.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 19s 62ms/step - total_loss: 44.8794 - reconstruction_loss: 41.0861 - clustering_loss: -0.8758 - prior_loss: 2.7080 - kl_weight: 0.0497 - kl_divergence: -2.8722 - kmeans_loss: 2.0218 - number_of_populated_clusters: 12.2667 - confidence_in_selected_cluster: 0.9130 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "195/195 [==============================] - 11s 56ms/step - total_loss: 44.2113 - reconstruction_loss: 40.8575 - clustering_loss: -0.8873 - prior_loss: 2.7080 - kl_weight: 0.1497 - kl_divergence: -2.3650 - kmeans_loss: 1.8793 - number_of_populated_clusters: 11.9487 - confidence_in_selected_cluster: 0.9213 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "  2/195 [..............................] - ETA: 11s - total_loss: 53.4684 - reconstruction_loss: 49.9148 - clustering_loss: -0.8993 - prior_loss: 2.7080 - kl_weight: 0.2003 - kl_divergence: -2.2605 - kmeans_loss: 2.1960 - number_of_populated_clusters: 11.0000 - confidence_in_selected_cluster: 0.9303"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 14:16:17.309145: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 12s 59ms/step - total_loss: 43.7878 - reconstruction_loss: 40.6670 - clustering_loss: -0.8983 - prior_loss: 2.7080 - kl_weight: 0.2497 - kl_divergence: -2.2565 - kmeans_loss: 1.8728 - number_of_populated_clusters: 11.8103 - confidence_in_selected_cluster: 0.9292 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "195/195 [==============================] - 11s 56ms/step - total_loss: 43.4298 - reconstruction_loss: 40.5201 - clustering_loss: -0.9009 - prior_loss: 2.7080 - kl_weight: 0.3497 - kl_divergence: -2.2312 - kmeans_loss: 1.8818 - number_of_populated_clusters: 11.7692 - confidence_in_selected_cluster: 0.9309 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "195/195 [==============================] - ETA: 0s - total_loss: 43.0703 - reconstruction_loss: 40.3797 - clustering_loss: -0.9073 - prior_loss: 2.7080 - kl_weight: 0.4497 - kl_divergence: -2.2171 - kmeans_loss: 1.8859 - number_of_populated_clusters: 11.7590 - confidence_in_selected_cluster: 0.9357"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 14:16:50.467240: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 11s 55ms/step - total_loss: 43.0703 - reconstruction_loss: 40.3797 - clustering_loss: -0.9073 - prior_loss: 2.7080 - kl_weight: 0.4497 - kl_divergence: -2.2171 - kmeans_loss: 1.8859 - number_of_populated_clusters: 11.7590 - confidence_in_selected_cluster: 0.9357 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "195/195 [==============================] - 11s 58ms/step - total_loss: 42.7350 - reconstruction_loss: 40.2262 - clustering_loss: -0.9090 - prior_loss: 2.7080 - kl_weight: 0.5497 - kl_divergence: -2.2304 - kmeans_loss: 1.9345 - number_of_populated_clusters: 11.6923 - confidence_in_selected_cluster: 0.9368 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "195/195 [==============================] - 10s 52ms/step - total_loss: 42.3803 - reconstruction_loss: 40.1121 - clustering_loss: -0.9095 - prior_loss: 2.7080 - kl_weight: 0.6497 - kl_divergence: -2.2944 - kmeans_loss: 1.9551 - number_of_populated_clusters: 11.6513 - confidence_in_selected_cluster: 0.9369 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "195/195 [==============================] - ETA: 0s - total_loss: 42.0445 - reconstruction_loss: 40.0033 - clustering_loss: -0.9087 - prior_loss: 2.7080 - kl_weight: 0.7497 - kl_divergence: -2.4529 - kmeans_loss: 2.0611 - number_of_populated_clusters: 11.7795 - confidence_in_selected_cluster: 0.9365"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 14:17:23.251437: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 11s 57ms/step - total_loss: 42.0445 - reconstruction_loss: 40.0033 - clustering_loss: -0.9087 - prior_loss: 2.7080 - kl_weight: 0.7497 - kl_divergence: -2.4529 - kmeans_loss: 2.0611 - number_of_populated_clusters: 11.7795 - confidence_in_selected_cluster: 0.9365 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "195/195 [==============================] - 11s 57ms/step - total_loss: 41.6527 - reconstruction_loss: 39.9801 - clustering_loss: -0.9033 - prior_loss: 2.7080 - kl_weight: 0.8497 - kl_divergence: -2.7896 - kmeans_loss: 2.1732 - number_of_populated_clusters: 11.8667 - confidence_in_selected_cluster: 0.9325 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "195/195 [==============================] - 11s 55ms/step - total_loss: 41.2125 - reconstruction_loss: 39.9812 - clustering_loss: -0.8972 - prior_loss: 2.7080 - kl_weight: 0.9497 - kl_divergence: -3.3204 - kmeans_loss: 2.4040 - number_of_populated_clusters: 11.8513 - confidence_in_selected_cluster: 0.9282 - lr: 0.0010\n",
      "CPU times: user 10min 9s, sys: 2min 32s, total: 12min 41s\n",
      "Wall time: 4min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cons = my_deepof_project.deep_unsupervised_embedding(\n",
    "    pp,\n",
    "    adjacency_matrix=adj,\n",
    "    embedding_model=\"VaDE\",\n",
    "    epochs=10,\n",
    "    encoder_type=\"recurrent\",\n",
    "    n_components=15,\n",
    "    latent_dim=4,\n",
    "    kl_warmup=10,\n",
    "    kl_annealing_mode=\"linear\",\n",
    "    batch_size=128,\n",
    "    kmeans_loss=0.0,\n",
    "    reg_cat_clusters=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa43e0b",
   "metadata": {},
   "source": [
    "### Understanding the different available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aff9e992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VaDE\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 25, 33)]     0           []                               \n",
      "                                                                                                  \n",
      " encoder_edge_features (InputLa  [(None, 25, 11)]    0           []                               \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " recurrent_encoder (Functional)  (None, 4)           3484        ['input_7[0][0]',                \n",
      "                                                                  'encoder_edge_features[0][0]']  \n",
      "                                                                                                  \n",
      " gaussian_mixture_latent (Gauss  ((None, 4),         161         ['recurrent_encoder[0][0]']      \n",
      " ianMixtureLatent)               (None, 15))                                                      \n",
      "                                                                                                  \n",
      " recurrent_decoder (Functional)  (None, 25, 33)      2105        ['gaussian_mixture_latent[0][0]',\n",
      "                                                                  'input_7[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,750\n",
      "Trainable params: 5,749\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cons.vade.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7ec89d",
   "metadata": {},
   "source": [
    "### Cluster number selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b207299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3175278c",
   "metadata": {},
   "source": [
    "### Visualizing temporal and global embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2af44272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'20191204_Day2_SI_JB08_Test_56': 'Stressed',\n",
       " '20191204_Day2_SI_JB08_Test_61': 'Stressed',\n",
       " '20191204_Day2_SI_JB08_Test_62': 'Stressed',\n",
       " '20191204_Day2_SI_JB08_Test_54': 'Nonstressed',\n",
       " '20191204_Day2_SI_JB08_Test_63': 'Nonstressed',\n",
       " '20191204_Day2_SI_JB08_Test_64': 'Nonstressed'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_deepof_project.get_exp_conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2ad890",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20191204_Day2_SI_JB08_Test_56\n",
      "20191204_Day2_SI_JB08_Test_61\n",
      "20191204_Day2_SI_JB08_Test_62\n"
     ]
    }
   ],
   "source": [
    "embeddings = {}\n",
    "soft_counts = {}\n",
    "\n",
    "for key in my_deepof_project.get_exp_conditions.keys():\n",
    "    \n",
    "    print(key)\n",
    "    \n",
    "    dd, _, _, _ = my_deepof_project.get_graph_dataset(\n",
    "        animal_id=\"B\",\n",
    "        precomputed_tab_dict=to_preprocess.filter_videos([key]),\n",
    "        preprocess=True,\n",
    "        scale=\"standard\",\n",
    "        shuffle=False,\n",
    "        pretrained_scaler=global_scaler,\n",
    "    )\n",
    "\n",
    "    dd = (dd[0], dd[1], dd[2], dd[3], dd[4], dd[5])\n",
    "\n",
    "#     dd = my_deepof_project.get_coords(\n",
    "#         center=\"Center\", align=\"Spine_1\"\n",
    "#     ).filter_id(\"B\").filter_videos([key]).preprocess(\n",
    "#         shuffle=False,\n",
    "#         test_videos=0,\n",
    "#     )\n",
    "#     dd = [dd[0], dd[0]]\n",
    "    \n",
    "    embeddings[key] = cons.encoder([dd[0], dd[1]])\n",
    "    soft_counts[key] = cons.grouper([dd[0], dd[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6866c9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(soft_counts['20191204_Day2_SI_JB08_Test_56'].numpy().argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d928a877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPORARY SOLUTION: Load precomputed embeddings. \n",
    "# Solve this later by defaulting embedding saving to a known directory within the project path.\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# emb=\"TCN\"\n",
    "# run=2\n",
    "# with open(f\"../../../Results/CSDS_embeddings/deepof_unsupervised_VaDE_encoder_{emb}_encodings_input=graph_k=25_latdim=8_changepoints_False_kmeans_loss=0.0_run={run}.pkl\", \"rb\") as handle:\n",
    "#     embeddings, soft_counts, breaks = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70433618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patched_breaks(key):\n",
    "        \n",
    "    tt, g, prep, _ = my_deepof_project.get_graph_dataset(center=\"Center\", align=\"Spine_1\", animal_id=\"B\", shuffle=False)\n",
    "    tt = my_deepof_project.get_graph_dataset(\n",
    "        precomputed_tab_dict=prep.filter_videos([key]),\n",
    "        animal_id=\"B\",\n",
    "        window_size=25,\n",
    "        window_step=1,\n",
    "        shuffle=False,\n",
    "        automatic_changepoints=False,\n",
    "        scale=\"standard\",\n",
    "        test_videos=0,\n",
    "    )[0]\n",
    "\n",
    "    return (~np.all(tt[0] == 0, axis=2)).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430bc3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "breaks = {\n",
    "    key: get_patched_breaks(key) for key in my_deepof_project.get_exp_conditions.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa50ace5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "deepof.visuals.plot_embeddings(\n",
    "    my_deepof_project, \n",
    "    embeddings, \n",
    "    soft_counts,\n",
    "    breaks,\n",
    "    aggregate_experiments=False,\n",
    "    ax=ax1,\n",
    "    save=False, # Set to True, or give a custom name, to save the plot\n",
    ")\n",
    "\n",
    "deepof.visuals.plot_embeddings(\n",
    "    my_deepof_project,\n",
    "    embeddings, \n",
    "    soft_counts,\n",
    "    breaks,\n",
    "    aggregate_experiments=\"median\",\n",
    "    ax=ax2,\n",
    "    save=False, # Set to True, or give a custom name, to save the plot,\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a99d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "video = deepof.visuals.animate_skeleton(\n",
    "    my_deepof_project,\n",
    "    embedding=embeddings,\n",
    "    animal_id=\"B\",\n",
    "    cluster_assignments=soft_counts,\n",
    "    experiment_id=\"20191204_Day2_SI_JB08_Test_54\",\n",
    "    frame_limit=150,\n",
    "    selected_cluster=4,\n",
    "    dpi=60,\n",
    "    #center=\"Center\",\n",
    "    #align=\"Spine_1\",\n",
    "    #embedding=[emb_B, emb_W],\n",
    ")\n",
    "\n",
    "html = display.HTML(video)\n",
    "display.display(html)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e61418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "video = deepof.visuals.animate_skeleton(\n",
    "    my_deepof_project,\n",
    "    embedding=embeddings,\n",
    "    animal_id=\"B\",\n",
    "    cluster_assignments=soft_counts,\n",
    "    experiment_id=\"20191204_Day2_SI_JB08_Test_56\",\n",
    "    frame_limit=150,\n",
    "    selected_cluster=4,\n",
    "    dpi=60,\n",
    "    #center=\"Center\",\n",
    "    #align=\"Spine_1\",\n",
    "    #embedding=[emb_B, emb_W],\n",
    ")\n",
    "\n",
    "html = display.HTML(video)\n",
    "display.display(html)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522f1116",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "video = deepof.visuals.animate_skeleton(\n",
    "    my_deepof_project,\n",
    "    embedding=embeddings,\n",
    "    cluster_assignments=soft_counts,\n",
    "    experiment_id=\"20191204_Day2_SI_JB08_Test_54\",\n",
    "    frame_limit=250,\n",
    "    selected_cluster=4,\n",
    "    dpi=60,\n",
    "    #center=\"Center\",\n",
    "    #align=\"Spine_1\",\n",
    "    #embedding=[emb_B, emb_W],\n",
    ")\n",
    "\n",
    "html = display.HTML(video)\n",
    "display.display(html)\n",
    "plt.close()\n",
    "\n",
    "#TODO: Correct for misalignment. The way this is implemented, \n",
    "#      makes the last data point the representative of the sequence, not the middle one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ae0e11",
   "metadata": {},
   "source": [
    "### Global separation dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec60eee",
   "metadata": {},
   "source": [
    "### Exploring cluster enrichment across conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0950730c",
   "metadata": {},
   "source": [
    "### Exploring cluster dynamics across conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9787776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "deepof.visuals.plot_gantt(\n",
    "    my_deepof_project,\n",
    "    soft_counts=soft_counts,\n",
    "    experiment_id=\"20191204_Day2_SI_JB08_Test_54\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ffb1d3",
   "metadata": {},
   "source": [
    "### Interpreting clusters using SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c18109",
   "metadata": {},
   "source": [
    "### Exporting cluster video snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b7ee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: they should be saved to a directory that makes sense!."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1f6b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "files = [i for i in os.listdir(\"../../Desktop/deepOF_datasets/Tagged_videos/Data_for_deepof_OF/JB08_files_OF/Tables/\")]\n",
    "\n",
    "for f in files:\n",
    "    cur = pd.read_hdf(\"../../Desktop/deepOF_datasets/Tagged_videos/Data_for_deepof_OF/JB08_files_OF/Tables/\" + f)\n",
    "    \n",
    "    cur.to_csv(\"../../Desktop/deepOF_datasets/Tagged_videos/Data_for_deepof_OF/JB08_files_OF/Tables/\" + f[:-2] + \"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7556420",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = cons.encoder([pp[0][:25000], pp[1][:25000]])\n",
    "cls = cons.quantizer([pp[0][:25000], pp[1][:25000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73357da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "umap = umap.UMAP(\n",
    "    n_components=2, \n",
    "    n_neighbors=250,\n",
    "    min_dist=1.0,\n",
    ").fit_transform(emb.numpy())\n",
    "# umap = emb.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea74c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(cls.numpy().argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fd99b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#tt = GaussianMixture(n_components=5, covariance_type=\"diag\", reg_covar=1e-04).fit(emb.numpy())\n",
    "#means = tt.means_\n",
    "#means = cons.get_gmm_params['means'].numpy()\n",
    "\n",
    "sns.scatterplot(x=umap[:, 0], y=umap[:, 1], hue=cls.numpy().argmax(axis=1), palette=\"tab20\")\n",
    "# means = cons.get_layer(\"grouper\").get_layer(\"gaussian_mixture_latent\").c_mu.numpy()\n",
    "# sns.scatterplot(x=means[:,0], y=means[:,1], s=250, c=\"black\")\n",
    "\n",
    "plt.title(\"DeepOF embeddings\")\n",
    "\n",
    "# plt.legend(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21006d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "cons.get_gmm_params['weights'].numpy().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c17e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = np.split(np.concatenate(tt), np.cumsum([i.shape[0] for k,i in vqvae_solution[0].items() if k in list(cc.keys())]))\n",
    "\n",
    "for i in tt:\n",
    "    print(i.shape)\n",
    "    print(np.max(np.abs(i.mean(axis=0))))\n",
    "    print(np.mean(np.abs(i.std(axis=0))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21595771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import numpy as np\n",
    "# with open(\"../train_models/deepof_unsupervised_VQVAE_encodings_input=coords_k=100_latdim=8_kmeans_loss=0.0_run=1.pkl\", \"rb\") as handle:\n",
    "#     vqvae_solution = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499a3098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import AgglomerativeClustering\n",
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# from deepof.post_hoc import get_transitions\n",
    "# from hmmlearn.hmm import GaussianHMM\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "\n",
    "# def merge_and_smooth_clusters(\n",
    "#     n_clusters, centroids, embedding, concat_embedding, cluster_assignments\n",
    "# ):\n",
    "#     \"\"\"Merges the current clusters using a hierarchical agglomerative approach, and smoothens using a Gaussian HMM.\n",
    "\n",
    "#     Args:\n",
    "#         n_clusters (int): number of clusters to report.\n",
    "#         centroids (np.ndarray): precomputed means per cluster.\n",
    "#         embedding (tabdict): original deepof.TableDict object containing unsupervised embeddings.\n",
    "#         concat_embedding (np.ndarray): concatenated list of embeddings per animal in the dataset.\n",
    "#         cluster_assignments (tabdict): original deepof.TableDict object containing cluster assignments.\n",
    "\n",
    "#     Returns:\n",
    "#         new_soft_assignments (np.ndarray): concatenated postprocessed assignments for all animals in the dataset.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Merge clusters ussing a hierarchical agglomerative approach\n",
    "#     new_hard_assignments = AgglomerativeClustering(\n",
    "#         n_clusters=n_clusters, compute_distances=True\n",
    "#     ).fit_predict(centroids)\n",
    "#     cluster_predictor = LinearDiscriminantAnalysis().fit(\n",
    "#         centroids, new_hard_assignments\n",
    "#     )\n",
    "#     centroids = cluster_predictor.means_\n",
    "#     new_soft_assignments = cluster_predictor.predict_proba(concat_embedding)\n",
    "\n",
    "#     # Rebuild the soft assignments dictionary per experimental animal\n",
    "#     new_soft_assignments = np.split(\n",
    "#         new_soft_assignments,\n",
    "#         np.cumsum([i.shape[0] for i in embedding.values()]),\n",
    "#     )\n",
    "#     new_soft_assignments = {\n",
    "#         key: val for key, val in zip(cluster_assignments.keys(), new_soft_assignments)\n",
    "#     }\n",
    "\n",
    "#     # Smooth assignments across time using a Gaussian HMM on the embeddings, with priors based on the clustering results\n",
    "#     for key, val in tqdm(new_soft_assignments.items()):\n",
    "\n",
    "#         hmm = GaussianHMM(\n",
    "#             startprob_prior=np.unique(val.argmax(axis=1), return_counts=True)[1],\n",
    "#             transmat_prior=get_transitions(val.argmax(axis=1), n_states=n_clusters) + 10,\n",
    "#             means_prior=centroids,\n",
    "#             n_components=n_clusters,\n",
    "#             covariance_type=\"diag\",\n",
    "#             n_iter=100,\n",
    "#             tol=0.0001,\n",
    "#         )\n",
    "        \n",
    "#         hmm.fit(embedding[key].numpy())\n",
    "#         new_soft_assignments[key] = hmm.predict_proba(embedding[key].numpy())\n",
    "\n",
    "#     return new_soft_assignments\n",
    "\n",
    "\n",
    "# def cluster_postprocessing(embedding, cluster_assignments, n_clusters=\"auto\"):\n",
    "#     \"\"\"Merges clusters using a hierarchical approach.\n",
    "\n",
    "#     Args:\n",
    "#         embedding (list): list of embeddings per animal in the dataset.\n",
    "#         cluster_assignments (list): list of cluster assignments per animal in the dataset.\n",
    "#         n_clusters (int): number of clusters to report.\n",
    "\n",
    "#     Returns:\n",
    "#         new_soft_assignments (list): list of new (merged) cluster assignments.\n",
    "\n",
    "#     \"\"\"\n",
    "#     # Concatenate embeddings and cluster assignments in to unique np.ndarray objects\n",
    "#     concat_embedding = np.concatenate([tensor.numpy() for tensor in embedding.values()])\n",
    "#     hard_assignments = np.concatenate(\n",
    "#         [tensor.numpy().argmax(axis=1) for tensor in cluster_assignments.values()]\n",
    "#     )\n",
    "\n",
    "#     assert concat_embedding.shape[0] == hard_assignments.shape[0]\n",
    "\n",
    "#     # Get cluster centroids from the concatenated embeddings\n",
    "#     centroids = []\n",
    "#     for cluster in range(np.max(hard_assignments)):\n",
    "#         centroid = concat_embedding[hard_assignments == cluster]\n",
    "#         if len(centroid) == 0:\n",
    "#             continue\n",
    "#         centroid = np.mean(centroid, axis=0)\n",
    "#         centroids.append(centroid)\n",
    "\n",
    "#     centroids = np.stack(centroids)\n",
    "\n",
    "#     # Merge centroids using a hierarchical approach with the given resolution, and soft-assign instances to clusters\n",
    "#     if isinstance(n_clusters, int):\n",
    "#         new_soft_assignments = merge_and_smooth_clusters(\n",
    "#             n_clusters, centroids, embedding, concat_embedding, cluster_assignments\n",
    "#         )\n",
    "\n",
    "#     else:\n",
    "#         raise NotImplementedError\n",
    "\n",
    "#     return new_soft_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946cd858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from hmmlearn.hmm import GaussianHMM\n",
    "\n",
    "# new_ass = cluster_postprocessing(\n",
    "#     vqvae_solution[0], \n",
    "#     vqvae_solution[1],\n",
    "#     n_clusters=12\n",
    "# )\n",
    "# hcc = new_ass['20191203_Day1_SI_JB08_Test_54'].argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f4d221",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import umap\n",
    "\n",
    "# # Cluster on the original embedding space\n",
    "# new_emb = umap.UMAP(n_components=2, n_neighbors=75).fit_transform(vqvae_solution[0]['20191203_Day1_SI_JB08_Test_54'])\n",
    "\n",
    "# sns.scatterplot(x=new_emb[:, 0], y=new_emb[:, 1], hue=hcc, palette=\"tab20\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419b7975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # How prevalent are these clusters?\n",
    "# from collections import Counter\n",
    "# print(Counter(hcc))\n",
    "\n",
    "# new_ass = hcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b722b809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # How often does the model change clusters?\n",
    "# from collections import defaultdict\n",
    "\n",
    "# lengths = defaultdict(list)\n",
    "# cur = 0\n",
    "# for i in range(1, len(new_ass)):\n",
    "#     if new_ass[i-1] == new_ass[i]:\n",
    "#         cur += 1\n",
    "#     else:\n",
    "#         lengths[new_ass[i-1]].append(cur)\n",
    "#         cur = 1\n",
    "\n",
    "# {key:np.mean(val) for key, val in lengths.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0fcf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Duration histograms per cluster\n",
    "# lengths_df = pd.DataFrame([lengths]).melt().explode(\"value\").astype(int)\n",
    "# sns.violinplot(data=lengths_df, x=\"variable\", y=\"value\")\n",
    "\n",
    "# plt.axhline(25, linestyle=\"--\", color=\"black\")\n",
    "        \n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
