{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d64823a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../../..\")\n",
    "import deepof.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3227f178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a68dc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1763ab7f",
   "metadata": {},
   "source": [
    "# DeepOF supervised pipeline: detecting pre-defined behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0170cc",
   "metadata": {},
   "source": [
    "##### Tutorial index:\n",
    "    \n",
    "    * Brief introduction to supervised analysis, including the figure with all tracked behaviors.\n",
    "    * Load the previous project.\n",
    "    * Run the supervised annotation pipeline.\n",
    "    * Visualize global embeddings using the retrieved traits.\n",
    "    * Visualize animated unsupervised embeddings, coloured by specific traits.\n",
    "    * Explore trait enrichment across conditions.\n",
    "    * Generate Gantt plots with all traits.\n",
    "    * Export video snippets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14673fa",
   "metadata": {},
   "source": [
    "### Supervised annotation in DeepOF - search for pre-established patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b57bdf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60b9158e",
   "metadata": {},
   "source": [
    "### Load a previously initiated project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6382da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# # FC data\n",
    "# my_deepof_project = deepof.data.load_project(\"./deepof_FC_project_files/\")\n",
    "\n",
    "# with open(\"./deepof_FC_project_files/Coordinates/FC_dataset_experimental_conditions.pkl\", \"rb\") as handle:\n",
    "#     exp_conditions = pickle.load(handle)\n",
    "# my_deepof_project._exp_conditions = exp_conditions\n",
    "\n",
    "# SI data\n",
    "my_deepof_project = deepof.data.load_project(\"../../Desktop/deepOF_datasets/Tagged_videos/Data_for_deepof_SI/deepof_SI_project/\")\n",
    "with open(\"deepof_SI_exp_conds.pkl\", \"rb\") as handle:\n",
    "    exp_conds = pickle.load(handle)\n",
    "my_deepof_project._exp_conditions = exp_conds\n",
    "\n",
    "# Update project path to a local path\n",
    "my_deepof_project._project_path = \"../../Desktop/deepOF_datasets/Tagged_videos/Data_for_deepof_SI/\"\n",
    "my_deepof_project._project_name = \"deepof_SI_project\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10776701",
   "metadata": {},
   "source": [
    "### Run the supervised annotation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d368119b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                    | 0/53 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/psycl/g/mpsstatgen/lucas/DLC/DeepOF/deepof/deepof/trained_models/deepof_supervised/deepof_supervised_huddle_estimator.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmy_deepof_project\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msupervised_annotation\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/deepof/deepof/data.py:1463\u001B[0m, in \u001B[0;36mCoordinates.supervised_annotation\u001B[0;34m(self, params, video_output, frame_limit, debug, n_jobs, propagate_labels)\u001B[0m\n\u001B[1;32m   1459\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tables\u001B[38;5;241m.\u001B[39mkeys()):\n\u001B[1;32m   1460\u001B[0m     \u001B[38;5;66;03m# Remove indices and add at the very end, to avoid conflicts if\u001B[39;00m\n\u001B[1;32m   1461\u001B[0m     \u001B[38;5;66;03m# frame_rate is specified in project\u001B[39;00m\n\u001B[1;32m   1462\u001B[0m     tag_index \u001B[38;5;241m=\u001B[39m raw_coords[key]\u001B[38;5;241m.\u001B[39mindex\n\u001B[0;32m-> 1463\u001B[0m     supervised_tags \u001B[38;5;241m=\u001B[39m \u001B[43mdeepof\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mannotation_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msupervised_tagging\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1464\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1465\u001B[0m \u001B[43m        \u001B[49m\u001B[43mraw_coords\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mraw_coords\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1466\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcoords\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcoords\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1467\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdists\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdists\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1468\u001B[0m \u001B[43m        \u001B[49m\u001B[43mangs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mangs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1469\u001B[0m \u001B[43m        \u001B[49m\u001B[43mspeeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mspeeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1470\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvideo\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mvid\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mvid\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_videos\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mDLC\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mvid\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1471\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrained_model_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_trained_model_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1472\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1473\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1474\u001B[0m     supervised_tags\u001B[38;5;241m.\u001B[39mindex \u001B[38;5;241m=\u001B[39m tag_index\n\u001B[1;32m   1475\u001B[0m     tag_dict[key] \u001B[38;5;241m=\u001B[39m supervised_tags\n",
      "File \u001B[0;32m~/PycharmProjects/deepof/deepof/annotation_utils.py:537\u001B[0m, in \u001B[0;36msupervised_tagging\u001B[0;34m(coord_object, raw_coords, coords, dists, angs, speeds, video, trained_model_path, params)\u001B[0m\n\u001B[1;32m    517\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Outputs a dataframe with the registered motives per frame. If specified, produces a labeled\u001B[39;00m\n\u001B[1;32m    518\u001B[0m \u001B[38;5;124;03mvideo displaying the information in real time\u001B[39;00m\n\u001B[1;32m    519\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    533\u001B[0m \u001B[38;5;124;03m    - tag_df (pandas.DataFrame): table with traits as columns and frames as rows. Each\u001B[39;00m\n\u001B[1;32m    534\u001B[0m \u001B[38;5;124;03m    value is a boolean indicating trait detection at a given time\"\"\"\u001B[39;00m\n\u001B[1;32m    536\u001B[0m \u001B[38;5;66;03m# Load pre-trained models for ML annotated traits\u001B[39;00m\n\u001B[0;32m--> 537\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    538\u001B[0m \u001B[43m    \u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    539\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrained_model_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    540\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdeepof_supervised\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    541\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdeepof_supervised_huddle_estimator.pkl\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    542\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    543\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    544\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m est:\n\u001B[1;32m    545\u001B[0m     huddle_estimator \u001B[38;5;241m=\u001B[39m pickle\u001B[38;5;241m.\u001B[39mload(est)\n\u001B[1;32m    546\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\n\u001B[1;32m    547\u001B[0m     os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\n\u001B[1;32m    548\u001B[0m         trained_model_path,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    552\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    553\u001B[0m ) \u001B[38;5;28;01mas\u001B[39;00m est:\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/psycl/g/mpsstatgen/lucas/DLC/DeepOF/deepof/deepof/trained_models/deepof_supervised/deepof_supervised_huddle_estimator.pkl'"
     ]
    }
   ],
   "source": [
    "my_deepof_project.supervised_annotation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efa63dc",
   "metadata": {},
   "source": [
    "### Explore trait enrichment across conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3802f7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5dbdc821",
   "metadata": {},
   "source": [
    "### Generate Gantt plots with all traits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e60f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b88d253",
   "metadata": {},
   "source": [
    "### Exporting video snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0882eedd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
