<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>deepof.unsupervised_utils module &mdash; deepof 0.1.85 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="shortcut icon" href="_static/deepof.ico"/>
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="deepof.models module" href="deepof.models.html" />
    <link rel="prev" title="deepof.supervised_utils module" href="deepof.supervised_utils.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> deepof
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="tutorial_notebooks/deepof_preprocessing_tutorial.html">Formatting your data: feature extraction from DLC output</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_notebooks/deepof_supervised_tutorial.html">DeepOF supervised pipeline: detecting pre-defined behaviors</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_notebooks/deepof_unsupervised_tutorial.html">DeepOF unsupervised pipeline: exploring the behavioral space</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="deepof.data.html">deepof.data (main data-wrangling module)</a></li>
<li class="toctree-l1"><a class="reference internal" href="deepof.utils.html">deepof.utils (data-wrangling auxiliary functions)</a></li>
<li class="toctree-l1"><a class="reference internal" href="deepof.supervised_utils.html">deepof.supervised_utils (deep supervised model training auxiliary functions)</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">deepof.unsupervised_utils (deep unsupervised models' auxiliary functions)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.select_contrastive_loss"><code class="docutils literal notranslate"><span class="pre">select_contrastive_loss()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.nce_loss_fn"><code class="docutils literal notranslate"><span class="pre">nce_loss_fn()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.dcl_loss_fn"><code class="docutils literal notranslate"><span class="pre">dcl_loss_fn()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.fc_loss_fn"><code class="docutils literal notranslate"><span class="pre">fc_loss_fn()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.hard_loss_fn"><code class="docutils literal notranslate"><span class="pre">hard_loss_fn()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.load_treatments"><code class="docutils literal notranslate"><span class="pre">load_treatments()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.compute_kmeans_loss"><code class="docutils literal notranslate"><span class="pre">compute_kmeans_loss()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.get_k_nearest_neighbors"><code class="docutils literal notranslate"><span class="pre">get_k_nearest_neighbors()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.compute_shannon_entropy"><code class="docutils literal notranslate"><span class="pre">compute_shannon_entropy()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.get_neighbourhood_entropy"><code class="docutils literal notranslate"><span class="pre">get_neighbourhood_entropy()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.plot_lr_vs_loss"><code class="docutils literal notranslate"><span class="pre">plot_lr_vs_loss()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.get_angles"><code class="docutils literal notranslate"><span class="pre">get_angles()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.positional_encoding"><code class="docutils literal notranslate"><span class="pre">positional_encoding()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.create_padding_mask"><code class="docutils literal notranslate"><span class="pre">create_padding_mask()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.create_look_ahead_mask"><code class="docutils literal notranslate"><span class="pre">create_look_ahead_mask()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.create_masks"><code class="docutils literal notranslate"><span class="pre">create_masks()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.find_learning_rate"><code class="docutils literal notranslate"><span class="pre">find_learning_rate()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.get_hard_counts"><code class="docutils literal notranslate"><span class="pre">get_hard_counts()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.cluster_frequencies_regularizer"><code class="docutils literal notranslate"><span class="pre">cluster_frequencies_regularizer()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.get_callbacks"><code class="docutils literal notranslate"><span class="pre">get_callbacks()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.CustomStopper"><code class="docutils literal notranslate"><span class="pre">CustomStopper</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#deepof.unsupervised_utils.CustomStopper.__init__"><code class="docutils literal notranslate"><span class="pre">CustomStopper.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#deepof.unsupervised_utils.CustomStopper.get_config"><code class="docutils literal notranslate"><span class="pre">CustomStopper.get_config()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#deepof.unsupervised_utils.CustomStopper.on_epoch_end"><code class="docutils literal notranslate"><span class="pre">CustomStopper.on_epoch_end()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.ExponentialLearningRate"><code class="docutils literal notranslate"><span class="pre">ExponentialLearningRate</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#deepof.unsupervised_utils.ExponentialLearningRate.__init__"><code class="docutils literal notranslate"><span class="pre">ExponentialLearningRate.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#deepof.unsupervised_utils.ExponentialLearningRate.on_batch_end"><code class="docutils literal notranslate"><span class="pre">ExponentialLearningRate.on_batch_end()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.ProbabilisticDecoder"><code class="docutils literal notranslate"><span class="pre">ProbabilisticDecoder</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#deepof.unsupervised_utils.ProbabilisticDecoder.__init__"><code class="docutils literal notranslate"><span class="pre">ProbabilisticDecoder.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#deepof.unsupervised_utils.ProbabilisticDecoder.call"><code class="docutils literal notranslate"><span class="pre">ProbabilisticDecoder.call()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.ClusterControl"><code class="docutils literal notranslate"><span class="pre">ClusterControl</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#deepof.unsupervised_utils.ClusterControl.__init__"><code class="docutils literal notranslate"><span class="pre">ClusterControl.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#deepof.unsupervised_utils.ClusterControl.get_config"><code class="docutils literal notranslate"><span class="pre">ClusterControl.get_config()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#deepof.unsupervised_utils.ClusterControl.call"><code class="docutils literal notranslate"><span class="pre">ClusterControl.call()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.KLDivergenceLayer"><code class="docutils literal notranslate"><span class="pre">KLDivergenceLayer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#deepof.unsupervised_utils.KLDivergenceLayer.__init__"><code class="docutils literal notranslate"><span class="pre">KLDivergenceLayer.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#deepof.unsupervised_utils.KLDivergenceLayer.get_config"><code class="docutils literal notranslate"><span class="pre">KLDivergenceLayer.get_config()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#deepof.unsupervised_utils.KLDivergenceLayer.call"><code class="docutils literal notranslate"><span class="pre">KLDivergenceLayer.call()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.TransformerEncoderLayer"><code class="docutils literal notranslate"><span class="pre">TransformerEncoderLayer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#deepof.unsupervised_utils.TransformerEncoderLayer.__init__"><code class="docutils literal notranslate"><span class="pre">TransformerEncoderLayer.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#deepof.unsupervised_utils.TransformerEncoderLayer.call"><code class="docutils literal notranslate"><span class="pre">TransformerEncoderLayer.call()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.TransformerDecoderLayer"><code class="docutils literal notranslate"><span class="pre">TransformerDecoderLayer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#deepof.unsupervised_utils.TransformerDecoderLayer.__init__"><code class="docutils literal notranslate"><span class="pre">TransformerDecoderLayer.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#deepof.unsupervised_utils.TransformerDecoderLayer.call"><code class="docutils literal notranslate"><span class="pre">TransformerDecoderLayer.call()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.TransformerEncoder"><code class="docutils literal notranslate"><span class="pre">TransformerEncoder</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#deepof.unsupervised_utils.TransformerEncoder.__init__"><code class="docutils literal notranslate"><span class="pre">TransformerEncoder.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#deepof.unsupervised_utils.TransformerEncoder.call"><code class="docutils literal notranslate"><span class="pre">TransformerEncoder.call()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.TransformerDecoder"><code class="docutils literal notranslate"><span class="pre">TransformerDecoder</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#deepof.unsupervised_utils.TransformerDecoder.__init__"><code class="docutils literal notranslate"><span class="pre">TransformerDecoder.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#deepof.unsupervised_utils.TransformerDecoder.call"><code class="docutils literal notranslate"><span class="pre">TransformerDecoder.call()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.log_hyperparameters"><code class="docutils literal notranslate"><span class="pre">log_hyperparameters()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.autoencoder_fitting"><code class="docutils literal notranslate"><span class="pre">autoencoder_fitting()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#deepof.unsupervised_utils.tune_search"><code class="docutils literal notranslate"><span class="pre">tune_search()</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="deepof.models.html">deepof.models (deep unsupervised models)</a></li>
<li class="toctree-l1"><a class="reference internal" href="deepof.hypermodels.html">deepof.hypermodels (deep unsupervised hypermodels for hyperparameter tuning)</a></li>
<li class="toctree-l1"><a class="reference internal" href="deepof.visuals.html">deepof.visuals (auxiliary visualization functions)</a></li>
<li class="toctree-l1"><a class="reference internal" href="deepof.post_hoc.html">deepof.post_hoc (auxiliary annotation analysis functions)</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">deepof</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>deepof.unsupervised_utils module</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/deepof.unsupervised_utils.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="module-deepof.unsupervised_utils">
<span id="deepof-unsupervised-utils-module"></span><h1>deepof.unsupervised_utils module<a class="headerlink" href="#module-deepof.unsupervised_utils" title="Permalink to this heading"></a></h1>
<p>Utility functions for both training autoencoder models in deepof.models and tuning hyperparameters with deepof.hypermodels.</p>
<dl class="py function">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.select_contrastive_loss">
<span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">select_contrastive_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">history</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">similarity</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'nce'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">elimination_topk</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attraction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.select_contrastive_loss" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>history</strong> – </p></li>
<li><p><strong>future</strong> – </p></li>
<li><p><strong>similarity</strong> – </p></li>
<li><p><strong>loss_fn</strong> – </p></li>
<li><p><strong>temperature</strong> – </p></li>
<li><p><strong>tau</strong> – </p></li>
<li><p><strong>beta</strong> – </p></li>
<li><p><strong>elimination_topk</strong> – </p></li>
<li><p><strong>attraction</strong> – </p></li>
</ul>
</dd>
</dl>
<p>Returns:</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.nce_loss_fn">
<span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">nce_loss_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">history</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">similarity</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.nce_loss_fn" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.dcl_loss_fn">
<span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">dcl_loss_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">history</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">similarity</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debiased</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_plus</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.dcl_loss_fn" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.fc_loss_fn">
<span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">fc_loss_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">history</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">similarity</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">elimination_topk</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attraction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.fc_loss_fn" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.hard_loss_fn">
<span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">hard_loss_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">history</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">similarity</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debiased</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_plus</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.hard_loss_fn" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.load_treatments">
<span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">load_treatments</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.load_treatments" title="Permalink to this definition"></a></dt>
<dd><p>Loads a dictionary containing the treatments per individual, to be loaded as metadata in the coordinates class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>train_path</strong> (<em>str</em>) – path to the training data.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>dictionary containing the treatments per individual.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.compute_kmeans_loss">
<span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">compute_kmeans_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">latent_means</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.compute_kmeans_loss" title="Permalink to this definition"></a></dt>
<dd><p>Adds a penalty to the singular values of the Gram matrix of the latent means. It helps disentangle the latent
space.
Based on <a class="reference external" href="https://arxiv.org/pdf/1610.04794.pdf">https://arxiv.org/pdf/1610.04794.pdf</a>, and <a class="reference external" href="https://www.biorxiv.org/content/10.1101/2020.05.14.095430v3">https://www.biorxiv.org/content/10.1101/2020.05.14.095430v3</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>latent_means</strong> – tensor containing the means of the latent distribution</p></li>
<li><p><strong>weight</strong> – weight of the Gram loss in the total loss function</p></li>
<li><p><strong>batch_size</strong> – batch size of the data to compute the kmeans loss for.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>kmeans loss</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.get_k_nearest_neighbors">
<span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">get_k_nearest_neighbors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.get_k_nearest_neighbors" title="Permalink to this definition"></a></dt>
<dd><p>Retrieve indices of the k nearest neighbors in tensor to the vector with the specified index</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensor</strong> (<em>tf.Tensor</em>) – tensor to compute the k nearest neighbors for</p></li>
<li><p><strong>k</strong> (<em>int</em>) – number of nearest neighbors to retrieve</p></li>
<li><p><strong>index</strong> (<em>int</em>) – index of the vector to compute the k nearest neighbors for</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>indices of the k nearest neighbors</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.compute_shannon_entropy">
<span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">compute_shannon_entropy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.compute_shannon_entropy" title="Permalink to this definition"></a></dt>
<dd><p>Computes Shannon entropy for a given tensor</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>tensor</strong> (<em>tf.Tensor</em>) – tensor to compute the entropy for</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>entropy of the tensor</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.get_neighbourhood_entropy">
<span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">get_neighbourhood_entropy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">index</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clusters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.get_neighbourhood_entropy" title="Permalink to this definition"></a></dt>
<dd><p>Computes the neighbourhood entropy for a given vector in a tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>index</strong> (<em>int</em>) – index of the vector to compute the neighbourhood entropy for</p></li>
<li><p><strong>tensor</strong> (<em>tf.Tensor</em>) – tensor to compute the neighbourhood entropy for</p></li>
<li><p><strong>clusters</strong> (<em>tf.Tensor</em>) – tensor containing the cluster labels for each vector in the tensor</p></li>
<li><p><strong>k</strong> (<em>int</em>) – number of nearest neighbours to consider</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>neighbourhood entropy of the vector with the specified index</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.plot_lr_vs_loss">
<span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">plot_lr_vs_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rates</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">losses</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.plot_lr_vs_loss" title="Permalink to this definition"></a></dt>
<dd><p>Plots learing rate versus the loss function of the model</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>rates</strong> (<em>np.ndarray</em>) – array containing the learning rates to plot in the x-axis</p></li>
<li><p><strong>losses</strong> (<em>np.ndarray</em>) – array containing the losses to plot in the y-axis</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.get_angles">
<span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">get_angles</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pos</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">i</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.get_angles" title="Permalink to this definition"></a></dt>
<dd><p>Auxiliary function for positional encoding computation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pos</strong> (<em>int</em>) – position in the sequence.</p></li>
<li><p><strong>i</strong> (<em>int</em>) – number of sequences.</p></li>
<li><p><strong>d_model</strong> (<em>int</em>) – dimensionality of the embeddings.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.positional_encoding">
<span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">positional_encoding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">position</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.positional_encoding" title="Permalink to this definition"></a></dt>
<dd><p>Computes positional encodings, as in
<a class="reference external" href="https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>position</strong> (<em>int</em>) – position in the sequence.</p></li>
<li><p><strong>d_model</strong> (<em>int</em>) – dimensionality of the embeddings.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.create_padding_mask">
<span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">create_padding_mask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seq</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.create_padding_mask" title="Permalink to this definition"></a></dt>
<dd><p>Creates a padding mask, with zeros where data is missing, and ones where data is available.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>seq</strong> (<em>tf.Tensor</em>) – Sequence to compute the mask on</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.create_look_ahead_mask">
<span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">create_look_ahead_mask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.create_look_ahead_mask" title="Permalink to this definition"></a></dt>
<dd><p>Creates a triangular matrix containing an increasing amount of ones from left to right on each subsequent row.
Useful for transformer decoder, which allows it to go through the data in a sequential manner, without taking
the future into account.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>size</strong> (<em>int</em>) – number of time steps in the sequence</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.create_masks">
<span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">create_masks</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.create_masks" title="Permalink to this definition"></a></dt>
<dd><p>Given an input sequence, it creates all necessary masks to pass it through the transformer architecture.
This includes encoder and decoder padding masks, and a look-ahead mask</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>inp</strong> (<em>tf.Tensor</em>) – input sequence to create the masks for.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.find_learning_rate">
<span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">find_learning_rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.find_learning_rate" title="Permalink to this definition"></a></dt>
<dd><p>Trains the provided model for an epoch with an exponentially increasing learning rate</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>tf.keras.Model</em>) – model to train</p></li>
<li><p><strong>data</strong> (<em>tuple</em>) – training data</p></li>
<li><p><strong>epochs</strong> (<em>int</em>) – number of epochs to train the model for</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – batch size to use for training</p></li>
<li><p><strong>min_rate</strong> (<em>float</em>) – minimum learning rate to consider</p></li>
<li><p><strong>max_rate</strong> (<em>float</em>) – maximum learning rate to consider</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>learning rate that resulted in the lowest loss</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.get_hard_counts">
<span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">get_hard_counts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">soft_counts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.get_hard_counts" title="Permalink to this definition"></a></dt>
<dd><p>Computes hard counts per cluster in a differentiable way</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>soft_counts</strong> (<em>tf.Tensor</em>) – soft counts per cluster</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.cluster_frequencies_regularizer">
<span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">cluster_frequencies_regularizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">soft_counts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_samples</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1000</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.cluster_frequencies_regularizer" title="Permalink to this definition"></a></dt>
<dd><p>Computes the KL divergence between the cluster assignment distribution
and a uniform prior across clusters. While this assumes an equal distribution
between clusters, the prior can be tweaked to reflect domain knowledge.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>soft_counts</strong> (<em>tf.Tensor</em>) – soft counts per cluster</p></li>
<li><p><strong>k</strong> (<em>int</em>) – number of clusters</p></li>
<li><p><strong>n_samples</strong> (<em>int</em>) – number of samples to draw from the categorical distribution</p></li>
<li><p><strong>assignments.</strong> (<em>modeling cluster</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.get_callbacks">
<span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">get_callbacks</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embedding_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kmeans_loss</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logparam</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outpath</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'.'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">run</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#deepof.unsupervised_utils.get_callbacks" title="Permalink to this definition"></a></dt>
<dd><p>Generates callbacks used for model training.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>embedding_model</strong> (<em>str</em>) – name of the embedding model</p></li>
<li><p><strong>kmeans_loss</strong> (<em>float</em>) – Weight of the gram loss</p></li>
<li><p><strong>input_type</strong> (<em>str</em>) – Input type to use for training</p></li>
<li><p><strong>cp</strong> (<em>bool</em>) – Whether to use checkpointing or not</p></li>
<li><p><strong>logparam</strong> (<em>dict</em>) – Dictionary containing the hyperparameters to log in tensorboard</p></li>
<li><p><strong>outpath</strong> (<em>str</em>) – Path to the output directory</p></li>
<li><p><strong>run</strong> (<em>int</em>) – Run number to use for checkpointing</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of callbacks to be used for training</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[Union[Any]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.CustomStopper">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">CustomStopper</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">start_epoch</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.CustomStopper" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">EarlyStopping</span></code></p>
<p>Custom early stopping callback. Prevents the model from stopping before warmup is over.</p>
<dl class="py method">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.CustomStopper.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">start_epoch</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.CustomStopper.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Initializes the CustomStopper callback.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>start_epoch</strong> – epoch from which performance will be taken into account when deciding whether to stop training.</p></li>
<li><p><strong>*args</strong> – arguments passed to the callback.</p></li>
<li><p><strong>**kwargs</strong> – keyword arguments passed to the callback.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.CustomStopper.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.CustomStopper.get_config" title="Permalink to this definition"></a></dt>
<dd><p>Updates callback metadata</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.CustomStopper.on_epoch_end">
<span class="sig-name descname"><span class="pre">on_epoch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.CustomStopper.on_epoch_end" title="Permalink to this definition"></a></dt>
<dd><p>Called at the end of an epoch.</p>
<p>Subclasses should override for any actions to run. This function should only
be called during TRAIN mode.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> – Integer, index of epoch.</p></li>
<li><p><strong>logs</strong> – <dl>
<dt>Dict, metric results for this training epoch, and for the</dt><dd><p>validation epoch if validation is performed. Validation result keys
are prefixed with <cite>val_</cite>. For training epoch, the values of the</p>
</dd>
<dt><cite>Model</cite>’s metrics are returned. Example<span class="classifier"><a href="#id1"><span class="problematic" id="id2">`</span></a>{‘loss’: 0.2, ‘accuracy’:</span></dt><dd><p>0.7}`.</p>
</dd>
</dl>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.ExponentialLearningRate">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">ExponentialLearningRate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.ExponentialLearningRate" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Callback</span></code></p>
<p>Simple class that allows to grow learning rate exponentially during training.
Used to trigger optimal learning rate search in deepof.train_utils.find_learning_rate.</p>
<dl class="py method">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.ExponentialLearningRate.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.ExponentialLearningRate.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Initializes the exponential learning rate callback</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>factor</strong> (<em>float</em>) – factor by which to multiply the learning rate</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.ExponentialLearningRate.on_batch_end">
<span class="sig-name descname"><span class="pre">on_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.ExponentialLearningRate.on_batch_end" title="Permalink to this definition"></a></dt>
<dd><p>This callback acts after processing each batch</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> – batch number</p></li>
<li><p><strong>logs</strong> (<em>dict</em>) – dictionary containing the loss for the current batch</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.ProbabilisticDecoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">ProbabilisticDecoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.ProbabilisticDecoder" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Layer</span></code></p>
<p>Maps the reconstruction output of a given decoder to a multivariate normal distribution.</p>
<dl class="py method">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.ProbabilisticDecoder.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.ProbabilisticDecoder.__init__" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.ProbabilisticDecoder.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.ProbabilisticDecoder.call" title="Permalink to this definition"></a></dt>
<dd><p>Maps the reconstruction output of a given decoder to a multivariate normal distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>tuple</em>) – tuple containing the reconstruction output and the validity mask</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>multivariate normal distribution</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.ClusterControl">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">ClusterControl</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.ClusterControl" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Layer</span></code></p>
<p>Identity layer that evaluates different clustering metrics between the components of the latent Gaussian Mixture
using the entropy of the nearest neighbourhood. If self.loss_weight &gt; 0, it also adds a regularization
penalty to the loss function which attempts to maximize the number of populated clusters during training.</p>
<dl class="py method">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.ClusterControl.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_components</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoding_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">15</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.ClusterControl.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Initializes the ClusterControl layer</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_size</strong> (<em>int</em>) – batch size of the model</p></li>
<li><p><strong>n_components</strong> (<em>int</em>) – number of components in the latent Gaussian Mixture</p></li>
<li><p><strong>encoding_dim</strong> (<em>int</em>) – dimension of the latent Gaussian Mixture</p></li>
<li><p><strong>k</strong> (<em>int</em>) – number of nearest components of the latent Gaussian Mixture to consider</p></li>
<li><p><strong>loss_weight</strong> (<em>float</em>) – weight of the regularization penalty applied to the local entropy of each</p></li>
<li><p><strong>instance</strong> (<em>training</em>) – </p></li>
<li><p><strong>*args</strong> – additional positional arguments</p></li>
<li><p><strong>**kwargs</strong> – additional keyword arguments</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.ClusterControl.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.ClusterControl.get_config" title="Permalink to this definition"></a></dt>
<dd><p>Updates Constraint metadata</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.ClusterControl.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.ClusterControl.call" title="Permalink to this definition"></a></dt>
<dd><p>Updates Layer’s call method</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.KLDivergenceLayer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">KLDivergenceLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.KLDivergenceLayer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">KLDivergenceAddLoss</span></code></p>
<p>Identity transform layer that adds KL Divergence
to the final model loss.</p>
<dl class="py method">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.KLDivergenceLayer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">iters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_up_iters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">annealing_mode</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.KLDivergenceLayer.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Initializes the KL Divergence layer</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>iters</strong> (<em>int</em>) – number of training iterations taken so far</p></li>
<li><p><strong>warm_up_iters</strong> (<em>int</em>) – maximum number of training iterations for warmup</p></li>
<li><p><strong>annealing_mode</strong> (<em>str</em>) – mode of annealing, either ‘linear’ or ‘sigmoid’</p></li>
<li><p><strong>*args</strong> – additional positional arguments</p></li>
<li><p><strong>**kwargs</strong> – additional keyword arguments</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.KLDivergenceLayer.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.KLDivergenceLayer.get_config" title="Permalink to this definition"></a></dt>
<dd><p>Updates Constraint metadata</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.KLDivergenceLayer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">distribution_a</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.KLDivergenceLayer.call" title="Permalink to this definition"></a></dt>
<dd><p>Updates Layer’s call method</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.TransformerEncoderLayer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">TransformerEncoderLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.TransformerEncoderLayer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Layer</span></code></p>
<p>Transformer encoder layer. Based on <a class="reference external" href="https://www.tensorflow.org/text/tutorials/transformer">https://www.tensorflow.org/text/tutorials/transformer</a>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.TransformerEncoderLayer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">key_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_heads</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dff</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.TransformerEncoderLayer.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Constructor for the transformer encoder layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>key_dim</strong> – dimensionality of the time series</p></li>
<li><p><strong>num_heads</strong> – number of heads of the multi-head-attention layers</p></li>
<li><p><strong>dff</strong> – dimensionality of the embeddings</p></li>
<li><p><strong>rate</strong> – dropout rate</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.TransformerEncoderLayer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_scores</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.TransformerEncoderLayer.call" title="Permalink to this definition"></a></dt>
<dd><p>This is where the layer’s logic lives.</p>
<p>The <cite>call()</cite> method may not create state (except in its first invocation,
wrapping the creation of variables or other resources in <cite>tf.init_scope()</cite>).
It is recommended to create state in <cite>__init__()</cite>, or the <cite>build()</cite> method
that is called automatically before <cite>call()</cite> executes the first time.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – <p>Input tensor, or dict/list/tuple of input tensors.
The first positional <cite>inputs</cite> argument is subject to special rules:
- <cite>inputs</cite> must be explicitly passed. A layer cannot have zero</p>
<blockquote>
<div><p>arguments, and <cite>inputs</cite> cannot be provided via the default value
of a keyword argument.</p>
</div></blockquote>
<ul>
<li><p>NumPy array or Python scalar values in <cite>inputs</cite> get cast as tensors.</p></li>
<li><p>Keras mask metadata is only collected from <cite>inputs</cite>.</p></li>
<li><p>Layers are built (<cite>build(input_shape)</cite> method)
using shape info from <cite>inputs</cite> only.</p></li>
<li><p><cite>input_spec</cite> compatibility is only checked against <cite>inputs</cite>.</p></li>
<li><p>Mixed precision input casting is only applied to <cite>inputs</cite>.
If a layer has tensor arguments in <cite>*args</cite> or <cite>**kwargs</cite>, their
casting behavior in mixed precision should be handled manually.</p></li>
<li><p>The SavedModel input specification is generated using <cite>inputs</cite> only.</p></li>
<li><p>Integration with various ecosystem packages like TFMOT, TFLite,
TF.js, etc is only supported for <cite>inputs</cite> and not for tensors in
positional and keyword arguments.</p></li>
</ul>
</p></li>
<li><p><strong>*args</strong> – Additional positional arguments. May contain tensors, although
this is not recommended, for the reasons above.</p></li>
<li><p><strong>**kwargs</strong> – <p>Additional keyword arguments. May contain tensors, although
this is not recommended, for the reasons above.
The following optional keyword arguments are reserved:
- <cite>training</cite>: Boolean scalar tensor of Python boolean indicating</p>
<blockquote>
<div><p>whether the <cite>call</cite> is meant for training or inference.</p>
</div></blockquote>
<ul>
<li><p><cite>mask</cite>: Boolean input mask. If the layer’s <cite>call()</cite> method takes a
<cite>mask</cite> argument, its default value will be set to the mask generated
for <cite>inputs</cite> by the previous layer (if <cite>input</cite> did come from a layer
that generated a corresponding mask, i.e. if it came from a Keras
layer with masking support).</p></li>
</ul>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor or list/tuple of tensors.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.TransformerDecoderLayer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">TransformerDecoderLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.TransformerDecoderLayer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Layer</span></code></p>
<p>Transformer decoder layer. Based on <a class="reference external" href="https://www.tensorflow.org/text/tutorials/transformer">https://www.tensorflow.org/text/tutorials/transformer</a>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.TransformerDecoderLayer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">key_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_heads</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dff</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.TransformerDecoderLayer.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Constructor for the transformer decoder layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>key_dim</strong> – dimensionality of the time series</p></li>
<li><p><strong>num_heads</strong> – number of heads of the multi-head-attention layers</p></li>
<li><p><strong>dff</strong> – dimensionality of the embeddings</p></li>
<li><p><strong>rate</strong> – dropout rate</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.TransformerDecoderLayer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enc_output</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">look_ahead_mask</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_mask</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.TransformerDecoderLayer.call" title="Permalink to this definition"></a></dt>
<dd><p>This is where the layer’s logic lives.</p>
<p>The <cite>call()</cite> method may not create state (except in its first invocation,
wrapping the creation of variables or other resources in <cite>tf.init_scope()</cite>).
It is recommended to create state in <cite>__init__()</cite>, or the <cite>build()</cite> method
that is called automatically before <cite>call()</cite> executes the first time.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – <p>Input tensor, or dict/list/tuple of input tensors.
The first positional <cite>inputs</cite> argument is subject to special rules:
- <cite>inputs</cite> must be explicitly passed. A layer cannot have zero</p>
<blockquote>
<div><p>arguments, and <cite>inputs</cite> cannot be provided via the default value
of a keyword argument.</p>
</div></blockquote>
<ul>
<li><p>NumPy array or Python scalar values in <cite>inputs</cite> get cast as tensors.</p></li>
<li><p>Keras mask metadata is only collected from <cite>inputs</cite>.</p></li>
<li><p>Layers are built (<cite>build(input_shape)</cite> method)
using shape info from <cite>inputs</cite> only.</p></li>
<li><p><cite>input_spec</cite> compatibility is only checked against <cite>inputs</cite>.</p></li>
<li><p>Mixed precision input casting is only applied to <cite>inputs</cite>.
If a layer has tensor arguments in <cite>*args</cite> or <cite>**kwargs</cite>, their
casting behavior in mixed precision should be handled manually.</p></li>
<li><p>The SavedModel input specification is generated using <cite>inputs</cite> only.</p></li>
<li><p>Integration with various ecosystem packages like TFMOT, TFLite,
TF.js, etc is only supported for <cite>inputs</cite> and not for tensors in
positional and keyword arguments.</p></li>
</ul>
</p></li>
<li><p><strong>*args</strong> – Additional positional arguments. May contain tensors, although
this is not recommended, for the reasons above.</p></li>
<li><p><strong>**kwargs</strong> – <p>Additional keyword arguments. May contain tensors, although
this is not recommended, for the reasons above.
The following optional keyword arguments are reserved:
- <cite>training</cite>: Boolean scalar tensor of Python boolean indicating</p>
<blockquote>
<div><p>whether the <cite>call</cite> is meant for training or inference.</p>
</div></blockquote>
<ul>
<li><p><cite>mask</cite>: Boolean input mask. If the layer’s <cite>call()</cite> method takes a
<cite>mask</cite> argument, its default value will be set to the mask generated
for <cite>inputs</cite> by the previous layer (if <cite>input</cite> did come from a layer
that generated a corresponding mask, i.e. if it came from a Keras
layer with masking support).</p></li>
</ul>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor or list/tuple of tensors.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.TransformerEncoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">TransformerEncoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.TransformerEncoder" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Layer</span></code></p>
<p>Transformer encoder. Based on <a class="reference external" href="https://www.tensorflow.org/text/tutorials/transformer">https://www.tensorflow.org/text/tutorials/transformer</a>.
Adapted according to <a class="reference external" href="https://academic.oup.com/gigascience/article/8/11/giz134/5626377?login=true">https://academic.oup.com/gigascience/article/8/11/giz134/5626377?login=true</a>
and <a class="reference external" href="https://arxiv.org/abs/1711.03905">https://arxiv.org/abs/1711.03905</a>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.TransformerEncoder.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seq_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">key_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_heads</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dff</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximum_position_encoding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.TransformerEncoder.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Constructor for the transformer encoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_layers</strong> – number of transformer layers to include.</p></li>
<li><p><strong>seq_dim</strong> – dimensionality of the sequence embeddings</p></li>
<li><p><strong>key_dim</strong> – dimensionality of the time series</p></li>
<li><p><strong>num_heads</strong> – number of heads of the multi-head-attention layers used on the transformer encoder</p></li>
<li><p><strong>dff</strong> – dimensionality of the token embeddings</p></li>
<li><p><strong>maximum_position_encoding</strong> – maximum time series length</p></li>
<li><p><strong>rate</strong> – dropout rate</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.TransformerEncoder.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.TransformerEncoder.call" title="Permalink to this definition"></a></dt>
<dd><p>This is where the layer’s logic lives.</p>
<p>The <cite>call()</cite> method may not create state (except in its first invocation,
wrapping the creation of variables or other resources in <cite>tf.init_scope()</cite>).
It is recommended to create state in <cite>__init__()</cite>, or the <cite>build()</cite> method
that is called automatically before <cite>call()</cite> executes the first time.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – <p>Input tensor, or dict/list/tuple of input tensors.
The first positional <cite>inputs</cite> argument is subject to special rules:
- <cite>inputs</cite> must be explicitly passed. A layer cannot have zero</p>
<blockquote>
<div><p>arguments, and <cite>inputs</cite> cannot be provided via the default value
of a keyword argument.</p>
</div></blockquote>
<ul>
<li><p>NumPy array or Python scalar values in <cite>inputs</cite> get cast as tensors.</p></li>
<li><p>Keras mask metadata is only collected from <cite>inputs</cite>.</p></li>
<li><p>Layers are built (<cite>build(input_shape)</cite> method)
using shape info from <cite>inputs</cite> only.</p></li>
<li><p><cite>input_spec</cite> compatibility is only checked against <cite>inputs</cite>.</p></li>
<li><p>Mixed precision input casting is only applied to <cite>inputs</cite>.
If a layer has tensor arguments in <cite>*args</cite> or <cite>**kwargs</cite>, their
casting behavior in mixed precision should be handled manually.</p></li>
<li><p>The SavedModel input specification is generated using <cite>inputs</cite> only.</p></li>
<li><p>Integration with various ecosystem packages like TFMOT, TFLite,
TF.js, etc is only supported for <cite>inputs</cite> and not for tensors in
positional and keyword arguments.</p></li>
</ul>
</p></li>
<li><p><strong>*args</strong> – Additional positional arguments. May contain tensors, although
this is not recommended, for the reasons above.</p></li>
<li><p><strong>**kwargs</strong> – <p>Additional keyword arguments. May contain tensors, although
this is not recommended, for the reasons above.
The following optional keyword arguments are reserved:
- <cite>training</cite>: Boolean scalar tensor of Python boolean indicating</p>
<blockquote>
<div><p>whether the <cite>call</cite> is meant for training or inference.</p>
</div></blockquote>
<ul>
<li><p><cite>mask</cite>: Boolean input mask. If the layer’s <cite>call()</cite> method takes a
<cite>mask</cite> argument, its default value will be set to the mask generated
for <cite>inputs</cite> by the previous layer (if <cite>input</cite> did come from a layer
that generated a corresponding mask, i.e. if it came from a Keras
layer with masking support).</p></li>
</ul>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor or list/tuple of tensors.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.TransformerDecoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">TransformerDecoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.TransformerDecoder" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Layer</span></code></p>
<p>Transformer decoder. Based on <a class="reference external" href="https://www.tensorflow.org/text/tutorials/transformer">https://www.tensorflow.org/text/tutorials/transformer</a>.
Adapted according to <a class="reference external" href="https://academic.oup.com/gigascience/article/8/11/giz134/5626377?login=true">https://academic.oup.com/gigascience/article/8/11/giz134/5626377?login=true</a>
and <a class="reference external" href="https://arxiv.org/abs/1711.03905">https://arxiv.org/abs/1711.03905</a>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.TransformerDecoder.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seq_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">key_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_heads</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dff</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximum_position_encoding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.TransformerDecoder.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Constructor for the transformer decoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_layers</strong> – number of transformer layers to include.</p></li>
<li><p><strong>seq_dim</strong> – dimensionality of the sequence embeddings</p></li>
<li><p><strong>key_dim</strong> – dimensionality of the time series</p></li>
<li><p><strong>num_heads</strong> – number of heads of the multi-head-attention layers used on the transformer encoder</p></li>
<li><p><strong>dff</strong> – dimensionality of the token embeddings</p></li>
<li><p><strong>maximum_position_encoding</strong> – maximum time series length</p></li>
<li><p><strong>rate</strong> – dropout rate</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.TransformerDecoder.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enc_output</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">look_ahead_mask</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_mask</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.TransformerDecoder.call" title="Permalink to this definition"></a></dt>
<dd><p>This is where the layer’s logic lives.</p>
<p>The <cite>call()</cite> method may not create state (except in its first invocation,
wrapping the creation of variables or other resources in <cite>tf.init_scope()</cite>).
It is recommended to create state in <cite>__init__()</cite>, or the <cite>build()</cite> method
that is called automatically before <cite>call()</cite> executes the first time.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – <p>Input tensor, or dict/list/tuple of input tensors.
The first positional <cite>inputs</cite> argument is subject to special rules:
- <cite>inputs</cite> must be explicitly passed. A layer cannot have zero</p>
<blockquote>
<div><p>arguments, and <cite>inputs</cite> cannot be provided via the default value
of a keyword argument.</p>
</div></blockquote>
<ul>
<li><p>NumPy array or Python scalar values in <cite>inputs</cite> get cast as tensors.</p></li>
<li><p>Keras mask metadata is only collected from <cite>inputs</cite>.</p></li>
<li><p>Layers are built (<cite>build(input_shape)</cite> method)
using shape info from <cite>inputs</cite> only.</p></li>
<li><p><cite>input_spec</cite> compatibility is only checked against <cite>inputs</cite>.</p></li>
<li><p>Mixed precision input casting is only applied to <cite>inputs</cite>.
If a layer has tensor arguments in <cite>*args</cite> or <cite>**kwargs</cite>, their
casting behavior in mixed precision should be handled manually.</p></li>
<li><p>The SavedModel input specification is generated using <cite>inputs</cite> only.</p></li>
<li><p>Integration with various ecosystem packages like TFMOT, TFLite,
TF.js, etc is only supported for <cite>inputs</cite> and not for tensors in
positional and keyword arguments.</p></li>
</ul>
</p></li>
<li><p><strong>*args</strong> – Additional positional arguments. May contain tensors, although
this is not recommended, for the reasons above.</p></li>
<li><p><strong>**kwargs</strong> – <p>Additional keyword arguments. May contain tensors, although
this is not recommended, for the reasons above.
The following optional keyword arguments are reserved:
- <cite>training</cite>: Boolean scalar tensor of Python boolean indicating</p>
<blockquote>
<div><p>whether the <cite>call</cite> is meant for training or inference.</p>
</div></blockquote>
<ul>
<li><p><cite>mask</cite>: Boolean input mask. If the layer’s <cite>call()</cite> method takes a
<cite>mask</cite> argument, its default value will be set to the mask generated
for <cite>inputs</cite> by the previous layer (if <cite>input</cite> did come from a layer
that generated a corresponding mask, i.e. if it came from a Keras
layer with masking support).</p></li>
</ul>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor or list/tuple of tensors.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.log_hyperparameters">
<span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">log_hyperparameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.log_hyperparameters" title="Permalink to this definition"></a></dt>
<dd><p>Blueprint for hyperparameter and metric logging in tensorboard during hyperparameter tuning</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>List containing the hyperparameters to log in tensorboard.
metrics (list): List containing the metrics to log in tensorboard.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>logparams (list)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.autoencoder_fitting">
<span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">autoencoder_fitting</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">preprocessed_object</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">latent_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_history</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_hparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_components</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kmeans_loss</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pretrained</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_checkpoints</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kl_annealing_mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kl_warmup</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_cat_clusters</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">run</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Strategy</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'one_device'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.unsupervised_utils.autoencoder_fitting" title="Permalink to this definition"></a></dt>
<dd><p>Trains the specified autoencoder on the preprocessed data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>preprocessed_object</strong> (<em>tuple</em>) – Tuple containing the preprocessed data.</p></li>
<li><p><strong>embedding_model</strong> (<em>str</em>) – Model to use to embed and cluster the data. Must be one of VQVAE (default), GMVAE,</p></li>
<li><p><strong>contrastive.</strong> (<em>and</em>) – </p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – Batch size to use for training.</p></li>
<li><p><strong>latent_dim</strong> (<em>int</em>) – Encoding size to use for training.</p></li>
<li><p><strong>epochs</strong> (<em>int</em>) – Number of epochs to train the autoencoder for.</p></li>
<li><p><strong>log_history</strong> (<em>bool</em>) – Whether to log the history of the autoencoder.</p></li>
<li><p><strong>log_hparams</strong> (<em>bool</em>) – Whether to log the hyperparameters used for training.</p></li>
<li><p><strong>n_components</strong> (<em>int</em>) – Number of components to fit to the data.</p></li>
<li><p><strong>output_path</strong> (<em>str</em>) – Path to the output directory.</p></li>
<li><p><strong>kmeans_loss</strong> (<em>float</em>) – Weight of the gram loss, which adds a regularization term to VQVAE models which</p></li>
<li><p><strong>space.</strong> (<em>penalizes the correlation between the dimensions in the latent</em>) – </p></li>
<li><p><strong>pretrained</strong> (<em>str</em>) – Path to the pretrained weights to use for the autoencoder.</p></li>
<li><p><strong>save_checkpoints</strong> (<em>bool</em>) – Whether to save checkpoints during training.</p></li>
<li><p><strong>save_weights</strong> (<em>bool</em>) – Whether to save the weights of the autoencoder after training.</p></li>
<li><p><strong>input_type</strong> (<em>str</em>) – Input type of the TableDict objects used for preprocessing. For logging purposes only.</p></li>
<li><p><strong>run</strong> (<em>int</em>) – Run number to use for logging.</p></li>
<li><p><strong>strategy</strong> (<em>tf.distribute.Strategy</em>) – Distribution strategy to use for training.</p></li>
<li><p><strong>parameters</strong> (<em># GMVAE Model specific</em>) – </p></li>
<li><p><strong>kl_annealing_mode</strong> (<em>str</em>) – Mode to use for KL annealing. Must be one of “linear” (default), or “sigmoid”.</p></li>
<li><p><strong>kl_warmup</strong> (<em>int</em>) – Number of epochs during which KL is annealed.</p></li>
<li><p><strong>reg_cat_clusters</strong> (<em>bool</em>) – whether to use the penalize uneven cluster membership in the latent space, by</p></li>
<li><p><strong>distribution.</strong> (<em>minimizing the KL divergence between cluster membership and a uniform categorical</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of trained models corresponding to the selected model class. The full trained model is last.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.unsupervised_utils.tune_search">
<span class="sig-prename descclassname"><span class="pre">deepof.unsupervised_utils.</span></span><span class="sig-name descname"><span class="pre">tune_search</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tuple</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoding_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hypertun_trials</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hpt_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">project_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_epochs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">30</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_replicas</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outpath</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'unsupervised_tuner_search'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span></span></span><a class="headerlink" href="#deepof.unsupervised_utils.tune_search" title="Permalink to this definition"></a></dt>
<dd><p>Define the search space using keras-tuner and hyperband or bayesian optimization</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>tf.data.Dataset</em>) – Dataset object for training and validation.</p></li>
<li><p><strong>encoding_size</strong> (<em>int</em>) – Size of the encoding layer.</p></li>
<li><p><strong>embedding_model</strong> (<em>str</em>) – Model to use to embed and cluster the data. Must be one of VQVAE (default), GMVAE,</p></li>
<li><p><strong>contrastive.</strong> (<em>and</em>) – </p></li>
<li><p><strong>hypertun_trials</strong> (<em>int</em>) – Number of hypertuning trials to run.</p></li>
<li><p><strong>hpt_type</strong> (<em>str</em>) – Type of hypertuning to run. Must be one of “hyperband” or “bayesian”.</p></li>
<li><p><strong>k</strong> (<em>int</em>) – Number of clusters on the latent space.</p></li>
<li><p><strong>kmeans_loss</strong> (<em>float</em>) – Weight of the kmeans loss, which enforces disentanglement by penalizing the correlation</p></li>
<li><p><strong>space.</strong> (<em>between dimensions in the latent</em>) – </p></li>
<li><p><strong>project_name</strong> (<em>str</em>) – Name of the project.</p></li>
<li><p><strong>callbacks</strong> (<em>List</em>) – List of callbacks to use.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – Batch size to use.</p></li>
<li><p><strong>n_epochs</strong> (<em>int</em>) – Maximum number of epochs to train for.</p></li>
<li><p><strong>n_replicas</strong> (<em>int</em>) – Number of replicas to use.</p></li>
<li><p><strong>outpath</strong> (<em>str</em>) – Path to save the results.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Dictionary of the best hyperparameters.
best_run (str): Name of the best run.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>best_hparams (dict)</p>
</dd>
</dl>
</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="deepof.supervised_utils.html" class="btn btn-neutral float-left" title="deepof.supervised_utils module" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="deepof.models.html" class="btn btn-neutral float-right" title="deepof.models module" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Lucas Miranda.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>