<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>deepof.model_utils module &mdash; deepof 0.2 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/jupyter-sphinx.css" type="text/css" />
      <link rel="stylesheet" href="_static/thebelab.css" type="text/css" />
    <link rel="shortcut icon" href="_static/deepof.ico"/>
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
        <script src="_static/thebelab-helper.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            deepof
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">deepof.model_utils module</a><ul>
<li><a class="reference internal" href="#deepof.model_utils.select_contrastive_loss"><code class="docutils literal notranslate"><span class="pre">select_contrastive_loss()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.nce_loss"><code class="docutils literal notranslate"><span class="pre">nce_loss()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.dcl_loss"><code class="docutils literal notranslate"><span class="pre">dcl_loss()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.fc_loss"><code class="docutils literal notranslate"><span class="pre">fc_loss()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.hard_loss"><code class="docutils literal notranslate"><span class="pre">hard_loss()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.compute_kmeans_loss"><code class="docutils literal notranslate"><span class="pre">compute_kmeans_loss()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.get_k_nearest_neighbors"><code class="docutils literal notranslate"><span class="pre">get_k_nearest_neighbors()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.compute_shannon_entropy"><code class="docutils literal notranslate"><span class="pre">compute_shannon_entropy()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.plot_lr_vs_loss"><code class="docutils literal notranslate"><span class="pre">plot_lr_vs_loss()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.get_angles"><code class="docutils literal notranslate"><span class="pre">get_angles()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.get_recurrent_block"><code class="docutils literal notranslate"><span class="pre">get_recurrent_block()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.positional_encoding"><code class="docutils literal notranslate"><span class="pre">positional_encoding()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.create_padding_mask"><code class="docutils literal notranslate"><span class="pre">create_padding_mask()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.create_look_ahead_mask"><code class="docutils literal notranslate"><span class="pre">create_look_ahead_mask()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.create_masks"><code class="docutils literal notranslate"><span class="pre">create_masks()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.find_learning_rate"><code class="docutils literal notranslate"><span class="pre">find_learning_rate()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.get_hard_counts"><code class="docutils literal notranslate"><span class="pre">get_hard_counts()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.cluster_frequencies_regularizer"><code class="docutils literal notranslate"><span class="pre">cluster_frequencies_regularizer()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.get_callbacks"><code class="docutils literal notranslate"><span class="pre">get_callbacks()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.CustomStopper"><code class="docutils literal notranslate"><span class="pre">CustomStopper</span></code></a><ul>
<li><a class="reference internal" href="#deepof.model_utils.CustomStopper.__init__"><code class="docutils literal notranslate"><span class="pre">CustomStopper.__init__()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.CustomStopper.get_config"><code class="docutils literal notranslate"><span class="pre">CustomStopper.get_config()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.CustomStopper.on_epoch_end"><code class="docutils literal notranslate"><span class="pre">CustomStopper.on_epoch_end()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#deepof.model_utils.ExponentialLearningRate"><code class="docutils literal notranslate"><span class="pre">ExponentialLearningRate</span></code></a><ul>
<li><a class="reference internal" href="#deepof.model_utils.ExponentialLearningRate.__init__"><code class="docutils literal notranslate"><span class="pre">ExponentialLearningRate.__init__()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.ExponentialLearningRate.on_batch_end"><code class="docutils literal notranslate"><span class="pre">ExponentialLearningRate.on_batch_end()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#deepof.model_utils.ProbabilisticDecoder"><code class="docutils literal notranslate"><span class="pre">ProbabilisticDecoder</span></code></a><ul>
<li><a class="reference internal" href="#deepof.model_utils.ProbabilisticDecoder.__init__"><code class="docutils literal notranslate"><span class="pre">ProbabilisticDecoder.__init__()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.ProbabilisticDecoder.call"><code class="docutils literal notranslate"><span class="pre">ProbabilisticDecoder.call()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#deepof.model_utils.ClusterControl"><code class="docutils literal notranslate"><span class="pre">ClusterControl</span></code></a><ul>
<li><a class="reference internal" href="#deepof.model_utils.ClusterControl.__init__"><code class="docutils literal notranslate"><span class="pre">ClusterControl.__init__()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.ClusterControl.get_config"><code class="docutils literal notranslate"><span class="pre">ClusterControl.get_config()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.ClusterControl.call"><code class="docutils literal notranslate"><span class="pre">ClusterControl.call()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#deepof.model_utils.TransformerEncoderLayer"><code class="docutils literal notranslate"><span class="pre">TransformerEncoderLayer</span></code></a><ul>
<li><a class="reference internal" href="#deepof.model_utils.TransformerEncoderLayer.__init__"><code class="docutils literal notranslate"><span class="pre">TransformerEncoderLayer.__init__()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.TransformerEncoderLayer.call"><code class="docutils literal notranslate"><span class="pre">TransformerEncoderLayer.call()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#deepof.model_utils.TransformerDecoderLayer"><code class="docutils literal notranslate"><span class="pre">TransformerDecoderLayer</span></code></a><ul>
<li><a class="reference internal" href="#deepof.model_utils.TransformerDecoderLayer.__init__"><code class="docutils literal notranslate"><span class="pre">TransformerDecoderLayer.__init__()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.TransformerDecoderLayer.call"><code class="docutils literal notranslate"><span class="pre">TransformerDecoderLayer.call()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#deepof.model_utils.TransformerEncoder"><code class="docutils literal notranslate"><span class="pre">TransformerEncoder</span></code></a><ul>
<li><a class="reference internal" href="#deepof.model_utils.TransformerEncoder.__init__"><code class="docutils literal notranslate"><span class="pre">TransformerEncoder.__init__()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.TransformerEncoder.call"><code class="docutils literal notranslate"><span class="pre">TransformerEncoder.call()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#deepof.model_utils.TransformerDecoder"><code class="docutils literal notranslate"><span class="pre">TransformerDecoder</span></code></a><ul>
<li><a class="reference internal" href="#deepof.model_utils.TransformerDecoder.__init__"><code class="docutils literal notranslate"><span class="pre">TransformerDecoder.__init__()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.TransformerDecoder.call"><code class="docutils literal notranslate"><span class="pre">TransformerDecoder.call()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#deepof.model_utils.log_hyperparameters"><code class="docutils literal notranslate"><span class="pre">log_hyperparameters()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.embedding_model_fitting"><code class="docutils literal notranslate"><span class="pre">embedding_model_fitting()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.embedding_per_video"><code class="docutils literal notranslate"><span class="pre">embedding_per_video()</span></code></a></li>
<li><a class="reference internal" href="#deepof.model_utils.tune_search"><code class="docutils literal notranslate"><span class="pre">tune_search()</span></code></a></li>
</ul>
</li>
</ul>
</div>
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">deepof</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">deepof.model_utils module</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/deepof.model_utils.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="deepof-model-utils-module">
<h1>deepof.model_utils module<a class="headerlink" href="#deepof-model-utils-module" title="Permalink to this heading"></a></h1>
<span class="target" id="module-deepof.model_utils"></span><p>Utility functions for both training autoencoder models in deepof.models and tuning hyperparameters with deepof.hypermodels.</p>
<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.select_contrastive_loss">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">select_contrastive_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">history</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">similarity</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'nce'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">elimination_topk</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attraction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.select_contrastive_loss" title="Permalink to this definition"></a></dt>
<dd><p>Select and applies the contrastive loss function to be used in the Contrastive embedding models.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>history</strong> – Tensor of shape (batch_size, seq_len, embedding_dim).</p></li>
<li><p><strong>future</strong> – Tensor of shape (batch_size, seq_len, embedding_dim).</p></li>
<li><p><strong>similarity</strong> – Function that computes the similarity between two tensors.</p></li>
<li><p><strong>loss_fn</strong> – String indicating the loss function to be used.</p></li>
<li><p><strong>temperature</strong> – Float indicating the temperature to be used in the specified loss function.</p></li>
<li><p><strong>tau</strong> – Float indicating the tau value to be used if DCL or hard DLC are selected.</p></li>
<li><p><strong>beta</strong> – Float indicating the beta value to be used if hard DLC is selected.</p></li>
<li><p><strong>elimination_topk</strong> – Float indicating the top-k value to be used if FC is selected.</p></li>
<li><p><strong>attraction</strong> – Boolean indicating whether to use attraction in FC.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.nce_loss">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">nce_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">history</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">similarity</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.nce_loss" title="Permalink to this definition"></a></dt>
<dd><p>Compute the NCE loss function, as described in the paper “A Simple Framework for Contrastive Learning of Visual Representations” (<a class="reference external" href="https://arxiv.org/abs/2002.05709">https://arxiv.org/abs/2002.05709</a>).</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.dcl_loss">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">dcl_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">history</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">similarity</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debiased</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_plus</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.dcl_loss" title="Permalink to this definition"></a></dt>
<dd><p>Compute the DCL loss function, as described in the paper “Debiased Contrastive Learning” (<a class="reference external" href="https://github.com/chingyaoc/DCL/">https://github.com/chingyaoc/DCL/</a>).</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.fc_loss">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">fc_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">history</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">similarity</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">elimination_topk</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attraction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.fc_loss" title="Permalink to this definition"></a></dt>
<dd><p>Compute the FC loss function, as described in the paper “Fully-Contrastive Learning of Visual Representations” (<a class="reference external" href="https://arxiv.org/abs/2004.11362">https://arxiv.org/abs/2004.11362</a>).</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.hard_loss">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">hard_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">history</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">future</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">similarity</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debiased</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_plus</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.hard_loss" title="Permalink to this definition"></a></dt>
<dd><p>Compute the Hard loss function, as described in the paper “Contrastive Learning with Hard Negative Samples” (<a class="reference external" href="https://arxiv.org/abs/2011.03343">https://arxiv.org/abs/2011.03343</a>).</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.compute_kmeans_loss">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">compute_kmeans_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">latent_means</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.compute_kmeans_loss" title="Permalink to this definition"></a></dt>
<dd><p>Add a penalty to the singular values of the Gram matrix of the latent means. It helps disentangle the latent space.</p>
<p>Based on <a class="reference external" href="https://arxiv.org/pdf/1610.04794.pdf">https://arxiv.org/pdf/1610.04794.pdf</a>, and <a class="reference external" href="https://www.biorxiv.org/content/10.1101/2020.05.14.095430v3">https://www.biorxiv.org/content/10.1101/2020.05.14.095430v3</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>latent_means</strong> – tensor containing the means of the latent distribution</p></li>
<li><p><strong>weight</strong> – weight of the Gram loss in the total loss function</p></li>
<li><p><strong>batch_size</strong> – batch size of the data to compute the kmeans loss for.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>kmeans loss</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.get_k_nearest_neighbors">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">get_k_nearest_neighbors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.get_k_nearest_neighbors" title="Permalink to this definition"></a></dt>
<dd><p>Retrieve indices of the k nearest neighbors in tensor to the vector with the specified index.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensor</strong> (<em>tf.Tensor</em>) – tensor to compute the k nearest neighbors for</p></li>
<li><p><strong>k</strong> (<em>int</em>) – number of nearest neighbors to retrieve</p></li>
<li><p><strong>index</strong> (<em>int</em>) – index of the vector to compute the k nearest neighbors for</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>indices of the k nearest neighbors</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.compute_shannon_entropy">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">compute_shannon_entropy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.compute_shannon_entropy" title="Permalink to this definition"></a></dt>
<dd><p>Compute Shannon entropy for a given tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>tensor</strong> (<em>tf.Tensor</em>) – tensor to compute the entropy for</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>entropy of the tensor</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.plot_lr_vs_loss">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">plot_lr_vs_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rates</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">losses</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.plot_lr_vs_loss" title="Permalink to this definition"></a></dt>
<dd><p>Plot learing rate versus the loss function of the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>rates</strong> (<em>np.ndarray</em>) – array containing the learning rates to plot in the x-axis</p></li>
<li><p><strong>losses</strong> (<em>np.ndarray</em>) – array containing the losses to plot in the y-axis</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.get_angles">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">get_angles</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pos</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">i</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.get_angles" title="Permalink to this definition"></a></dt>
<dd><p>Auxiliary function for positional encoding computation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pos</strong> (<em>int</em>) – position in the sequence.</p></li>
<li><p><strong>i</strong> (<em>int</em>) – number of sequences.</p></li>
<li><p><strong>d_model</strong> (<em>int</em>) – dimensionality of the embeddings.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.get_recurrent_block">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">get_recurrent_block</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">latent_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gru_unroll</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bidirectional_merge</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.get_recurrent_block" title="Permalink to this definition"></a></dt>
<dd><p>Build a recurrent embedding block, using a 1D convolution followed by two bidirectional GRU layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>tf.Tensor</em>) – Input tensor.</p></li>
<li><p><strong>latent_dim</strong> (<em>int</em>) – Number of dimensions of the output tensor.</p></li>
<li><p><strong>gru_unroll</strong> (<em>bool</em>) – whether to unroll the GRU layers. Defaults to False.</p></li>
<li><p><strong>bidirectional_merge</strong> (<em>str</em>) – how to merge the forward and backward GRU layers. Defaults to “concat”.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>tf.keras.models.Model object with the specified architecture.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.positional_encoding">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">positional_encoding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">position</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.positional_encoding" title="Permalink to this definition"></a></dt>
<dd><p>Compute positional encodings, as in <a class="reference external" href="https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>position</strong> (<em>int</em>) – position in the sequence.</p></li>
<li><p><strong>d_model</strong> (<em>int</em>) – dimensionality of the embeddings.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.create_padding_mask">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">create_padding_mask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seq</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.create_padding_mask" title="Permalink to this definition"></a></dt>
<dd><p>Create a padding mask, with zeros where data is missing, and ones where data is available.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>seq</strong> (<em>tf.Tensor</em>) – Sequence to compute the mask on</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.create_look_ahead_mask">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">create_look_ahead_mask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.create_look_ahead_mask" title="Permalink to this definition"></a></dt>
<dd><p>Create a triangular matrix containing an increasing amount of ones from left to right on each subsequent row.</p>
<p>Useful for transformer decoder, which allows it to go through the data in a sequential manner, without taking
the future into account.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>size</strong> (<em>int</em>) – number of time steps in the sequence</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.create_masks">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">create_masks</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.create_masks" title="Permalink to this definition"></a></dt>
<dd><p>Given an input sequence, it creates all necessary masks to pass it through the transformer architecture.</p>
<p>This includes encoder and decoder padding masks, and a look-ahead mask</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>inp</strong> (<em>tf.Tensor</em>) – input sequence to create the masks for.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.find_learning_rate">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">find_learning_rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.find_learning_rate" title="Permalink to this definition"></a></dt>
<dd><p>Train the provided model for an epoch with an exponentially increasing learning rate.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>tf.keras.Model</em>) – model to train</p></li>
<li><p><strong>data</strong> (<em>tuple</em>) – training data</p></li>
<li><p><strong>epochs</strong> (<em>int</em>) – number of epochs to train the model for</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – batch size to use for training</p></li>
<li><p><strong>min_rate</strong> (<em>float</em>) – minimum learning rate to consider</p></li>
<li><p><strong>max_rate</strong> (<em>float</em>) – maximum learning rate to consider</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>learning rate that resulted in the lowest loss</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.get_hard_counts">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">get_hard_counts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">soft_counts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.get_hard_counts" title="Permalink to this definition"></a></dt>
<dd><p>Compute hard counts per cluster in a differentiable way.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>soft_counts</strong> (<em>tf.Tensor</em>) – soft counts per cluster</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.cluster_frequencies_regularizer">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">cluster_frequencies_regularizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">soft_counts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_samples</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1000</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.cluster_frequencies_regularizer" title="Permalink to this definition"></a></dt>
<dd><p>Compute the KL divergence between the cluster assignment distribution and a uniform prior across clusters.</p>
<p>While this assumes an equal distribution between clusters, the prior can be tweaked to reflect domain knowledge.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>soft_counts</strong> (<em>tf.Tensor</em>) – soft counts per cluster</p></li>
<li><p><strong>k</strong> (<em>int</em>) – number of clusters</p></li>
<li><p><strong>n_samples</strong> (<em>int</em>) – number of samples to draw from the categorical distribution</p></li>
<li><p><strong>assignments.</strong> (<em>modeling cluster</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.get_callbacks">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">get_callbacks</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embedding_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kmeans_loss</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logparam</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outpath</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'.'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">run</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#deepof.model_utils.get_callbacks" title="Permalink to this definition"></a></dt>
<dd><p>Generate callbacks used for model training.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>embedding_model</strong> (<em>str</em>) – name of the embedding model</p></li>
<li><p><strong>encoder_type</strong> (<em>str</em>) – Architecture used for the encoder. Must be one of “recurrent”, “TCN”, and “transformer”</p></li>
<li><p><strong>kmeans_loss</strong> (<em>float</em>) – Weight of the gram loss</p></li>
<li><p><strong>input_type</strong> (<em>str</em>) – Input type to use for training</p></li>
<li><p><strong>cp</strong> (<em>bool</em>) – Whether to use checkpointing or not</p></li>
<li><p><strong>logparam</strong> (<em>dict</em>) – Dictionary containing the hyperparameters to log in tensorboard</p></li>
<li><p><strong>outpath</strong> (<em>str</em>) – Path to the output directory</p></li>
<li><p><strong>run</strong> (<em>int</em>) – Run number to use for checkpointing</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of callbacks to be used for training</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[Union[Any]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deepof.model_utils.CustomStopper">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">CustomStopper</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">start_epoch</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.CustomStopper" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">EarlyStopping</span></code></p>
<p>Custom early stopping callback. Prevents the model from stopping before warmup is over.</p>
<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.CustomStopper.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">start_epoch</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.CustomStopper.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Initialize the CustomStopper callback.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>start_epoch</strong> – epoch from which performance will be taken into account when deciding whether to stop training.</p></li>
<li><p><strong>*args</strong> – arguments passed to the callback.</p></li>
<li><p><strong>**kwargs</strong> – keyword arguments passed to the callback.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.CustomStopper.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.CustomStopper.get_config" title="Permalink to this definition"></a></dt>
<dd><p>Update callback metadata.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.CustomStopper.on_epoch_end">
<span class="sig-name descname"><span class="pre">on_epoch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.CustomStopper.on_epoch_end" title="Permalink to this definition"></a></dt>
<dd><p>Check whether to stop training.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deepof.model_utils.ExponentialLearningRate">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">ExponentialLearningRate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.ExponentialLearningRate" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Callback</span></code></p>
<p>Simple class that allows to grow learning rate exponentially during training.</p>
<p>Used to trigger optimal learning rate search in deepof.train_utils.find_learning_rate.</p>
<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.ExponentialLearningRate.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.ExponentialLearningRate.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Initialize the exponential learning rate callback.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>factor</strong> (<em>float</em>) – factor by which to multiply the learning rate</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.ExponentialLearningRate.on_batch_end">
<span class="sig-name descname"><span class="pre">on_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.ExponentialLearningRate.on_batch_end" title="Permalink to this definition"></a></dt>
<dd><p>Apply on batch end.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> – batch number</p></li>
<li><p><strong>logs</strong> (<em>dict</em>) – dictionary containing the loss for the current batch</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deepof.model_utils.ProbabilisticDecoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">ProbabilisticDecoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.ProbabilisticDecoder" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Layer</span></code></p>
<p>Map the reconstruction output of a given decoder to a multivariate normal distribution.</p>
<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.ProbabilisticDecoder.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.ProbabilisticDecoder.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Initialize the probabilistic decoder.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.ProbabilisticDecoder.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.ProbabilisticDecoder.call" title="Permalink to this definition"></a></dt>
<dd><p>Map the reconstruction output of a given decoder to a multivariate normal distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>tuple</em>) – tuple containing the reconstruction output and the validity mask</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>multivariate normal distribution</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deepof.model_utils.ClusterControl">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">ClusterControl</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.ClusterControl" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Layer</span></code></p>
<p>Identity layer.</p>
<p>Evaluates different clustering metrics between the components of the latent Gaussian Mixture
using the entropy of the nearest neighbourhood. If self.loss_weight &gt; 0, it also adds a regularization
penalty to the loss function which attempts to maximize the number of populated clusters during training.</p>
<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.ClusterControl.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_components</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoding_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">15</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.ClusterControl.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Initialize the ClusterControl layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_size</strong> (<em>int</em>) – batch size of the model</p></li>
<li><p><strong>n_components</strong> (<em>int</em>) – number of components in the latent Gaussian Mixture</p></li>
<li><p><strong>encoding_dim</strong> (<em>int</em>) – dimension of the latent Gaussian Mixture</p></li>
<li><p><strong>k</strong> (<em>int</em>) – number of nearest components of the latent Gaussian Mixture to consider</p></li>
<li><p><strong>loss_weight</strong> (<em>float</em>) – weight of the regularization penalty applied to the local entropy of each</p></li>
<li><p><strong>instance</strong> (<em>training</em>) – </p></li>
<li><p><strong>*args</strong> – additional positional arguments</p></li>
<li><p><strong>**kwargs</strong> – additional keyword arguments</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.ClusterControl.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.ClusterControl.get_config" title="Permalink to this definition"></a></dt>
<dd><p>Update Constraint metadata.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.ClusterControl.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.ClusterControl.call" title="Permalink to this definition"></a></dt>
<dd><p>Update Layer’s call method.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deepof.model_utils.TransformerEncoderLayer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">TransformerEncoderLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.TransformerEncoderLayer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Layer</span></code></p>
<p>Transformer encoder layer. Based on <a class="reference external" href="https://www.tensorflow.org/text/tutorials/transformer">https://www.tensorflow.org/text/tutorials/transformer</a>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.TransformerEncoderLayer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">key_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_heads</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dff</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.TransformerEncoderLayer.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Construct the transformer encoder layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>key_dim</strong> – dimensionality of the time series</p></li>
<li><p><strong>num_heads</strong> – number of heads of the multi-head-attention layers</p></li>
<li><p><strong>dff</strong> – dimensionality of the embeddings</p></li>
<li><p><strong>rate</strong> – dropout rate</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.TransformerEncoderLayer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_scores</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.TransformerEncoderLayer.call" title="Permalink to this definition"></a></dt>
<dd><p>Call the transformer encoder layer.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deepof.model_utils.TransformerDecoderLayer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">TransformerDecoderLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.TransformerDecoderLayer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Layer</span></code></p>
<p>Transformer decoder layer. Based on <a class="reference external" href="https://www.tensorflow.org/text/tutorials/transformer">https://www.tensorflow.org/text/tutorials/transformer</a>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.TransformerDecoderLayer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">key_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_heads</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dff</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.TransformerDecoderLayer.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Construct the transformer decoder layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>key_dim</strong> – dimensionality of the time series</p></li>
<li><p><strong>num_heads</strong> – number of heads of the multi-head-attention layers</p></li>
<li><p><strong>dff</strong> – dimensionality of the embeddings</p></li>
<li><p><strong>rate</strong> – dropout rate</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.TransformerDecoderLayer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enc_output</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">look_ahead_mask</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_mask</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.TransformerDecoderLayer.call" title="Permalink to this definition"></a></dt>
<dd><p>Call the transformer decoder layer.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deepof.model_utils.TransformerEncoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">TransformerEncoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.TransformerEncoder" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Layer</span></code></p>
<p>Transformer encoder.</p>
<p>Based on <a class="reference external" href="https://www.tensorflow.org/text/tutorials/transformer">https://www.tensorflow.org/text/tutorials/transformer</a>.
Adapted according to <a class="reference external" href="https://academic.oup.com/gigascience/article/8/11/giz134/5626377?login=true">https://academic.oup.com/gigascience/article/8/11/giz134/5626377?login=true</a>
and <a class="reference external" href="https://arxiv.org/abs/1711.03905">https://arxiv.org/abs/1711.03905</a>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.TransformerEncoder.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seq_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">key_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_heads</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dff</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximum_position_encoding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.TransformerEncoder.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Construct the transformer encoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_layers</strong> – number of transformer layers to include.</p></li>
<li><p><strong>seq_dim</strong> – dimensionality of the sequence embeddings</p></li>
<li><p><strong>key_dim</strong> – dimensionality of the time series</p></li>
<li><p><strong>num_heads</strong> – number of heads of the multi-head-attention layers used on the transformer encoder</p></li>
<li><p><strong>dff</strong> – dimensionality of the token embeddings</p></li>
<li><p><strong>maximum_position_encoding</strong> – maximum time series length</p></li>
<li><p><strong>rate</strong> – dropout rate</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.TransformerEncoder.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.TransformerEncoder.call" title="Permalink to this definition"></a></dt>
<dd><p>Call the transformer encoder.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deepof.model_utils.TransformerDecoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">TransformerDecoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.TransformerDecoder" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Layer</span></code></p>
<p>Transformer decoder.</p>
<p>Based on <a class="reference external" href="https://www.tensorflow.org/text/tutorials/transformer">https://www.tensorflow.org/text/tutorials/transformer</a>.
Adapted according to <a class="reference external" href="https://academic.oup.com/gigascience/article/8/11/giz134/5626377?login=true">https://academic.oup.com/gigascience/article/8/11/giz134/5626377?login=true</a>
and <a class="reference external" href="https://arxiv.org/abs/1711.03905">https://arxiv.org/abs/1711.03905</a>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.TransformerDecoder.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seq_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">key_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_heads</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dff</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximum_position_encoding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.TransformerDecoder.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Construct the transformer decoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_layers</strong> – number of transformer layers to include.</p></li>
<li><p><strong>seq_dim</strong> – dimensionality of the sequence embeddings</p></li>
<li><p><strong>key_dim</strong> – dimensionality of the time series</p></li>
<li><p><strong>num_heads</strong> – number of heads of the multi-head-attention layers used on the transformer encoder</p></li>
<li><p><strong>dff</strong> – dimensionality of the token embeddings</p></li>
<li><p><strong>maximum_position_encoding</strong> – maximum time series length</p></li>
<li><p><strong>rate</strong> – dropout rate</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.TransformerDecoder.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enc_output</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">look_ahead_mask</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_mask</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.TransformerDecoder.call" title="Permalink to this definition"></a></dt>
<dd><p>Call the transformer decoder.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.log_hyperparameters">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">log_hyperparameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.log_hyperparameters" title="Permalink to this definition"></a></dt>
<dd><p>Log hyperparameters in tensorboard.</p>
<p>Blueprint for hyperparameter and metric logging in tensorboard during hyperparameter tuning</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>List containing the hyperparameters to log in tensorboard.
metrics (list): List containing the metrics to log in tensorboard.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>logparams (list)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.embedding_model_fitting">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">embedding_model_fitting</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">preprocessed_object</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">adjacency_matrix</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">latent_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_history</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_hparams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_components</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kmeans_loss</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pretrained</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_checkpoints</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kl_annealing_mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kl_warmup</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_cat_clusters</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recluster</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">contrastive_similarity_function</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">contrastive_loss_function</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interaction_regularization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">run</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.embedding_model_fitting" title="Permalink to this definition"></a></dt>
<dd><p>Trains the specified embedding model on the preprocessed data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>coordinates</strong> (<em>np.ndarray</em>) – Coordinates of the data.</p></li>
<li><p><strong>preprocessed_object</strong> (<em>tuple</em>) – Tuple containing the preprocessed data.</p></li>
<li><p><strong>adjacency_matrix</strong> (<em>np.ndarray</em>) – adjacency_matrix (np.ndarray): adjacency matrix of the connectivity graph to use.</p></li>
<li><p><strong>embedding_model</strong> (<em>str</em>) – Model to use to embed and cluster the data. Must be one of VQVAE (default), VaDE,</p></li>
<li><p><strong>contrastive.</strong> (<em>and</em>) – </p></li>
<li><p><strong>encoder_type</strong> (<em>str</em>) – Encoder architecture to use. Must be one of “recurrent”, “TCN”, and “transformer”.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – Batch size to use for training.</p></li>
<li><p><strong>latent_dim</strong> (<em>int</em>) – Encoding size to use for training.</p></li>
<li><p><strong>epochs</strong> (<em>int</em>) – Number of epochs to train the autoencoder for.</p></li>
<li><p><strong>log_history</strong> (<em>bool</em>) – Whether to log the history of the autoencoder.</p></li>
<li><p><strong>log_hparams</strong> (<em>bool</em>) – Whether to log the hyperparameters used for training.</p></li>
<li><p><strong>n_components</strong> (<em>int</em>) – Number of components to fit to the data.</p></li>
<li><p><strong>output_path</strong> (<em>str</em>) – Path to the output directory.</p></li>
<li><p><strong>kmeans_loss</strong> (<em>float</em>) – Weight of the gram loss, which adds a regularization term to VQVAE models which</p></li>
<li><p><strong>space.</strong> (<em>penalizes the correlation between the dimensions in the latent</em>) – </p></li>
<li><p><strong>pretrained</strong> (<em>str</em>) – Path to the pretrained weights to use for the autoencoder.</p></li>
<li><p><strong>save_checkpoints</strong> (<em>bool</em>) – Whether to save checkpoints during training.</p></li>
<li><p><strong>save_weights</strong> (<em>bool</em>) – Whether to save the weights of the autoencoder after training.</p></li>
<li><p><strong>input_type</strong> (<em>str</em>) – Input type of the TableDict objects used for preprocessing. For logging purposes only.</p></li>
<li><p><strong>interaction_regularization</strong> (<em>float</em>) – Weight of the interaction regularization term (L1 penalization to all features not related to interactions).</p></li>
<li><p><strong>run</strong> (<em>int</em>) – Run number to use for logging.</p></li>
<li><p><strong>parameters</strong> (<em># Contrastive Model specific</em>) – </p></li>
<li><p><strong>kl_annealing_mode</strong> (<em>str</em>) – Mode to use for KL annealing. Must be one of “linear” (default), or “sigmoid”.</p></li>
<li><p><strong>kl_warmup</strong> (<em>int</em>) – Number of epochs during which KL is annealed.</p></li>
<li><p><strong>reg_cat_clusters</strong> (<em>bool</em>) – whether to penalize uneven cluster membership in the latent space, by</p></li>
<li><p><strong>distribution.</strong> (<em>minimizing the KL divergence between cluster membership and a uniform categorical</em>) – </p></li>
<li><p><strong>recluster</strong> (<em>bool</em>) – Whether to recluster the data after each training using a Gaussian Mixture Model.</p></li>
<li><p><strong>parameters</strong> – </p></li>
<li><p><strong>temperature</strong> (<em>float</em>) – temperature parameter for the contrastive loss functions. Higher values put harsher penalties on negative pair similarity.</p></li>
<li><p><strong>contrastive_similarity_function</strong> (<em>str</em>) – similarity function between positive and negative pairs. Must be one of ‘cosine’ (default), ‘euclidean’, ‘dot’, and ‘edit’.</p></li>
<li><p><strong>contrastive_loss_function</strong> (<em>str</em>) – contrastive loss function. Must be one of ‘nce’ (default), ‘dcl’, ‘fc’, and ‘hard_dcl’. See specific documentation for details.</p></li>
<li><p><strong>beta</strong> (<em>float</em>) – Beta (concentration) parameter for the hard_dcl contrastive loss. Higher values lead to ‘harder’ negative samples.</p></li>
<li><p><strong>tau</strong> (<em>float</em>) – Tau parameter for the dcl and hard_dcl contrastive losses, indicating positive class probability.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of trained models corresponding to the selected model class. The full trained model is last.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.embedding_per_video">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">embedding_per_video</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">coordinates</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">deepof_coordinates</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">to_preprocess</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">deepof_table_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'standard'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">animal_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ruptures</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">global_scaler</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.embedding_per_video" title="Permalink to this definition"></a></dt>
<dd><p>Use a previously trained model to produce embeddings, soft_counts and breaks per experiment in table_dict format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>coordinates</strong> (<em>coordinates</em>) – deepof.Coordinates object for the project at hand.</p></li>
<li><p><strong>to_preprocess</strong> (<em>table_dict</em>) – dictionary with (merged) features to process.</p></li>
<li><p><strong>scale</strong> (<em>str</em>) – The type of scaler to use within animals. Defaults to ‘standard’, but can be changed to ‘minmax’, ‘robust’, or False.</p></li>
<li><p><strong>model.</strong> (<em>Use the same that was used when training the original</em>) – </p></li>
<li><p><strong>animal_id</strong> (<em>str</em>) – if more than one animal is present, provide the ID(s) of the animal(s) to include.</p></li>
<li><p><strong>ruptures</strong> (<em>bool</em>) – Whether to compute the breaks based on ruptures (with the length of all retrieved chunks</p></li>
<li><p><strong>not</strong> (<em>per experiment</em><em>) </em><em>or</em>) – </p></li>
<li><p><strong>global_scaler</strong> (<em>Any</em>) – trained global scaler produced when processing the original dataset.</p></li>
<li><p><strong>model</strong> (<em>tf.keras.models.Model</em>) – trained deepof unsupervised model to run inference with.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>embeddings per experiment.
soft_counts (table_dict): soft_counts per experiment.
breaks (table_dict): breaks per experiment.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>embeddings (table_dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.tune_search">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">tune_search</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">preprocessed_object</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tuple</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">adjacency_matrix</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoding_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hypertun_trials</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hpt_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">project_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1024</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_epochs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">30</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_replicas</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outpath</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'unsupervised_tuner_search'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span></span></span><a class="headerlink" href="#deepof.model_utils.tune_search" title="Permalink to this definition"></a></dt>
<dd><p>Define the search space using keras-tuner and hyperband or bayesian optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>preprocessed_object</strong> (<em>tf.data.Dataset</em>) – Dataset object for training and validation.</p></li>
<li><p><strong>adjacency_matrix</strong> (<em>np.ndarray</em>) – Adjacency matrix for the graph.</p></li>
<li><p><strong>encoding_size</strong> (<em>int</em>) – Size of the encoding layer.</p></li>
<li><p><strong>embedding_model</strong> (<em>str</em>) – Model to use to embed and cluster the data. Must be one of VQVAE (default), VaDE,</p></li>
<li><p><strong>Contrastive.</strong> (<em>and</em>) – </p></li>
<li><p><strong>hypertun_trials</strong> (<em>int</em>) – Number of hypertuning trials to run.</p></li>
<li><p><strong>hpt_type</strong> (<em>str</em>) – Type of hypertuning to run. Must be one of “hyperband” or “bayesian”.</p></li>
<li><p><strong>k</strong> (<em>int</em>) – Number of clusters on the latent space.</p></li>
<li><p><strong>kmeans_loss</strong> (<em>float</em>) – Weight of the kmeans loss, which enforces disentanglement by penalizing the correlation</p></li>
<li><p><strong>space.</strong> (<em>between dimensions in the latent</em>) – </p></li>
<li><p><strong>project_name</strong> (<em>str</em>) – Name of the project.</p></li>
<li><p><strong>callbacks</strong> (<em>List</em>) – List of callbacks to use.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – Batch size to use.</p></li>
<li><p><strong>n_epochs</strong> (<em>int</em>) – Maximum number of epochs to train for.</p></li>
<li><p><strong>n_replicas</strong> (<em>int</em>) – Number of replicas to use.</p></li>
<li><p><strong>outpath</strong> (<em>str</em>) – Path to save the results.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Dictionary of the best hyperparameters.
best_run (str): Name of the best run.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>best_hparams (dict)</p>
</dd>
</dl>
</dd></dl>

</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Lucas Miranda.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>