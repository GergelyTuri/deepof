<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>deepof.model_utils module &mdash; deepof 0.1.5 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="shortcut icon" href="_static/deepof.ico"/>
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> deepof
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">deepof.model_utils module</a></li>
</ul>
</div>
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">deepof</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>deepof.model_utils module</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/deepof.model_utils.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-deepof.model_utils">
<span id="deepof-model-utils-module"></span><h1>deepof.model_utils module<a class="headerlink" href="#module-deepof.model_utils" title="Permalink to this headline"></a></h1>
<p>Functions, layers, regularizers, and general utilities for the unsupervised models within the deepof package.
See deepof.models for details on the currently supported architectures.</p>
<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.compute_shannon_entropy">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">compute_shannon_entropy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.compute_shannon_entropy" title="Permalink to this definition"></a></dt>
<dd><p>Computes Shannon entropy for a given tensor</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tensor</strong> (<em>tf.Tensor</em>) – tensor to compute the entropy for</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>entropy of the tensor</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.get_k_nearest_neighbors">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">get_k_nearest_neighbors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.get_k_nearest_neighbors" title="Permalink to this definition"></a></dt>
<dd><p>Retrieve indices of the k nearest neighbors in tensor to the vector with the specified index</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensor</strong> (<em>tf.Tensor</em>) – tensor to compute the k nearest neighbors for</p></li>
<li><p><strong>k</strong> (<em>int</em>) – number of nearest neighbors to retrieve</p></li>
<li><p><strong>index</strong> (<em>int</em>) – index of the vector to compute the k nearest neighbors for</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>indices of the k nearest neighbors</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.get_neighbourhood_entropy">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">get_neighbourhood_entropy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">index</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clusters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.get_neighbourhood_entropy" title="Permalink to this definition"></a></dt>
<dd><p>Computes the neighbourhood entropy for a given vector in a tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>index</strong> (<em>int</em>) – index of the vector to compute the neighbourhood entropy for</p></li>
<li><p><strong>tensor</strong> (<em>tf.Tensor</em>) – tensor to compute the neighbourhood entropy for</p></li>
<li><p><strong>clusters</strong> (<em>tf.Tensor</em>) – tensor containing the cluster labels for each vector in the tensor</p></li>
<li><p><strong>k</strong> (<em>int</em>) – number of nearest neighbours to consider</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>neighbourhood entropy of the vector with the specified index</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deepof.model_utils.exponential_learning_rate">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">exponential_learning_rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.exponential_learning_rate" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">keras.callbacks.Callback</span></code></p>
<p>Simple class that allows to grow learning rate exponentially during training</p>
<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.exponential_learning_rate.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.exponential_learning_rate.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Initializes the exponential learning rate callback</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>factor</strong> (<em>float</em>) – factor by which to multiply the learning rate</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.exponential_learning_rate.on_batch_end">
<span class="sig-name descname"><span class="pre">on_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.exponential_learning_rate.on_batch_end" title="Permalink to this definition"></a></dt>
<dd><p>This callback acts after processing each batch</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<em>int</em>) – current batch number</p></li>
<li><p><strong>logs</strong> (<em>dict</em>) – dictionary containing the loss for the current batch</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.find_learning_rate">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">find_learning_rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.find_learning_rate" title="Permalink to this definition"></a></dt>
<dd><p>Trains the provided model for an epoch with an exponentially increasing learning rate</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>tf.keras.Model</em>) – model to train</p></li>
<li><p><strong>X</strong> (<em>tf.Tensor</em>) – tensor containing the input data</p></li>
<li><p><strong>y</strong> (<em>tf.Tensor</em>) – tensor containing the target data</p></li>
<li><p><strong>epochs</strong> (<em>int</em>) – number of epochs to train the model for</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – batch size to use for training</p></li>
<li><p><strong>min_rate</strong> (<em>float</em>) – minimum learning rate to consider</p></li>
<li><p><strong>max_rate</strong> (<em>float</em>) – maximum learning rate to consider</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>learning rate that resulted in the lowest loss</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.plot_lr_vs_loss">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">plot_lr_vs_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rates</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">losses</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.plot_lr_vs_loss" title="Permalink to this definition"></a></dt>
<dd><p>Plots learing rate versus the loss function of the model</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>rates</strong> (<em>np.ndarray</em>) – array containing the learning rates to plot in the x-axis</p></li>
<li><p><strong>losses</strong> (<em>np.ndarray</em>) – array containing the losses to plot in the y-axis</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.compute_kernel">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">compute_kernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tensorflow.python.framework.ops.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tensorflow.python.framework.ops.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tensorflow.python.framework.ops.Tensor</span></span></span><a class="headerlink" href="#deepof.model_utils.compute_kernel" title="Permalink to this definition"></a></dt>
<dd><p>Computes the MMD between the two specified vectors using a gaussian kernel.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>tf.Tensor</em>) – left tensor</p></li>
<li><p><strong>y</strong> (<em>tf.Tensor</em>) – right tensor</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>returns the result of applying the kernel, for
each training instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>kernel (tf.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deepof.model_utils.compute_mmd">
<span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">compute_mmd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tensorflow.python.framework.ops.Tensor</span></span></span><a class="headerlink" href="#deepof.model_utils.compute_mmd" title="Permalink to this definition"></a></dt>
<dd><p>Computes the MMD between the two specified vectors using a gaussian kernel.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tensors</strong> (<em>tuple</em>) – tuple containing two tf.Tensor objects</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>returns the maximum mean discrepancy for each
training instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>mmd (tf.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deepof.model_utils.GaussianMixtureLatent">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">GaussianMixtureLatent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.GaussianMixtureLatent" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">keras.engine.training.Model</span></code></p>
<p>Gaussian Mixture probabilistic latent space model. Used to represent the embedding of motion tracking data in a
mixture of Gaussians with a specified number of components, with means, covariances and weights specified by
neural network layers.</p>
<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.GaussianMixtureLatent.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape:</span> <span class="pre">tuple</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_components:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">latent_dim:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size:</span> <span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss:</span> <span class="pre">str</span> <span class="pre">=</span> <span class="pre">'ELBO'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kl_warmup:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kl_annealing_mode:</span> <span class="pre">str</span> <span class="pre">=</span> <span class="pre">'linear'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mc_kl:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mmd_warmup:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mmd_annealing_mode:</span> <span class="pre">str</span> <span class="pre">=</span> <span class="pre">'linear'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer:</span> <span class="pre">keras.optimizer_v2.optimizer_v2.OptimizerV2</span> <span class="pre">=</span> <span class="pre">&lt;keras.optimizer_v2.adam.Adam</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overlap_loss:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_cat_clusters:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_cluster_variance:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.GaussianMixtureLatent.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Initializes the Gaussian Mixture Latent layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_shape</strong> (<em>tuple</em>) – shape of the input data</p></li>
<li><p><strong>n_components</strong> (<em>int</em>) – number of components in the Gaussian mixture.</p></li>
<li><p><strong>latent_dim</strong> (<em>int</em>) – dimensionality of the latent space.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – batch size for training.</p></li>
<li><p><strong>loss</strong> (<em>str</em>) – loss function to use for training. Must be one of “ELBO”, “MMD”, or “ELBO+MMD”.</p></li>
<li><p><strong>kl_warmup</strong> (<em>int</em>) – number of epochs to warm up the KL divergence.</p></li>
<li><p><strong>kl_annealing_mode</strong> (<em>str</em>) – mode to use for annealing the KL divergence. Must be one of “linear” and “sigmoid”.</p></li>
<li><p><strong>mc_kl</strong> (<em>int</em>) – number of Monte Carlo samples to use for computing the KL divergence.</p></li>
<li><p><strong>mmd_warmup</strong> (<em>int</em>) – number of epochs to warm up the MMD.</p></li>
<li><p><strong>mmd_annealing_mode</strong> (<em>str</em>) – mode to use for annealing the MMD. Must be one of “linear” and “sigmoid”.</p></li>
<li><p><strong>optimizer</strong> (<em>tf.keras.optimizers.Optimizer</em>) – optimizer to use for training. The layer needs access to it in</p></li>
<li><p><strong>weights.</strong> (<em>order to compute the KL and MMD annealing</em>) – </p></li>
<li><p><strong>overlap_loss</strong> (<em>float</em>) – weight of the overlap loss as described in deepof.mode_utils.ClusterOverlap</p></li>
<li><p><strong>reg_cat_clusters</strong> (<em>bool</em>) – whether to use the penalize uneven cluster membership in the latent space.</p></li>
<li><p><strong>reg_cluster_variance</strong> (<em>bool</em>) – whether to penalize uneven cluster variances in the latent space.</p></li>
<li><p><strong>**kwargs</strong> – keyword arguments passed to the parent class</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.GaussianMixtureLatent.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.GaussianMixtureLatent.call" title="Permalink to this definition"></a></dt>
<dd><p>Computes the output of the layer.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="deepof.model_utils.GaussianMixtureLatent.model">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model</span></span><a class="headerlink" href="#deepof.model_utils.GaussianMixtureLatent.model" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deepof.model_utils.VectorQuantizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">VectorQuantizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.VectorQuantizer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">keras.engine.base_layer.Layer</span></code></p>
<p>Vector quantizer layer, which quantizes the input vectors into a fixed number of clusters using L2 norm. Based on
<a class="reference external" href="https://arxiv.org/pdf/1509.03700.pdf">https://arxiv.org/pdf/1509.03700.pdf</a>. Implementation based on <a class="reference external" href="https://keras.io/examples/generative/vq_vae/">https://keras.io/examples/generative/vq_vae/</a>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.VectorQuantizer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_components</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.VectorQuantizer.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Initializes the VQ layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_components</strong> (<em>int</em>) – number of embeddings to use</p></li>
<li><p><strong>embedding_dim</strong> (<em>int</em>) – dimensionality of the embeddings</p></li>
<li><p><strong>beta</strong> (<em>float</em>) – beta value for the loss function</p></li>
<li><p><strong>**kwargs</strong> – additional arguments for the parent class</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.VectorQuantizer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.VectorQuantizer.call" title="Permalink to this definition"></a></dt>
<dd><p>Computes the VQ layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>tf.Tensor</em>) – input tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>output tensor</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>x (tf.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.VectorQuantizer.get_code_indices">
<span class="sig-name descname"><span class="pre">get_code_indices</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">flattened_inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_soft_counts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.VectorQuantizer.get_code_indices" title="Permalink to this definition"></a></dt>
<dd><p>Getter for the code indices at any given time.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_shape</strong> (<em>tf.Tensor</em>) – input shape</p></li>
<li><p><strong>flattened_inputs</strong> (<em>tf.Tensor</em>) – flattened input tensor (encoder output)</p></li>
<li><p><strong>return_soft_counts</strong> (<em>bool</em>) – whether to return soft counts based on the distance to the codes, instead of</p></li>
<li><p><strong>indices</strong> (<em>the code</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>code indices tensor with cluster assignments.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>encoding_indices (tf.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.VectorQuantizer.update_posterior_variances">
<span class="sig-name descname"><span class="pre">update_posterior_variances</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.VectorQuantizer.update_posterior_variances" title="Permalink to this definition"></a></dt>
<dd><p>Updates the posterior variances of the codebook (not used while training, only later as a way
of sampling the latent space.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deepof.model_utils.one_cycle_scheduler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">one_cycle_scheduler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">iterations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">last_iterations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">last_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'.'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.one_cycle_scheduler" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">keras.callbacks.Callback</span></code></p>
<p>One cycle learning rate scheduler.
Based on <a class="reference external" href="https://arxiv.org/pdf/1506.01186.pdf">https://arxiv.org/pdf/1506.01186.pdf</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.one_cycle_scheduler.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">iterations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">last_iterations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">last_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'.'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.one_cycle_scheduler.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Initializes the scheduler.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>iterations</strong> (<em>int</em>) – number of iterations to train for</p></li>
<li><p><strong>max_rate</strong> (<em>float</em>) – maximum learning rate</p></li>
<li><p><strong>start_rate</strong> (<em>float</em>) – starting learning rate</p></li>
<li><p><strong>last_iterations</strong> (<em>int</em>) – number of iterations to train for at the last rate</p></li>
<li><p><strong>last_rate</strong> (<em>float</em>) – learning rate at the last iteration</p></li>
<li><p><strong>log_dir</strong> (<em>str</em>) – directory to save the learning rate to</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.one_cycle_scheduler.on_batch_begin">
<span class="sig-name descname"><span class="pre">on_batch_begin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.one_cycle_scheduler.on_batch_begin" title="Permalink to this definition"></a></dt>
<dd><p>Defines computations to perform for each batch</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<em>int</em>) – current batch number</p></li>
<li><p><strong>logs</strong> (<em>dict</em>) – dictionary of logs</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.one_cycle_scheduler.on_epoch_end">
<span class="sig-name descname"><span class="pre">on_epoch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.one_cycle_scheduler.on_epoch_end" title="Permalink to this definition"></a></dt>
<dd><p>Logs the learning rate to tensorboard</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<em>int</em>) – current epoch number</p></li>
<li><p><strong>logs</strong> (<em>dict</em>) – dictionary of logs</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deepof.model_utils.MCDropout">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">MCDropout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.MCDropout" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">keras.layers.core.Dropout</span></code></p>
<p>Equivalent to tf.keras.layers.Dropout, but with training mode enabled at prediction time.
Useful for Montecarlo predictions</p>
<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.MCDropout.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.MCDropout.call" title="Permalink to this definition"></a></dt>
<dd><p>Overrides the call method of the subclassed function</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deepof.model_utils.DenseTranspose">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">DenseTranspose</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.DenseTranspose" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">keras.engine.base_layer.Layer</span></code></p>
<p>Mirrors a tf.keras.layers.Dense instance with transposed weights.
Useful for decoder layers in autoencoders, to force structure and
decrease the effective number of parameters to train</p>
<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.DenseTranspose.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dense</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.DenseTranspose.__init__" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.DenseTranspose.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.DenseTranspose.get_config" title="Permalink to this definition"></a></dt>
<dd><p>Updates Constraint metadata</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.DenseTranspose.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.DenseTranspose.build" title="Permalink to this definition"></a></dt>
<dd><p>Updates Layer’s build method</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.DenseTranspose.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.DenseTranspose.call" title="Permalink to this definition"></a></dt>
<dd><p>Updates Layer’s call method</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.DenseTranspose.compute_output_shape">
<span class="sig-name descname"><span class="pre">compute_output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.DenseTranspose.compute_output_shape" title="Permalink to this definition"></a></dt>
<dd><p>Outputs the transposed shape</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deepof.model_utils.KLDivergenceLayer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">KLDivergenceLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.KLDivergenceLayer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tensorflow_probability.python.layers.distribution_layer.KLDivergenceAddLoss</span></code></p>
<p>Identity transform layer that adds KL Divergence
to the final model loss.</p>
<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.KLDivergenceLayer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">iters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_up_iters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">annealing_mode</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.KLDivergenceLayer.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Initializes the KL Divergence layer</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>iters</strong> (<em>int</em>) – number of training iterations taken so far</p></li>
<li><p><strong>warm_up_iters</strong> (<em>int</em>) – maximum number of training iterations for warmup</p></li>
<li><p><strong>annealing_mode</strong> (<em>str</em>) – mode of annealing, either ‘linear’ or ‘sigmoid’</p></li>
<li><p><strong>*args</strong> – additional positional arguments</p></li>
<li><p><strong>**kwargs</strong> – additional keyword arguments</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.KLDivergenceLayer.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.KLDivergenceLayer.get_config" title="Permalink to this definition"></a></dt>
<dd><p>Updates Constraint metadata</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.KLDivergenceLayer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">distribution_a</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.KLDivergenceLayer.call" title="Permalink to this definition"></a></dt>
<dd><p>Updates Layer’s call method</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deepof.model_utils.MMDiscrepancyLayer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">MMDiscrepancyLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.MMDiscrepancyLayer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">keras.engine.base_layer.Layer</span></code></p>
<p>Identity transform layer that adds MM Discrepancy
to the final model loss.</p>
<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.MMDiscrepancyLayer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tensorflow_probability.python.distributions.distribution.Distribution</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_up_iters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">annealing_mode</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.MMDiscrepancyLayer.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Initializes the MMDiscrepancy layer</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_size</strong> (<em>int</em>) – batch size of the model</p></li>
<li><p><strong>prior</strong> (<em>tfd.Distribution</em>) – prior distribution of the model</p></li>
<li><p><strong>iters</strong> (<em>int</em>) – number of training iterations taken so far</p></li>
<li><p><strong>warm_up_iters</strong> (<em>int</em>) – maximum number of training iterations for warmup</p></li>
<li><p><strong>annealing_mode</strong> (<em>str</em>) – mode of annealing, either ‘linear’ or ‘sigmoid’</p></li>
<li><p><strong>*args</strong> – additional positional arguments</p></li>
<li><p><strong>**kwargs</strong> – additional keyword arguments</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.MMDiscrepancyLayer.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.MMDiscrepancyLayer.get_config" title="Permalink to this definition"></a></dt>
<dd><p>Updates Constraint metadata</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.MMDiscrepancyLayer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">z</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.MMDiscrepancyLayer.call" title="Permalink to this definition"></a></dt>
<dd><p>Updates Layer’s call method</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deepof.model_utils.ClusterOverlap">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">ClusterOverlap</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.ClusterOverlap" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">keras.engine.base_layer.Layer</span></code></p>
<p>Identity layer that measures the overlap between the components of the latent Gaussian Mixture
using the the entropy of the nearest neighbourhood. If self.loss_weight &gt; 0, it adds a regularization
penalty to the loss function</p>
<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.ClusterOverlap.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoding_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_weight</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.ClusterOverlap.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Initializes the ClusterOverlap layer</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_size</strong> (<em>int</em>) – batch size of the model</p></li>
<li><p><strong>encoding_dim</strong> (<em>int</em>) – dimension of the latent Gaussian Mixture</p></li>
<li><p><strong>k</strong> (<em>int</em>) – number of nearest components of the latent Gaussian Mixture to consider</p></li>
<li><p><strong>loss_weight</strong> (<em>float</em>) – weight of the regularization penalty applied to the local entropy of each</p></li>
<li><p><strong>instance</strong> (<em>training</em>) – </p></li>
<li><p><strong>*args</strong> – additional positional arguments</p></li>
<li><p><strong>**kwargs</strong> – additional keyword arguments</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.ClusterOverlap.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.ClusterOverlap.get_config" title="Permalink to this definition"></a></dt>
<dd><p>Updates Constraint metadata</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.ClusterOverlap.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.ClusterOverlap.call" title="Permalink to this definition"></a></dt>
<dd><p>Updates Layer’s call method</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deepof.model_utils.MeanVarianceRegularizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deepof.model_utils.</span></span><span class="sig-name descname"><span class="pre">MeanVarianceRegularizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">strength</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.MeanVarianceRegularizer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">keras.regularizers.Regularizer</span></code></p>
<p>Regularizer class that penalizes the variance difference across latent Gaussian Mixture components</p>
<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.MeanVarianceRegularizer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">strength</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.MeanVarianceRegularizer.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Initializes MeanVarianceRegularizer</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>strength</strong> (<em>float</em>) – strength of the regularization penalty</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deepof.model_utils.MeanVarianceRegularizer.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepof.model_utils.MeanVarianceRegularizer.get_config" title="Permalink to this definition"></a></dt>
<dd><p>Returns the config of the regularizer.</p>
<p>An regularizer config is a Python dictionary (serializable)
containing all configuration parameters of the regularizer.
The same regularizer can be reinstantiated later
(without any saved state) from this configuration.</p>
<p>This method is optional if you are just training and executing models,
exporting to and from SavedModels, or using weight checkpoints.</p>
<p>This method is required for Keras <cite>model_to_estimator</cite>, saving and
loading models to HDF5 formats, Keras model cloning, some visualization
utilities, and exporting models to and from JSON.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Python dictionary.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Lucas Miranda.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>