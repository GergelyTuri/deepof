{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(os.path.dirname(\"../\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import deepof.data\n",
    "import deepof.models\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda t: [item for sublist in t for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load first batch\n",
    "dset11 = pd.ExcelFile(\n",
    "    \"../../Desktop/deepof-data/tagged_videos/Individual_datasets/DLC_batch_1/DLC_single_CDR1_1/1.Openfield_data-part1/JB05.1-OF-SI-part1.xlsx\"\n",
    ")\n",
    "dset12 = pd.ExcelFile(\n",
    "    \"../../Desktop/deepof-data/tagged_videos/Individual_datasets/DLC_batch_1/DLC_single_CDR1_1/2.Openfielddata-part2/AnimalID's-JB05.1-part2.xlsx\"\n",
    ")\n",
    "dset11 = pd.read_excel(dset11, \"Tabelle2\")\n",
    "dset12 = pd.read_excel(dset12, \"Tabelle2\")\n",
    "\n",
    "dset11.Test = dset11.Test.apply(lambda x: \"Test {}_s11\".format(x))\n",
    "dset12.Test = dset12.Test.apply(lambda x: \"Test {}_s12\".format(x))\n",
    "\n",
    "dset1 = {\n",
    "    \"CSDS\": list(dset11.loc[dset11.Treatment.isin([\"CTR+CSDS\", \"NatCre+CSDS\"]), \"Test\"])\n",
    "    + list(dset12.loc[dset12.Treatment.isin([\"CTR+CSDS\", \"NatCre+CSDS\"]), \"Test\"]),\n",
    "    \"NS\": list(\n",
    "        dset11.loc[\n",
    "            dset11.Treatment.isin([\"CTR+nonstressed\", \"NatCre+nonstressed\"]), \"Test\"\n",
    "        ]\n",
    "    )\n",
    "    + list(\n",
    "        dset12.loc[\n",
    "            dset12.Treatment.isin([\"CTR+nonstressed\", \"NatCre+nonstressed\"]), \"Test\"\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "dset1inv = {}\n",
    "for i in flatten(list(dset1.values())):\n",
    "    if i in dset1[\"CSDS\"]:\n",
    "        dset1inv[i] = \"CSDS\"\n",
    "    else:\n",
    "        dset1inv[i] = \"NS\"\n",
    "\n",
    "assert len(dset1inv) == dset11.shape[0] + dset12.shape[0], \"You missed some labels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load second batch\n",
    "dset21 = pd.read_excel(\n",
    "    \"../../Desktop/deepof-data/tagged_videos/Individual_datasets/DLC_batch_2/Part1/2_Single/stressproject22.04.2020genotypes-openfieldday1.xlsx\"\n",
    ")\n",
    "dset22 = pd.read_excel(\n",
    "    \"../../Desktop/deepof-data/tagged_videos/Individual_datasets/DLC_batch_2/Part2/2_Single/OpenFieldvideos-part2.xlsx\"\n",
    ")\n",
    "dset21.Test = dset21.Test.apply(lambda x: \"Test {}_s21\".format(x))\n",
    "dset22.Test = dset22.Test.apply(lambda x: \"Test {}_s22\".format(x))\n",
    "\n",
    "dset2 = {\n",
    "    \"CSDS\": list(dset21.loc[dset21.Treatment == \"Stress\", \"Test\"])\n",
    "    + list(dset22.loc[dset22.Treatment == \"Stressed\", \"Test\"]),\n",
    "    \"NS\": list(dset21.loc[dset21.Treatment == \"Nonstressed\", \"Test\"])\n",
    "    + list(dset22.loc[dset22.Treatment == \"Nonstressed\", \"Test\"]),\n",
    "}\n",
    "\n",
    "dset2inv = {}\n",
    "for i in flatten(list(dset2.values())):\n",
    "    if i in dset2[\"CSDS\"]:\n",
    "        dset2inv[i] = \"CSDS\"\n",
    "    else:\n",
    "        dset2inv[i] = \"NS\"\n",
    "\n",
    "assert len(dset2inv) == dset21.shape[0] + dset22.shape[0], \"You missed some labels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load third batch\n",
    "\n",
    "dset31 = pd.read_excel(\n",
    "    \"../../Desktop/deepof-data/tagged_videos/Individual_datasets/DLC_batch_3/1.Day2OF-SIpart1/JB05 2Female-ELS-OF-SIpart1.xlsx\",\n",
    "    sheet_name=1,\n",
    ")\n",
    "dset32 = pd.read_excel(\n",
    "    \"../../Desktop/deepof-data/tagged_videos/Individual_datasets/DLC_batch_3/2.Day3OF-SIpart2/JB05 2FEMALE-ELS-OF-SIpart2.xlsx\",\n",
    "    sheet_name=1,\n",
    ")\n",
    "dset31.Test = dset31.Test.apply(lambda x: \"Test {}_s31\".format(x))\n",
    "dset32.Test = dset32.Test.apply(lambda x: \"Test {}_s32\".format(x))\n",
    "\n",
    "dset3 = {\"CSDS\": [], \"NS\": list(dset31.loc[:, \"Test\"]) + list(dset32.loc[:, \"Test\"])}\n",
    "\n",
    "dset3inv = {}\n",
    "for i in flatten(list(dset3.values())):\n",
    "    if i in dset3[\"CSDS\"]:\n",
    "        dset3inv[i] = \"CSDS\"\n",
    "    else:\n",
    "        dset3inv[i] = \"NS\"\n",
    "\n",
    "assert len(dset3inv) == dset31.shape[0] + dset32.shape[0], \"You missed some labels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fourth batch\n",
    "dset41 = os.listdir(\n",
    "    \"../../Desktop/deepof-data/tagged_videos/Individual_datasets/DLC_batch_4/JB05.4-OpenFieldvideos/\"\n",
    ")\n",
    "\n",
    "# Remove empty video!\n",
    "dset41 = [vid for vid in dset41 if \"52\" not in vid]\n",
    "\n",
    "dset4 = {\"CSDS\": [], \"NS\": [i[:-4] + \"_s41\" for i in dset41]}\n",
    "\n",
    "dset4inv = {}\n",
    "for i in flatten(list(dset4.values())):\n",
    "    if i in dset4[\"CSDS\"]:\n",
    "        dset4inv[i] = \"CSDS\"\n",
    "    else:\n",
    "        dset4inv[i] = \"NS\"\n",
    "\n",
    "assert len(dset4inv) == len(dset41), \"You missed some labels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge phenotype dicts and serialise!\n",
    "aggregated_dset = {**dset1inv, **dset2inv, **dset3inv, **dset4inv}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(Counter(aggregated_dset.values()))\n",
    "print(115 + 52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save aggregated dataset to disk\n",
    "import pickle\n",
    "\n",
    "with open(\n",
    "    \"../../Desktop/deepof-data/deepof_single_topview/deepof_exp_conditions.pkl\", \"wb\"\n",
    ") as handle:\n",
    "    pickle.dump(aggregated_dset, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and run project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "deepof_main = deepof.data.project(\n",
    "    path=os.path.join(\"..\", \"..\", \"Desktop\", \"deepoftesttemp\"),\n",
    "    smooth_alpha=0.99,\n",
    "    arena_dims=[380],\n",
    "    exclude_bodyparts=[\"Tail_1\", \"Tail_2\", \"Tail_tip\", \"Tail_base\"],\n",
    "    exp_conditions=aggregated_dset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "deepof_main = deepof_main.run(verbose=True)\n",
    "print(deepof_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_quality = pd.concat([tab for tab in deepof_main.get_quality().values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_quality.boxplot(rot=45)\n",
    "plt.ylim(0.99985, 1.00001)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(quality_top=(0.0, 1.0, 0.01))\n",
    "def low_quality_tags(quality_top):\n",
    "    pd.DataFrame(\n",
    "        pd.melt(all_quality)\n",
    "        .groupby(\"bodyparts\")\n",
    "        .value.apply(lambda y: sum(y < quality_top) / len(y) * 100)\n",
    "    ).sort_values(by=\"value\", ascending=False).plot.bar(rot=45)\n",
    "\n",
    "    plt.xlabel(\"body part\")\n",
    "    plt.ylabel(\"Tags with quality under {} (%)\".format(quality_top * 100))\n",
    "    plt.tight_layout()\n",
    "    plt.legend([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "deepof_coords = deepof_main.get_coords(\n",
    "    center=\"Center\",\n",
    "    polar=False,\n",
    "    speed=0,\n",
    "    align=\"Spine_1\",\n",
    "    align_inplace=True,\n",
    "    propagate_labels=False,\n",
    ")\n",
    "# deepof_dists  = deepof_main.get_distances(propagate_labels=False)\n",
    "# deepof_angles = deepof_main.get_angles(propagate_labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "print(\"Preprocessing training set...\")\n",
    "deepof_train = deepof_coords.preprocess(\n",
    "    window_size=24,\n",
    "    window_step=24,\n",
    "    conv_filter=None,\n",
    "    scale=\"standard\",\n",
    "    shuffle=False,\n",
    "    test_videos=0,\n",
    ")[0]\n",
    "\n",
    "# print(\"Loading pre-trained model...\")\n",
    "# encoder, decoder, grouper, gmvaep, = deepof.models.SEQ_2_SEQ_GMVAE(\n",
    "#     loss=\"ELBO\",\n",
    "#     number_of_components=20,\n",
    "#     compile_model=True,\n",
    "#     kl_warmup_epochs=20,\n",
    "#     montecarlo_kl=10,\n",
    "#     encoding=6,\n",
    "#     mmd_warmup_epochs=20,\n",
    "#     predictor=0,\n",
    "#     phenotype_prediction=0,\n",
    "# ).build(deepof_train.shape)[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [\n",
    "    \"../../Desktop/\" + i\n",
    "    for i in os.listdir(\"../../Desktop/\")\n",
    "    if i.endswith(\"h5\")\n",
    "]\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_network = weights[2]\n",
    "print(trained_network)\n",
    "l = int(re.findall(\"encoding=(\\d+)_\", trained_network)[0])\n",
    "k = int(re.findall(\"k=(\\d+)_\", trained_network)[0])\n",
    "pheno = 0\n",
    "\n",
    "encoder, decoder, grouper, gmvaep, = deepof.models.SEQ_2_SEQ_GMVAE(\n",
    "    loss=\"ELBO\",\n",
    "    number_of_components=k,\n",
    "    compile_model=True,\n",
    "    kl_warmup_epochs=20,\n",
    "    montecarlo_kl=10,\n",
    "    encoding=l,\n",
    "    mmd_warmup_epochs=20,\n",
    "    predictor=0,\n",
    "    phenotype_prediction=pheno,\n",
    "    reg_cat_clusters=(\"categorical\" in trained_network),\n",
    "    reg_cluster_variance=(\"variance\" in trained_network),\n",
    ").build(deepof_train.shape)[:4]\n",
    "\n",
    "gmvaep.load_weights(trained_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data to pass through the models\n",
    "trained_distribution = encoder(deepof_train)\n",
    "categories = tf.keras.models.Model(encoder.input, encoder.layers[15].output)(\n",
    "    deepof_train\n",
    ").numpy()\n",
    "\n",
    "# Fit a scaler to unscale the reconstructions later on\n",
    "video_key = np.random.choice(list(deepof_coords.keys()), 1)[0]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(np.array(pd.concat(list(deepof_coords.values()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve latent distribution parameters and sample from posterior\n",
    "def get_median_params(component, categories, cluster, param):\n",
    "\n",
    "    if param == \"mean\":\n",
    "        component = component.mean().numpy()\n",
    "    elif param == \"stddev\":\n",
    "        component = component.stddev().numpy()\n",
    "\n",
    "    cluster_select = np.argmax(categories, axis=1) == cluster\n",
    "    if np.sum(cluster_select) == 0:\n",
    "        return None\n",
    "    component = component[cluster_select]\n",
    "    return np.median(component, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_latent_parameters(\n",
    "    distribution, reduce=False, plot=False, categories=None, filt=0, save=True\n",
    "):\n",
    "    mix_components = distribution.components\n",
    "\n",
    "    # The main problem is here! We need to select only those training instances in which a given cluster was selected.\n",
    "    # Then compute the median for those only\n",
    "\n",
    "    means = [\n",
    "        get_median_params(component, categories, i, \"mean\")\n",
    "        for i, component in enumerate(mix_components)\n",
    "    ]\n",
    "    stddevs = [\n",
    "        get_median_params(component, categories, i, \"stddev\")\n",
    "        for i, component in enumerate(mix_components)\n",
    "    ]\n",
    "    means = [i for i in means if i is not None]\n",
    "    stddevs = [i for i in stddevs if i is not None]\n",
    "\n",
    "    if filter:\n",
    "        filts = np.max(categories, axis=0) > filt\n",
    "        means = [i for i, j in zip(means, filts) if j]\n",
    "        stddevs = [i for i, j in zip(stddevs, filts) if j]\n",
    "\n",
    "    if reduce:\n",
    "        data = [\n",
    "            np.random.normal(size=[1000, len(means[0])], loc=meanvec, scale=stddevvec)[\n",
    "                :, np.newaxis\n",
    "            ]\n",
    "            for meanvec, stddevvec in zip(means, stddevs)\n",
    "        ]\n",
    "        data = np.concatenate(data, axis=1).reshape([1000 * len(means), len(means[0])])\n",
    "        reducer = PCA(n_components=3)\n",
    "        data = reducer.fit_transform(data)\n",
    "        data = data.reshape([1000, len(means), 3])\n",
    "\n",
    "    if plot == 2:\n",
    "        for i in range(len(means)):\n",
    "            plt.scatter(data[:, i, 0], data[:, i, 1], label=i)\n",
    "        plt.title(\n",
    "            \"Mean representation of latent space - K={}/{} - L={} - filt={}\".format(\n",
    "                len(means), len(mix_components), len(means[0]), filt\n",
    "            )\n",
    "        )\n",
    "        plt.xlabel(\"PCA 1\")\n",
    "        plt.ylabel(\"PCA 2\")\n",
    "        # plt.legend()\n",
    "        if save:\n",
    "            plt.savefig(\n",
    "                \"Mean representation of latent space - K={}.{} - L={} - filt={}.png\".format(\n",
    "                    len(means), len(mix_components), len(means[0]), filt\n",
    "                ).replace(\n",
    "                    \" \", \"_\"\n",
    "                )\n",
    "            )\n",
    "        plt.show()\n",
    "\n",
    "    elif plot == 3:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection=\"3d\")\n",
    "        for i in range(len(means)):\n",
    "            ax.scatter(data[:, i, 0], data[:, i, 1], data[:, i, 2], label=i)\n",
    "        plt.title(\n",
    "            \"Mean representation of latent space - K={}/{} - L={} - filt={}\".format(\n",
    "                len(means), len(mix_components), len(means[0]), filt\n",
    "            )\n",
    "        )\n",
    "        ax.set_xlabel(\"PCA 1\")\n",
    "        ax.set_ylabel(\"PCA 2\")\n",
    "        ax.set_zlabel(\"PCA 3\")\n",
    "        # plt.legend()\n",
    "        if save:\n",
    "            plt.savefig(\n",
    "                \"Mean representation of latent space - K={}.{} - L={} - filt={}.png\".format(\n",
    "                    len(means), len(mix_components), len(means[0]), filt\n",
    "                ).replace(\n",
    "                    \" \", \"_\"\n",
    "                )\n",
    "            )\n",
    "        plt.show()\n",
    "\n",
    "    elif plot > 3:\n",
    "        raise ValueError(\"Can't plot in more than 3 dimensions!\")\n",
    "\n",
    "    return means, stddevs\n",
    "\n",
    "\n",
    "def sample_from_posterior(\n",
    "    decoder, parameters, component, enable_variance=False, video_output=False, samples=1\n",
    "):\n",
    "    means, stddevs = parameters\n",
    "    sample = np.random.normal(\n",
    "        size=[samples, len(means[component])],\n",
    "        loc=means[component],\n",
    "        scale=(stddevs[component] if enable_variance else 0),\n",
    "    )\n",
    "    reconstruction = decoder(sample).mean()\n",
    "\n",
    "    if video_output:\n",
    "        scaled_video_rec = scaler.inverse_transform(reconstruction)\n",
    "        scaled_video_rec = scaled_video_rec.reshape(\n",
    "            [samples * scaled_video_rec.shape[1], scaled_video_rec.shape[2]]\n",
    "        )\n",
    "        columns = deepof_coords[list(deepof_coords.keys())[0]].columns\n",
    "        scaled_video_rec = pd.DataFrame(scaled_video_rec, columns=columns)\n",
    "\n",
    "        ### VIDEO OUTPUT ###\n",
    "        w = 400\n",
    "        h = 400\n",
    "        factor = 2.5\n",
    "\n",
    "        # Instantiate video\n",
    "        writer = cv2.VideoWriter()\n",
    "        writer.open(\n",
    "            \"Reconstruction_test_L={}_k={}_pheno={}_component={}_video.avi\".format(\n",
    "                l, k, pheno, component\n",
    "            ),\n",
    "            cv2.VideoWriter_fourcc(*\"MJPG\"),\n",
    "            24,\n",
    "            (int(w * factor), int(h * factor)),\n",
    "            True,\n",
    "        )\n",
    "\n",
    "        for frame in tqdm.tqdm(range(scaled_video_rec.shape[0])):\n",
    "\n",
    "            image = np.zeros((h, w, 3), np.uint8) + 30\n",
    "            for bpart in scaled_video_rec.columns.levels[0]:\n",
    "\n",
    "                try:\n",
    "                    pos = (\n",
    "                        (-int(scaled_video_rec[bpart].loc[frame, \"x\"]) + w // 2),\n",
    "                        (-int(scaled_video_rec[bpart].loc[frame, \"y\"]) + h // 2),\n",
    "                    )\n",
    "\n",
    "                    cv2.circle(image, pos, 2, (0, 0, 255), -1)\n",
    "\n",
    "                except KeyError:\n",
    "                    continue\n",
    "\n",
    "            # draw skeleton\n",
    "            def draw_line(start, end, df, col):\n",
    "                for bpart in end:\n",
    "                    cv2.line(\n",
    "                        image,\n",
    "                        tuple(-df[start].loc[frame, :].asisinstance(int) + w // 2),\n",
    "                        tuple(-df[bpart].loc[frame, :].asisinstance(int) + h // 2),\n",
    "                        col,\n",
    "                        1,\n",
    "                    )\n",
    "\n",
    "            col = (0, 0, 255)\n",
    "            draw_line(\"Nose\", [\"Left_ear\", \"Right_ear\"], scaled_video_rec, col)\n",
    "            draw_line(\n",
    "                \"Spine_1\",\n",
    "                [\"Left_ear\", \"Right_ear\", \"Left_fhip\", \"Right_fhip\"],\n",
    "                scaled_video_rec,\n",
    "                col,\n",
    "            )\n",
    "            draw_line(\n",
    "                \"Spine_2\", [\"Spine_1\", \"Left_bhip\", \"Right_bhip\"], scaled_video_rec, col\n",
    "            )\n",
    "            # draw_line(\"Tail_1\", [\"Tail_base\", \"Tail_2\"], scaled_video_rec, col)\n",
    "            # draw_line(\"Tail_tip\", [\"Tail_2\"], scaled_video_rec, col)\n",
    "\n",
    "            image = cv2.resize(image, (0, 0), fx=factor, fy=factor)\n",
    "            writer.write(image)\n",
    "\n",
    "        writer.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    return reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trained_distribution' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f13a38354619>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m means, stddevs = retrieve_latent_parameters(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrained_distribution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcategories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trained_distribution' is not defined"
     ]
    }
   ],
   "source": [
    "means, stddevs = retrieve_latent_parameters(\n",
    "    trained_distribution,\n",
    "    categories=categories,\n",
    "    reduce=True,\n",
    "    plot=2,\n",
    "    filt=0.9,\n",
    "    save=True,\n",
    ")\n",
    "# for i in range(0, 25):\n",
    "#    reconst = sample_from_posterior(decoder, (means, stddevs), i, enable_variance=True, video_output=True, samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load rule based labels for the videos at play\n",
    "tag_path = \"./rule_based_labels/\"\n",
    "rule_based_tags = [\n",
    "    tag_path + i\n",
    "    for i in os.listdir(tag_path)\n",
    "    for j in list(deepof_main._tables.keys())\n",
    "    if j in i\n",
    "]\n",
    "rule_based_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = {k: pd.read_csv(k, sep=\"\\t\") for k in rule_based_tags}\n",
    "concat_tags = np.concatenate(list(tags.values()))\n",
    "concat_tags = concat_tags[:, 3]\n",
    "concat_tags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving = (\n",
    "    pd.Series(concat_tags)\n",
    "    .rolling(window=24,)\n",
    "    .apply(lambda x: np.any(x > 2))[::24][1:]\n",
    "    .asisinstance(bool)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass training set through the grouper to obtain cluster assignments\n",
    "clusters = grouper.predict(deepof_train)\n",
    "argmax_clusters = np.argmax(clusters, axis=1)\n",
    "confid_clusters = np.max(clusters, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(max(argmax_clusters)):\n",
    "    if i in argmax_clusters[confid_clusters > 0.9]:\n",
    "        print(\n",
    "            i,\n",
    "            np.sum(argmax_clusters == i, axis=0),\n",
    "            np.round(\n",
    "                sum(moving[argmax_clusters == i])\n",
    "                / np.sum(argmax_clusters == i, axis=0),\n",
    "                5,\n",
    "            ),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_key = np.random.choice(list(deepof_coords.keys()), 1)[0]\n",
    "print(video_key)\n",
    "video_input = deepof.data.table_dict({video_key:deepof_coords[video_key]}, typ=\"coords\").preprocess(\n",
    "                                                                                                window_size=24,\n",
    "                                                                                                window_step=1,\n",
    "                                                                                                conv_filter=None,\n",
    "                                                                                                scale=\"standard\",\n",
    "                                                                                                shuffle=False,\n",
    "                                                                                                test_videos=0,\n",
    "                                                                                            )[0]\n",
    "\n",
    "print(video_input.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(np.array(pd.concat(list(deepof_coords.values()))))\n",
    "\n",
    "for trained_network in tqdm.tqdm(weights):\n",
    "\n",
    "    l = int(re.findall(\"encoding=(\\d+)_\", trained_network)[0])\n",
    "    k = int(re.findall(\"k=(\\d+)_\", trained_network)[0])\n",
    "    #pheno = float(re.findall(\"pheno=(.+?)_\", trained_network)[0])\n",
    "\n",
    "    encoder, decoder, grouper, gmvaep, = deepof.models.SEQ_2_SEQ_GMVAE(\n",
    "        loss=\"ELBO\",\n",
    "        number_of_components=k,\n",
    "        compile_model=True,\n",
    "        kl_warmup_epochs=20,\n",
    "        montecarlo_kl=10,\n",
    "        encoding=l,\n",
    "        mmd_warmup_epochs=20,\n",
    "        predictor=0,\n",
    "        phenotype_prediction=0,\n",
    "    ).build(video_input.shape)[:4]\n",
    "\n",
    "    gmvaep.load_weights(trained_network)\n",
    "\n",
    "    # Get reconstruction\n",
    "    video_pred = gmvaep.predict(video_input)[:, 6, :]\n",
    "\n",
    "    # Get encodings\n",
    "    # video_clusters = grouper.predict(video_input)\n",
    "    # video_encodings = encoder.predict(video_input)\n",
    "\n",
    "    scaled_video_pred = scaler.inverse_transform(video_pred)\n",
    "    scaled_video_input = scaler.inverse_transform(video_input[:, 6, :])\n",
    "\n",
    "    scaled_video_input = pd.DataFrame(scaled_video_input, columns=deepof_coords[video_key].columns)\n",
    "    scaled_video_pred = pd.DataFrame(scaled_video_pred, columns=deepof_coords[video_key].columns)\n",
    "\n",
    "    ### VIDEO OUTPUT ###\n",
    "    w = 400\n",
    "    h = 400\n",
    "    factor = 2.5\n",
    "\n",
    "    # Instantiate video\n",
    "    writer = cv2.VideoWriter()\n",
    "    writer.open(\n",
    "        \"L={}_k={}_pheno={}_run0_video.avi\".format(l,k,pheno),\n",
    "        cv2.VideoWriter_fourcc(*\"MJPG\"),\n",
    "        24,\n",
    "        (int(w * factor), int(h * factor)),\n",
    "        True,\n",
    "    )\n",
    "\n",
    "    for frame in tqdm.tqdm(range(250)):\n",
    "\n",
    "        image = np.zeros((h, w, 3), np.uint8) + 30\n",
    "        for bpart in scaled_video_input.columns.levels[0]:\n",
    "\n",
    "            try:\n",
    "                pos = (\n",
    "                    (-int(scaled_video_input[bpart].loc[frame, \"x\"]) + w // 2),\n",
    "                    (-int(scaled_video_input[bpart].loc[frame, \"y\"]) + h // 2),\n",
    "                )\n",
    "\n",
    "                pos_pred = (\n",
    "                    (-int(scaled_video_pred[bpart].loc[frame, \"x\"]) + w // 2),\n",
    "                    (-int(scaled_video_pred[bpart].loc[frame, \"y\"]) + h // 2),\n",
    "                )\n",
    "\n",
    "                cv2.circle(image, pos, 2, (0, 0, 255), -1)\n",
    "                cv2.circle(image, pos_pred, 2, (0, 255, 0), -1)\n",
    "\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "        # draw skeleton\n",
    "        def draw_line(start, end, df, col):\n",
    "            for bpart in end:\n",
    "                cv2.line(\n",
    "                    image,\n",
    "                    tuple(-df[start].loc[frame, :].astype(int) + w // 2),\n",
    "                    tuple(-df[bpart].loc[frame, :].astype(int) + h // 2),\n",
    "                    col,\n",
    "                    1,\n",
    "                )\n",
    "\n",
    "        \n",
    "        for df, col in zip([scaled_video_input, scaled_video_pred], [(0,0,255),(0,255,0)]):\n",
    "            draw_line(\"Nose\", [\"Left_ear\", \"Right_ear\"], df, col)\n",
    "            draw_line(\"Spine_1\", [\"Left_ear\", \"Right_ear\", \"Left_fhip\", \"Right_fhip\"], df, col)\n",
    "            draw_line(\"Spine_2\", [\"Spine_1\", \"Left_bhip\", \"Right_bhip\"], df, col)\n",
    "            \n",
    "        \n",
    "#         for df, col in zip([scaled_video_input, scaled_video_pred], [(0,0,255),(0,255,0)]):\n",
    "#             draw_line(\"Nose\", [\"Left_ear\", \"Right_ear\"], df, col)\n",
    "#             draw_line(\"Spine_1\", [\"Left_ear\", \"Right_ear\", \"Left_fhip\", \"Right_fhip\"], df, col)\n",
    "#             draw_line(\"Spine_2\", [\"Spine_1\", \"Tail_base\", \"Left_bhip\", \"Right_bhip\"], df, col)\n",
    "#             draw_line(\"Tail_1\", [\"Tail_base\", \"Tail_2\"], df, col)\n",
    "#             draw_line(\"Tail_tip\", [\"Tail_2\"], df, col)\n",
    "\n",
    "        image = cv2.resize(image, (0, 0), fx=factor, fy=factor)\n",
    "        writer.write(image)\n",
    "\n",
    "    writer.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_corrs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "### Plot latent space!\n",
    "X_train = deepof_coords.preprocess(\n",
    "    window_size=11,\n",
    "    window_step=1,\n",
    "    conv_filter=None,\n",
    "    scale=\"standard\",\n",
    "    shuffle=True,\n",
    "    test_videos=0,\n",
    ")[0]\n",
    "\n",
    "samples = 10000\n",
    "X_train = X_train[:samples]\n",
    "\n",
    "for trained_network in tqdm.tqdm(weights):\n",
    "    print(trained_network)\n",
    "\n",
    "    l = int(re.findall(\"encoding=(\\d+)_\", trained_network)[0])\n",
    "    k = int(re.findall(\"k=(\\d+)_\", trained_network)[0])\n",
    "    pheno = float(re.findall(\"pheno=(.+?)_\", trained_network)[0])\n",
    "\n",
    "    encoder, decoder, grouper, gmvaep, = deepof.models.SEQ_2_SEQ_GMVAE(\n",
    "        loss=\"ELBO\",\n",
    "        number_of_components=k,\n",
    "        compile_model=True,\n",
    "        kl_warmup_epochs=20,\n",
    "        montecarlo_kl=10,\n",
    "        encoding=l,\n",
    "        mmd_warmup_epochs=20,\n",
    "        predictor=0,\n",
    "        phenotype_prediction=pheno,\n",
    "    ).build(X_train.shape)[:4]\n",
    "\n",
    "    gmvaep.load_weights(trained_network)\n",
    "\n",
    "    # Get encodings\n",
    "    pheno_pred = gmvaep.predict(X_train)[1]\n",
    "    clusters = grouper.predict(X_train)\n",
    "    encodings = encoder.predict(X_train)\n",
    "\n",
    "    #     # For each cluster, compute correlation between pheno prediction and cluster weight\n",
    "    #     pheno_corr = []\n",
    "    #     for i in range(k):\n",
    "    #         pheno_corr.append(np.corrcoef(clusters[:,i], np.squeeze(pheno_pred))[0,1])\n",
    "    #     pheno_corrs[\"L={}_k={}_pheno={}_run0\".format(l,k, pheno)] = pheno_corr\n",
    "\n",
    "    reducer = umap.UMAP(n_components=2)\n",
    "    encodings = reducer.fit_transform(encodings)\n",
    "\n",
    "    sns.scatterplot(\n",
    "        encodings[:, 0],\n",
    "        encodings[:, 1],\n",
    "        hue=np.squeeze(\n",
    "            pheno_pred\n",
    "        ),  # np.argmax(clusters, axis=1).asisinstance(int).asisinstance(str),\n",
    "        # palette=(\"jet\" if k>1 else None), legend=\"none\")\n",
    "    )\n",
    "    plt.title(\"GMVAE Latent space representation: L={}; k={}\".format(l, k))\n",
    "    plt.xlabel(\"UMAP 1\")\n",
    "    plt.ylabel(\"UMAP 2\")\n",
    "    plt.legend([], [], frameon=False)\n",
    "    plt.savefig(\"L={}_k={}_pheno={}_run0_latent_space_phenohue.pdf\".format(l, k, pheno))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pheno_pred.shape)\n",
    "print(clusters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation density plots\n",
    "pweights = [0.01, 0.1, 0.5, 0.25, 1, 2, 4, 10, 100]\n",
    "for i in pweights:\n",
    "    corrs = {k: v for k, v in pheno_corrs.items() if str(i) in k}\n",
    "    sns.kdeplot(np.concatenate([i for i in corrs.values()]), label=str(i))\n",
    "    plt.xlabel(\"pearson correlation coefficient\")\n",
    "    plt.ylabel(\"density\")\n",
    "\n",
    "plt.savefig(\"deepof_pheno_fullcorrhistogram.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation density plots\n",
    "pweights = [0.01, 0.1, 0.5, 0.25, 1, 2, 4, 10, 100]\n",
    "for i in pweights:\n",
    "    corrs = {k: v for k, v in pheno_corrs.items() if str(i) in k}\n",
    "    sns.kdeplot(np.concatenate([i for i in corrs.values()]), label=str(i))\n",
    "    plt.xlabel(\"pearson correlation coefficient\")\n",
    "    plt.ylabel(\"density\")\n",
    "\n",
    "plt.savefig(\"deepof_pheno_parccorrhistogram.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    gmvaep,\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=True,\n",
    "    dpi=70,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly_express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_encodings(data, samples, n, clusters, threshold, highlight=None):\n",
    "\n",
    "    reducer = LinearDiscriminantAnalysis(n_components=n)\n",
    "    clusters = clusters[:samples, :]\n",
    "\n",
    "    # filter   = np.max(np.mean(clusters, axis=0), axis=1) > threshold\n",
    "\n",
    "    clusters = np.argmax(clusters, axis=1)  # [filter]\n",
    "    rep = reducer.fit_transform(data[:samples], clusters)\n",
    "\n",
    "    if n == 2:\n",
    "        df = pd.DataFrame(\n",
    "            {\n",
    "                \"encoding-1\": rep[:, 0],\n",
    "                \"encoding-2\": rep[:, 1],\n",
    "                \"clusters\": [\"A\" + str(i) for i in clusters],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        enc = px.scatter(\n",
    "            data_frame=df,\n",
    "            x=\"encoding-1\",\n",
    "            y=\"encoding-2\",\n",
    "            color=\"clusters\",\n",
    "            width=600,\n",
    "            height=600,\n",
    "            color_discrete_sequence=px.colors.qualitative.T10,\n",
    "        )\n",
    "\n",
    "        # if highlight:\n",
    "        #    ig.add_trace(go.Scatter(x=, y=)\n",
    "\n",
    "    elif n == 3:\n",
    "        df3d = pd.DataFrame(\n",
    "            {\n",
    "                \"encoding-1\": rep[:, 0],\n",
    "                \"encoding-2\": rep[:, 1],\n",
    "                \"encoding-3\": rep[:, 2],\n",
    "                \"clusters\": [\"A\" + str(i) for i in clusters],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        enc = px.scatter_3d(\n",
    "            data_frame=df3d,\n",
    "            x=\"encoding-1\",\n",
    "            y=\"encoding-2\",\n",
    "            z=\"encoding-3\",\n",
    "            color=\"clusters\",\n",
    "            width=600,\n",
    "            height=600,\n",
    "            color_discrete_sequence=px.colors.qualitative.T10,\n",
    "        )\n",
    "\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_encodings(encoder.predict(deepof_train[:10000]), 1000, 2, categories, 1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train, y_train, X_test, y_test = deepof_coords.preprocess(\n",
    "    window_size=11,\n",
    "    window_step=11,\n",
    "    conv_filter=None,\n",
    "    sigma=55,\n",
    "    shift=0,\n",
    "    scale=\"standard\",\n",
    "    align=\"all\",\n",
    "    shuffle=True,\n",
    "    test_videos=5,\n",
    ")\n",
    "print(\"Train dataset shape: \", X_train.shape)\n",
    "print(\"Train dataset shape: \", y_train.shape)\n",
    "print(\"Test dataset shape: \", X_test.shape)\n",
    "print(\"Test dataset shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build models and get learning rate (1-cycle policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq 2 seq Variational Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import tensorflow.keras as k\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Baseline_AE\"\n",
    "log_dir = os.path.abspath(\n",
    "    \"logs/fit/{}_{}\".format(NAME, datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    ")\n",
    "tensorboard_callback = k.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepof.models import SEQ_2_SEQ_AE, SEQ_2_SEQ_GMVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, decoder, ae = SEQ_2_SEQ_AE().build(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "(\n",
    "    encoder,\n",
    "    generator,\n",
    "    grouper,\n",
    "    gmvaep,\n",
    "    kl_warmup_callback,\n",
    "    mmd_warmup_callback,\n",
    ") = SEQ_2_SEQ_GMVAE(\n",
    "    loss=\"ELBO\",\n",
    "    compile_model=True,\n",
    "    number_of_components=10,\n",
    "    kl_warmup_epochs=20,\n",
    "    mmd_warmup_epochs=0,\n",
    "    predictor=0,\n",
    "    phenotype_prediction=0,\n",
    "    architecture_hparams={\"encoding\": 2},\n",
    ").build(\n",
    "    X_train.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "rates, losses = deepof.model_utils.find_learning_rate(\n",
    "    gmvaep,\n",
    "    deepof_train[: 512 * 10],\n",
    "    deepof_test[: 512 * 10],\n",
    "    epochs=1,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "deepof.model_utils.plot_lr_vs_loss(rates, losses)\n",
    "plt.title(\"Learning rate tuning\")\n",
    "plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 1.4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = gmvaep.fit(\n",
    "    x=X_train,\n",
    "    y=X_train,\n",
    "    epochs=1,\n",
    "    batch_size=128,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test, [X_test, y_test]),\n",
    "    callbacks=[kl_warmup_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pttest\n",
    "samples = 15000\n",
    "montecarlo = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = \"GMVAE_components=30_loss=ELBO_kl_warmup=30_mmd_warmup=30_20200804-225526_final_weights.h5\"\n",
    "\n",
    "gmvaep.load_weights(weights)\n",
    "\n",
    "if montecarlo:\n",
    "    clusts = np.stack([grouper(data[:samples]) for sample in (tqdm(range(montecarlo)))])\n",
    "    clusters = clusts.mean(axis=0)\n",
    "    clusters = np.argmax(clusters, axis=1)\n",
    "\n",
    "else:\n",
    "    clusters = grouper(data[:samples], training=False)\n",
    "\n",
    "    clusters = np.argmax(clusters, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_encodings(data, samples, n, clusters, threshold):\n",
    "\n",
    "    reducer = PCA(n_components=n)\n",
    "    clusters = clusters[:, :samples]\n",
    "    filter = np.max(np.mean(clusters, axis=0), axis=1) > threshold\n",
    "    encoder.predict(data[:samples][filter])\n",
    "    print(\n",
    "        \"{}/{} samples used ({}%); confidence threshold={}\".format(\n",
    "            sum(filter), samples, sum(filter) / samples * 100, threshold\n",
    "        )\n",
    "    )\n",
    "\n",
    "    clusters = np.argmax(np.mean(clusters, axis=0), axis=1)[filter]\n",
    "    rep = reducer.fit_transform(encoder.predict(data[:samples][filter]))\n",
    "\n",
    "    if n == 2:\n",
    "        df = pd.DataFrame(\n",
    "            {\n",
    "                \"encoding-1\": rep[:, 0],\n",
    "                \"encoding-2\": rep[:, 1],\n",
    "                \"clusters\": [\"A\" + str(i) for i in clusters],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        enc = px.scatter(\n",
    "            data_frame=df,\n",
    "            x=\"encoding-1\",\n",
    "            y=\"encoding-2\",\n",
    "            color=\"clusters\",\n",
    "            width=600,\n",
    "            height=600,\n",
    "            color_discrete_sequence=px.colors.qualitative.T10,\n",
    "        )\n",
    "\n",
    "    elif n == 3:\n",
    "        df3d = pd.DataFrame(\n",
    "            {\n",
    "                \"encoding-1\": rep[:, 0],\n",
    "                \"encoding-2\": rep[:, 1],\n",
    "                \"encoding-3\": rep[:, 2],\n",
    "                \"clusters\": [\"A\" + str(i) for i in clusters],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        enc = px.scatter_3d(\n",
    "            data_frame=df3d,\n",
    "            x=\"encoding-1\",\n",
    "            y=\"encoding-2\",\n",
    "            z=\"encoding-3\",\n",
    "            color=\"clusters\",\n",
    "            width=600,\n",
    "            height=600,\n",
    "            color_discrete_sequence=px.colors.qualitative.T10,\n",
    "        )\n",
    "\n",
    "    return enc\n",
    "\n",
    "\n",
    "plot_encodings(data, 5000, 2, clusts, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence distribution per cluster\n",
    "for cl in range(5):\n",
    "    cl_select = np.argmax(np.mean(clusts, axis=0), axis=1) == cl\n",
    "    dt = np.mean(clusts[:, cl_select, cl], axis=0)\n",
    "    sns.kdeplot(dt, shade=True, label=cl)\n",
    "\n",
    "plt.xlabel(\"MC Dropout confidence\")\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animated_cluster_heatmap(data, clust, clusters, threshold=0.75, samples=False):\n",
    "\n",
    "    if not samples:\n",
    "        samples = data.shape[0]\n",
    "    tpoints = data.shape[1]\n",
    "    bdparts = data.shape[2] // 2\n",
    "\n",
    "    cls = clusters[:, :samples, :]\n",
    "    filt = np.max(np.mean(cls, axis=0), axis=1) > threshold\n",
    "\n",
    "    cls = np.argmax(np.mean(cls, axis=0), axis=1)[filt]\n",
    "    clust_series = data[:samples][filt][cls == clust]\n",
    "\n",
    "    rshape = clust_series.reshape(\n",
    "        clust_series.shape[0] * clust_series.shape[1], clust_series.shape[2]\n",
    "    )\n",
    "\n",
    "    cluster_df = pd.DataFrame()\n",
    "    cluster_df[\"x\"] = rshape[:, [0, 2, 4, 6, 8, 10]].flatten(order=\"F\")\n",
    "    cluster_df[\"y\"] = rshape[:, [1, 3, 5, 7, 9, 11]].flatten(order=\"F\")\n",
    "    cluster_df[\"bpart\"] = np.tile(\n",
    "        np.repeat(np.arange(bdparts), clust_series.shape[0]), tpoints\n",
    "    )\n",
    "    cluster_df[\"frame\"] = np.tile(\n",
    "        np.repeat(np.arange(tpoints), clust_series.shape[0]), bdparts\n",
    "    )\n",
    "\n",
    "    fig = px.density_contour(\n",
    "        data_frame=cluster_df,\n",
    "        x=\"x\",\n",
    "        y=\"y\",\n",
    "        animation_frame=\"frame\",\n",
    "        width=600,\n",
    "        height=600,\n",
    "        color=\"bpart\",\n",
    "        color_discrete_sequence=px.colors.qualitative.T10,\n",
    "    )\n",
    "\n",
    "    fig.update_traces(contours_coloring=\"fill\", contours_showlabels=True)\n",
    "\n",
    "    fig.update_xaxes(range=[-3, 3])\n",
    "    fig.update_yaxes(range=[-3, 3])\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# animated_cluster_heatmap(pttest, 4, clusts, samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stability across runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [i for i in os.listdir() if \"GMVAE\" in i and \".h5\" in i]\n",
    "mult_clusters = np.zeros([len(weights), samples])\n",
    "mean_conf = []\n",
    "\n",
    "for k, i in tqdm(enumerate(sorted(weights))):\n",
    "    print(i)\n",
    "    gmvaep.load_weights(i)\n",
    "\n",
    "    if montecarlo:\n",
    "        clusters = np.stack(\n",
    "            [grouper(data[:samples]) for sample in (tqdm(range(montecarlo)))]\n",
    "        )\n",
    "        clusters = clusters.mean(axis=0)\n",
    "        mean_conf.append(clusters.max(axis=1))\n",
    "        clusters = np.argmax(clusters, axis=1)\n",
    "\n",
    "    else:\n",
    "        clusters = grouper(data[:samples], training=False)\n",
    "        mean_conf.append(clusters.max(axis=1))\n",
    "        clusters = np.argmax(clusters, axis=1)\n",
    "\n",
    "    mult_clusters[k] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = 0.95\n",
    "ari_dist = []\n",
    "\n",
    "for i, k in enumerate(combinations(range(len(weights)), 2)):\n",
    "    filt = (mean_conf[k[0]] > thr) & (mean_conf[k[1]] > thr)\n",
    "\n",
    "    ari = adjusted_rand_score(mult_clusters[k[0]][filt], mult_clusters[k[1]][filt])\n",
    "\n",
    "    ari_dist.append(ari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ari_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_ari = []\n",
    "for i in tqdm(range(6)):\n",
    "    random_ari.append(\n",
    "        adjusted_rand_score(\n",
    "            np.random.uniform(0, 6, 50).asisinstance(int),\n",
    "            np.random.uniform(0, 6, 50).asisinstance(int),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(ari_dist, label=\"ARI gmvaep\", shade=True)\n",
    "sns.kdeplot(random_ari, label=\"ARI random\", shade=True)\n",
    "\n",
    "plt.xlabel(\"Normalised Adjusted Rand Index\")\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster differences across conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "DLCS1_coords = DLC_social_1_coords.get_coords(\n",
    "    center=\"B_Center\", polar=False, length=\"00:10:00\", align=\"B_Nose\"\n",
    ")\n",
    "\n",
    "Treatment_coords = {}\n",
    "\n",
    "for cond in Treatment_dict.keys():\n",
    "    Treatment_coords[cond] = DLCS1_coords.filter(Treatment_dict[cond]).preprocess(\n",
    "        window_size=13, window_step=10, filter=None, scale=\"standard\", align=\"center\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "montecarlo = 10\n",
    "\n",
    "Predictions_per_cond = {}\n",
    "Confidences_per_cond = {}\n",
    "\n",
    "for cond in Treatment_dict.keys():\n",
    "\n",
    "    Predictions_per_cond[cond] = np.stack(\n",
    "        [grouper(Treatment_coords[cond]) for sample in (tqdm(range(montecarlo)))]\n",
    "    )\n",
    "\n",
    "    Confidences_per_cond[cond] = np.mean(Predictions_per_cond[cond], axis=0)\n",
    "    Predictions_per_cond[cond] = np.argmax(Confidences_per_cond[cond], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Predictions_per_condition = {\n",
    "    k: {cl: [] for cl in range(1, 31)} for k in Treatment_dict.keys()\n",
    "}\n",
    "\n",
    "for k in Predictions_per_cond.values():\n",
    "    print(Counter(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cond in Treatment_dict.keys():\n",
    "    start = 0\n",
    "    for i, j in enumerate(DLCS1_coords.filter(Treatment_dict[cond]).values()):\n",
    "\n",
    "        update = start + j.shape[0] // 10\n",
    "        counter = Counter(Predictions_per_cond[cond][start:update])\n",
    "        start += j.shape[0] // 10\n",
    "\n",
    "        for num in counter.keys():\n",
    "            Predictions_per_condition[cond][num + 1].append(counter[num + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = []\n",
    "clusters = []\n",
    "conditions = []\n",
    "for cond, v in Predictions_per_condition.items():\n",
    "    for cluster, i in v.items():\n",
    "        counts += i\n",
    "        clusters += list(np.repeat(cluster, len(i)))\n",
    "        conditions += list(np.repeat(cond, len(i)))\n",
    "\n",
    "Prediction_per_cond_df = pd.DataFrame(\n",
    "    {\"condition\": conditions, \"cluster\": clusters, \"count\": counts}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame=Prediction_per_cond_df, x=\"cluster\", y=\"count\", color=\"condition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(Counter(labels[str(i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score(labels[0], labels[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(ari_dist)\n",
    "plt.xlabel(\"Adjusted Rand Index\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy(np.array([0.5, 0, 0.5, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd.Categorical(np.array([0.5, 0.5, 0.5, 0.5])).entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk = np.array([0.5, 0, 0.5, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.clip(np.log(pk), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-np.sum(pk * np.array([-0.69314718, 0, -0.69314718, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "entropy = K.sum(\n",
    "    tf.multiply(pk, tf.where(~tf.math.is_inf(K.log(pk)), K.log(pk), 0)), axis=0\n",
    ")\n",
    "entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.max(clusts, axis=1))\n",
    "sns.distplot(clusts.reshape(clusts.shape[0] * clusts.shape[1]))\n",
    "plt.axvline(1 / 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_means = gmvaep.get_layer(name=\"dense_4\").get_weights()[0][:32]\n",
    "gauss_variances = tf.keras.activations.softplus(\n",
    "    gmvaep.get_layer(name=\"dense_4\").get_weights()[0][32:]\n",
    ").numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_means.shape == gauss_variances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "n = 100\n",
    "samples = []\n",
    "for i in range(k):\n",
    "    samples.append(\n",
    "        np.random.normal(gauss_means[:, i], gauss_variances[:, i], size=(100, 32))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "test_matrix = np.zeros([k, k])\n",
    "for i in range(k):\n",
    "    for j in range(k):\n",
    "        test_matrix[i][j] = np.mean(\n",
    "            ttest_ind(samples[i], samples[j], equal_var=False)[1]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.55\n",
    "np.sum(test_matrix > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Treatment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomaly detection - the model was trained in the WT - NS mice alone\n",
    "gmvaep.load_weights(\n",
    "    \"GMVAE_components=10_loss=ELBO_kl_warmup=20_mmd_warmup=5_20200721-043310_final_weights.h5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_NS = table_dict(\n",
    "    {k: v for k, v in mtest2.items() if k in Treatment_dict[\"WT+NS\"]}, typ=\"coords\"\n",
    ")\n",
    "WT_WS = table_dict(\n",
    "    {k: v for k, v in mtest2.items() if k in Treatment_dict[\"WT+CSDS\"]}, typ=\"coords\"\n",
    ")\n",
    "MU_NS = table_dict(\n",
    "    {k: v for k, v in mtest2.items() if k in Treatment_dict[\"NatCre+NS\"]}, typ=\"coords\"\n",
    ")\n",
    "MU_WS = table_dict(\n",
    "    {k: v for k, v in mtest2.items() if k in Treatment_dict[\"NatCre+CSDS\"]},\n",
    "    typ=\"coords\",\n",
    ")\n",
    "\n",
    "preps = [\n",
    "    WT_NS.preprocess(\n",
    "        window_size=11,\n",
    "        window_step=10,\n",
    "        filter=\"gaussian\",\n",
    "        sigma=55,\n",
    "        shift=0,\n",
    "        scale=\"standard\",\n",
    "        align=True,\n",
    "    ),\n",
    "    WT_WS.preprocess(\n",
    "        window_size=11,\n",
    "        window_step=10,\n",
    "        filter=\"gaussian\",\n",
    "        sigma=55,\n",
    "        shift=0,\n",
    "        scale=\"standard\",\n",
    "        align=True,\n",
    "    ),\n",
    "    MU_NS.preprocess(\n",
    "        window_size=11,\n",
    "        window_step=10,\n",
    "        filter=\"gaussian\",\n",
    "        sigma=55,\n",
    "        shift=0,\n",
    "        scale=\"standard\",\n",
    "        align=True,\n",
    "    ),\n",
    "    MU_WS.preprocess(\n",
    "        window_size=11,\n",
    "        window_step=10,\n",
    "        filter=\"gaussian\",\n",
    "        sigma=55,\n",
    "        shift=0,\n",
    "        scale=\"standard\",\n",
    "        align=True,\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [gmvaep.predict(i) for i in preps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "reconst_error = {\n",
    "    k: mean_absolute_error(\n",
    "        preps[i].reshape(preps[i].shape[0] * preps[i].shape[1], 12).T,\n",
    "        preds[i].reshape(preds[i].shape[0] * preds[i].shape[1], 12).T,\n",
    "        multioutput=\"raw_values\",\n",
    "    )\n",
    "    for i, k in enumerate(Treatment_dict.keys())\n",
    "}\n",
    "\n",
    "reconst_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconst_df = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(\n",
    "            np.concatenate(\n",
    "                [np.repeat(k, len(v)).reshape(len(v), 1), v.reshape(len(v), 1)], axis=1\n",
    "            )\n",
    "        )\n",
    "        for k, v in reconst_error.items()\n",
    "    ]\n",
    ")\n",
    "reconst_df = reconst_df.asisinstance({0: str, 1: float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=reconst_df, x=0, y=1, orient=\"vertical\")\n",
    "plt.ylabel(\"Mean Absolute Error\")\n",
    "plt.ylim(0, 0.35)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check frame rates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
