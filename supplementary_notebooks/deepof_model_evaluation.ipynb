{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deepOF model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a dataset and a trained model, this notebook allows the user to \n",
    "\n",
    "* Load and inspect the different models (encoder, decoder, grouper, gmvaep)\n",
    "* Visualize reconstruction quality for a given model\n",
    "* Visualize a static latent space\n",
    "* Visualize trajectories on the latent space for a given video\n",
    "* sample from the latent space distributions and generate video clips showcasing generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.dirname(\"../\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepof.data\n",
    "import deepof.utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from ipywidgets import interact\n",
    "from IPython import display\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define and run project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\"..\", \"..\", \"Desktop\", \"deepoftesttemp\")\n",
    "trained_network = os.path.join(\"..\", \"..\", \"Desktop\")\n",
    "exclude_bodyparts = [\"Tail_1\", \"Tail_2\", \"Tail_tip\", \"Tail_base\"]\n",
    "window_size = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 280 ms, sys: 22.3 ms, total: 303 ms\n",
      "Wall time: 250 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "proj = deepof.data.project(\n",
    "    path=path,\n",
    "    smooth_alpha=0.99,\n",
    "    exclude_bodyparts=exclude_bodyparts,\n",
    "    arena_dims=[380],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trajectories...\n",
      "Smoothing trajectories...\n",
      "Interpolating outliers...\n",
      "Iterative imputation of ocluded bodyparts...\n",
      "Computing distances...\n",
      "Computing angles...\n",
      "Done!\n",
      "deepof analysis of 2 videos\n",
      "CPU times: user 2.63 s, sys: 85.8 ms, total: 2.71 s\n",
      "Wall time: 634 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "proj = proj.run(verbose=True)\n",
    "print(proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load pretrained deepof model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = proj.get_coords(center=\"Center\", align=\"Spine_1\", align_inplace=True)\n",
    "preprocessed_data,_,_,_ = coords.preprocess(test_videos=0, window_step=5, window_size=window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model parameters\n",
    "encoding=6\n",
    "loss=\"ELBO\"\n",
    "k=25\n",
    "pheno=0\n",
    "predictor=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to load a weight file containing 15 layers into a model with 14 layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-ea431bf97d05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m gmvaep.load_weights(\n\u001b[1;32m     11\u001b[0m     os.path.join(\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mtrained_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_network\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     )\n\u001b[1;32m     14\u001b[0m )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Machine_Learning/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2232\u001b[0m             f, self.layers, skip_mismatch=skip_mismatch)\n\u001b[1;32m   2233\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2234\u001b[0;31m         \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2236\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Machine_Learning/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m    686\u001b[0m                      \u001b[0;34m'containing '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                      \u001b[0;34m' layers into a model with '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m                      ' layers.')\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m   \u001b[0;31m# We batch weight value assignments in a single backend call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to load a weight file containing 15 layers into a model with 14 layers."
     ]
    }
   ],
   "source": [
    "encoder, decoder, grouper, gmvaep = deepof.models.SEQ_2_SEQ_GMVAE(\n",
    "    loss=loss,\n",
    "    number_of_components=k,\n",
    "    compile_model=True,\n",
    "    encoding=encoding,\n",
    "    predictor=predictor,\n",
    "    phenotype_prediction=pheno,\n",
    ").build(preprocessed_data.shape)[:4]\n",
    "\n",
    "gmvaep.load_weights(\n",
    "    os.path.join(\n",
    "        trained_network, [i for i in os.listdir(trained_network) if i.endswith(\"h5\")][0]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Uncomment to see model summaries\n",
    "# encoder.summary()\n",
    "# decoder.summary()\n",
    "# grouper.summary()\n",
    "# gmvaep.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to plot model structure\n",
    "def plot_model(model, name):\n",
    "    tf.keras.utils.plot_model(\n",
    "        model,\n",
    "        to_file=os.path.join(\n",
    "            path,\n",
    "            \"deepof_{}_{}.png\".format(name, datetime.now().strftime(\"%Y%m%d-%H%M%S\")),\n",
    "        ),\n",
    "        show_shapes=True,\n",
    "        show_dtype=False,\n",
    "        show_layer_names=True,\n",
    "        rankdir=\"TB\",\n",
    "        expand_nested=True,\n",
    "        dpi=200,\n",
    "    )\n",
    "\n",
    "\n",
    "# plot_model(encoder, \"encoder\")\n",
    "# plot_model(decoder, \"decoder\")\n",
    "# plot_model(grouper, \"grouper\")\n",
    "# plot_model(gmvaep, \"gmvaep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Pass data through all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = encoder.predict(preprocessed_data)\n",
    "groupings = grouper.predict(preprocessed_data)\n",
    "reconstrs = gmvaep.predict(preprocessed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate reconstruction (to be incorporated into deepof.evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a scaler to the data, to back-transform reconstructions later\n",
    "scaler = StandardScaler().fit(preprocessed_data[:, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale reconstructions\n",
    "rescaled_reconstructions = scaler.inverse_transform(\n",
    "    reconstrs.reshape(reconstrs.shape[0] * reconstrs.shape[1], reconstrs.shape[2])\n",
    ")\n",
    "rescaled_reconstructions = rescaled_reconstructions.reshape(reconstrs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary animation functions\n",
    "\n",
    "\n",
    "def plot_mouse_graph(instant_x, instant_y, instant_rec_x, instant_rec_y, ax, edges):\n",
    "    \"\"\"Generates a graph plot of the mouse\"\"\"\n",
    "    plots = []\n",
    "    rec_plots = []\n",
    "    for edge in edges:\n",
    "        (temp_plot,) = ax.plot(\n",
    "            [float(instant_x[edge[0]]), float(instant_x[edge[1]])],\n",
    "            [float(instant_y[edge[0]]), float(instant_y[edge[1]])],\n",
    "            color=\"#006699\",\n",
    "        )\n",
    "        (temp_rec_plot,) = ax.plot(\n",
    "            [float(instant_rec_x[edge[0]]), float(instant_rec_x[edge[1]])],\n",
    "            [float(instant_rec_y[edge[0]]), float(instant_rec_y[edge[1]])],\n",
    "            color=\"#006699\",\n",
    "        )\n",
    "        plots.append(temp_plot)\n",
    "        rec_plots.append(temp_rec_plot)\n",
    "    return plots\n",
    "\n",
    "\n",
    "def update_mouse_graph(x, y, plots, edges):\n",
    "    \"\"\"Updates the graph plot to enable animation\"\"\"\n",
    "\n",
    "    for plot, edge in zip(plots, edges):\n",
    "        plot.set_data(\n",
    "            [float(x[edge[0]]), float(x[edge[1]])],\n",
    "            [float(y[edge[0]]), float(y[edge[1]])],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7a005dac9b4673bc2c91dac50c7db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=7500.0, description='time_slider', max=15000.0, step=500.0), IntSlider…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display a video with the original data superimposed with the reconstructions\n",
    "\n",
    "random_exp = np.random.choice(list(coords.keys()), 1)[0]\n",
    "\n",
    "\n",
    "@interact(time_slider=(0.0, 15000, 500), length_slider=(0, 1000, 100))\n",
    "def animate_mice_across_time(time_slider, length_slider):\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "    edges = deepof.utils.connect_mouse_topview()\n",
    "\n",
    "    for bpart in exclude_bodyparts:\n",
    "        edges.remove_node(bpart)\n",
    "\n",
    "    for limb in [\"Left_fhip\", \"Right_fhip\", \"Left_bhip\", \"Right_bhip\"]:\n",
    "        edges.remove_edge(\"Center\", limb)\n",
    "\n",
    "    edges = edges.edges()\n",
    "\n",
    "    data = coords[random_exp].loc[time_slider : time_slider + length_slider - 1, :]\n",
    "    data_rec = gmvaep.predict(\n",
    "        coords.filter_videos([random_exp]).preprocess(\n",
    "            test_videos=0, window_step=5, window_size=window_size\n",
    "        )[0]\n",
    "    )\n",
    "    data_rec = pd.DataFrame(scaler.inverse_transform(data_rec[:, 24 // 2, :]))\n",
    "    data_rec.columns = data.columns\n",
    "\n",
    "    data[\"Center\", \"x\"] = 0\n",
    "    data[\"Center\", \"y\"] = 0\n",
    "    data_rec[\"Center\", \"x\"] = 0\n",
    "    data_rec[\"Center\", \"y\"] = 0\n",
    "\n",
    "    init_x = data.xs(\"x\", level=1, axis=1, drop_level=False).iloc[0, :]\n",
    "    init_y = data.xs(\"y\", level=1, axis=1, drop_level=False).iloc[0, :]\n",
    "    init_rec_x = data_rec.xs(\"x\", level=1, axis=1, drop_level=False).iloc[0, :]\n",
    "    init_rec_y = data_rec.xs(\"y\", level=1, axis=1, drop_level=False).iloc[0, :]\n",
    "\n",
    "    plots = plot_mouse_graph(init_x, init_y, init_rec_x, init_rec_y, ax, edges)\n",
    "    scatter = ax.scatter(x=np.array(init_x), y=np.array(init_y), color=\"#006699\",)\n",
    "    rec_scatter = ax.scatter(\n",
    "        x=np.array(init_rec_x), y=np.array(init_rec_y), color=\"#006699\",\n",
    "    )\n",
    "\n",
    "    # Update data in main plot\n",
    "    def animation_frame(i):\n",
    "        # Update scatter plot\n",
    "        x = data.xs(\"x\", level=1, axis=1, drop_level=False).iloc[i, :]\n",
    "        y = data.xs(\"y\", level=1, axis=1, drop_level=False).iloc[i, :]\n",
    "        rec_x = data_rec.xs(\"x\", level=1, axis=1, drop_level=False).iloc[i, :]\n",
    "        rec_y = data_rec.xs(\"y\", level=1, axis=1, drop_level=False).iloc[i, :]\n",
    "        \n",
    "        scatter.set_offsets(np.c_[np.array(x), np.array(y)])\n",
    "        scatter.set_offsets(np.c_[np.array(rec_x), np.array(rec_y)])\n",
    "        update_mouse_graph(x, y, plots, edges)\n",
    "\n",
    "        return scatter\n",
    "\n",
    "    animation = FuncAnimation(\n",
    "        fig, func=animation_frame, frames=length_slider, interval=100,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\"Positions across time for centered data\")\n",
    "    ax.set_ylim(-100, 60)\n",
    "    ax.set_xlim(-60, 60)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "\n",
    "    video = animation.to_html5_video()\n",
    "    html = display.HTML(video)\n",
    "    display.display(html)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Evaluate latent space (to be incorporated into deepof.evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
